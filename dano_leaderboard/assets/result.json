{"last_change": "2024-11-14-15-41", "last_commit": "f0a2462be108563b485bb17d92408ca594fcd13b", "results": [{"model": "Viking 7B", "scenario": "Citizenship Test", "executed": "2024-04-04-15-04", "scoring_id": "a77139f0-f2b6-11ee-9bcd-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.371900826446281, "uncertainty": 0.018650775779857676, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4489795918367347, "uncertainty": 0.019753125387153545, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.3752066115702479, "uncertainty": 0.018717525924754008, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.3135593220338983, "uncertainty": 0.017185582774201763, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.22109953345170463, "uncertainty": 0.01375027315618303, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.007729914812338915, "uncertainty": 0.0006124154547432365, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 1.263633533406614, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Viking 7B", "scenario": "Nordjylland News", "executed": "2024-04-04-15-17", "scoring_id": "a77ab232-f2b6-11ee-9bcd-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.4827202136317889, "uncertainty": 0.02837069264930697, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.014752556302783892, "uncertainty": 0.0016514352236616837, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.01574499389359204, "uncertainty": 0.0017607555860249637, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.010574731765858209, "uncertainty": 0.0011887794892527501, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.093755395396729, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Viking 7B", "scenario": "Angry Tweets", "executed": "2024-04-04-15-23", "scoring_id": "b10d3202-f2b6-11ee-9bcd-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4140625, "uncertainty": 0.02986148649273125, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.048780487804878044, "uncertainty": 0.005711117803697093, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.3984375, "uncertainty": 0.029500894957724687, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.5, "uncertainty": 0.030770477653893638, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2719926586806028, "uncertainty": 0.024371775571690377, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.021624987495154662, "uncertainty": 0.0026040867429020145, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 1.5561561943983406, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Viking 7B", "scenario": "HyggeSwag", "executed": "2024-04-04-15-29", "scoring_id": "b1123676-f2b6-11ee-9bcd-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.24193548387096775, "uncertainty": 0.03260145244886115, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.27586206896551724, "uncertainty": 0.03550949507906822, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.27419354838709675, "uncertainty": 0.035376044146636566, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.2857142857142857, "uncertainty": 0.03627731457907723, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.19629936795683633, "uncertainty": 0.028044288241239418, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.009456058487514723, "uncertainty": 0.0016650033314937588, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 2.317253303040249, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Viking 7B", "scenario": "#twitterhjerne", "executed": "2024-04-04-15-34", "scoring_id": "b115c714-f2b6-11ee-9bcd-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9743589743589743, "uncertainty": 0.005632923181305373, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.6410256410256411, "uncertainty": 0.05188218719623366, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.6794871794871795, "uncertainty": 0.04910278431072114, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.484683012860453, "uncertainty": 0.05631339411509332, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.03956715269448487, "uncertainty": 0.008568035352306103, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.043377839858088484, "uncertainty": 0.009355948104888344, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5038486818472544, "uncertainty": 0.05636295084885821, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.06398296230764015, "uncertainty": 0.013502915297266454, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.07050389786488169, "uncertainty": 0.014775430618234216, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.46301120672470486, "uncertainty": 0.05605781566072405, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.01780002744223364, "uncertainty": 0.003941849469945022, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.019607568435119207, "uncertainty": 0.004334141993897122, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.00991670939942989, "uncertainty": 0.0022136999942140192, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.9160714437435112, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Viking 7B", "scenario": "DaNE", "executed": "2024-04-04-15-35", "scoring_id": "e6a7ed12-f2b6-11ee-9bcd-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.042704626334519574, "uncertainty": 0.0050317043536312195, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 7.182342822265582, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Viking 7B", "scenario": "Da. Gym 2000", "executed": "2024-04-04-16-06", "scoring_id": "e84f6f50-f2b6-11ee-9bcd-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.30303030303030304, "uncertainty": 0.07488930560746875, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6666666666666666, "uncertainty": 0.07879657372611928, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.36363636363636365, "uncertainty": 0.08205263049166141, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.28571428571428575, "uncertainty": 0.0723642003607218, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.19179908010525554, "uncertainty": 0.05496493361527548, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.010403578736548813, "uncertainty": 0.003650570347811642, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 7.673776413182637, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Viking 7B", "scenario": "Da. Cloze Self Test", "executed": "2024-04-04-16-10", "scoring_id": "e85295f4-f2b6-11ee-9bcd-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36, "uncertainty": 0.06547895542019477, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.2666666666666667, "uncertainty": 0.05557627389059743, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.36, "uncertainty": 0.06547895542019477, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.7368421052631577, "uncertainty": 0.055107423430931106, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.2613411652208696, "uncertainty": 0.05486191810402394, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.02507945688196309, "uncertainty": 0.006948748875533685, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 2.3920189055200898, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Sonnet", "scenario": "Da. Cloze Self Test", "executed": "2024-04-03-07-48", "scoring_id": "7501dd1e-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.9, "uncertainty": 0.025577716961013578, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9565217391304348, "uncertainty": 0.011819150874654454, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 1.0334820099361242, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Sonnet", "scenario": "Da. Gym 2000", "executed": "2024-04-03-07-47", "scoring_id": "7507259e-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.696969696969697, "uncertainty": 0.07488930560746873, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7692307692307692, "uncertainty": 0.0629440085977876, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 2.3249743016380253, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Sonnet", "scenario": "DaNE", "executed": "2024-04-03-06-50", "scoring_id": "75096110-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.3489096573208723, "uncertainty": 0.027960727901411762, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 13.253532459621056, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mixtral (@ Groq)", "scenario": "Da. Cloze Self Test", "executed": "2024-04-03-07-42", "scoring_id": "754e203e-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.52, "uncertainty": 0.07093553503854434, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9473684210526316, "uncertainty": 0.014170480310810836, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 2.6117133751232178, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mixtral (@ Groq)", "scenario": "Da. Gym 2000", "executed": "2024-04-03-07-41", "scoring_id": "7552dfd4-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5151515151515151, "uncertainty": 0.08856474402274564, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7272727272727272, "uncertainty": 0.07033082613570979, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 2.598234966453729, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mixtral (@ Groq)", "scenario": "DaNE", "executed": "2024-04-03-06-53", "scoring_id": "75551236-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.09988385598141696, "uncertainty": 0.011065934112925498, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 11.207087789778598, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mixtral (@ Groq)", "scenario": "#twitterhjerne", "executed": "2024-04-03-06-49", "scoring_id": "75af2604-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.44871794871794873, "uncertainty": 0.055773351235951195, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.32051282051282054, "uncertainty": 0.04910278431072115, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.3717948717948718, "uncertainty": 0.052660420004177165, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6279441886605361, "uncertainty": 0.052675489979741426, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.07647668260962644, "uncertainty": 0.01592415338269922, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.09848477867085394, "uncertainty": 0.020018043244017396, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6520564861786671, "uncertainty": 0.05115327105198526, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.12134370614254432, "uncertainty": 0.02403896280875631, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.15740538997812237, "uncertainty": 0.0299032039158603, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6004386972158383, "uncertainty": 0.054091813317738636, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.03315955186128438, "uncertainty": 0.007228412190053706, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.04133995255357295, "uncertainty": 0.008935401017106657, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.003544722783725518, "uncertainty": 0.00079637851373353, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 2.542503722412034, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Sonnet", "scenario": "#twitterhjerne", "executed": "2024-04-03-06-46", "scoring_id": "95803892-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.3076923076923077, "uncertainty": 0.04802808186165631, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.20512820512820512, "uncertainty": 0.036762235499045566, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.16666666666666666, "uncertainty": 0.031314605843441035, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6314033340185116, "uncertainty": 0.05247322049786528, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.09579951481042091, "uncertainty": 0.01953023600289144, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.13801780028653937, "uncertainty": 0.02682333940950082, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6583028030701172, "uncertainty": 0.050716183731699664, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.14650739663964865, "uncertainty": 0.028192835609611843, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.20841286610981669, "uncertainty": 0.037196553270613074, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6022164156803718, "uncertainty": 0.05401058639608366, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.04604544375866975, "uncertainty": 0.009903616060633249, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.0646180433536013, "uncertainty": 0.013627689743711084, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.003969450917793438, "uncertainty": 0.0008914203435426711, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 2.763885706501941, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mixtral (@ Groq)", "scenario": "HyggeSwag", "executed": "2024-04-03-06-44", "scoring_id": "b4f19720-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6129032258064516, "uncertainty": 0.04217379380618634, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8148148148148148, "uncertainty": 0.026822321753254632, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 2.596087326389557, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Sonnet", "scenario": "HyggeSwag", "executed": "2024-04-03-06-44", "scoring_id": "b4f486ce-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6854838709677419, "uncertainty": 0.038324047825522956, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7500000000000001, "uncertainty": 0.033329782769527194, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 1.1736885368478513, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mixtral (@ Groq)", "scenario": "Angry Tweets", "executed": "2024-04-03-06-34", "scoring_id": "b4f6d622-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.51171875, "uncertainty": 0.030753574925690204, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4380952380952381, "uncertainty": 0.030298803211852094, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 2.2632945096447656, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Sonnet", "scenario": "Angry Tweets", "executed": "2024-04-03-06-39", "scoring_id": "b4f952bc-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 1.0821982733323239, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Sonnet", "scenario": "Nordjylland News", "executed": "2024-04-03-06-34", "scoring_id": "b4fbb228-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7286878804365794, "uncertainty": 0.02246258257088264, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.2383694059529876, "uncertainty": 0.0206273691615988, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.3202865615201117, "uncertainty": 0.024735091393696906, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.016242324468136456, "uncertainty": 0.0018154540526940865, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.9816170237865299, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mixtral (@ Groq)", "scenario": "Nordjylland News", "executed": "2024-04-03-06-34", "scoring_id": "b91872ce-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7089939326047897, "uncertainty": 0.02344193776254744, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.1936293000637752, "uncertainty": 0.017740046771299034, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.2700287144608583, "uncertainty": 0.022395701566791843, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.012945940676533306, "uncertainty": 0.001451855845386322, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.0003073673431451122, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mixtral (@ Groq)", "scenario": "Citizenship Test", "executed": "2024-04-03-06-34", "scoring_id": "bd983956-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6132231404958678, "uncertainty": 0.018937408755000752, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6666666666666667, "uncertainty": 0.017743080454379223, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.00042940743636986443, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Sonnet", "scenario": "Citizenship Test", "executed": "2024-04-03-06-34", "scoring_id": "bd9c3880-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.9305785123966942, "uncertainty": 0.00515808472620485, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.949748743718593, "uncertainty": 0.0038106335512864647, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.00043211258670761566, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Haiku", "scenario": "Da. Cloze Self Test", "executed": "2024-04-02-23-07", "scoring_id": "bda54b5a-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.76, "uncertainty": 0.05183750637432087, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 1.0, "uncertainty": 0.0, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 1.183950956184417, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Haiku", "scenario": "Da. Gym 2000", "executed": "2024-04-02-23-06", "scoring_id": "bda889fa-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.696969696969697, "uncertainty": 0.07488930560746873, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8333333333333333, "uncertainty": 0.04924785857882458, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 0.771822692346618, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Haiku", "scenario": "DaNE", "executed": "2024-04-02-22-42", "scoring_id": "bdaa8b9c-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.3024251069900143, "uncertainty": 0.025965872087552494, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 5.74013927904889, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Haiku", "scenario": "#twitterhjerne", "executed": "2024-04-02-22-40", "scoring_id": "bdde9cac-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.23076923076923078, "uncertainty": 0.040023401551380254, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.2564102564102564, "uncertainty": 0.042988097962593605, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.21794871794871795, "uncertainty": 0.038429877230353085, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6452031601952691, "uncertainty": 0.05161259257130762, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.10128461782946127, "uncertainty": 0.02052320176794845, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.13441503139927113, "uncertainty": 0.026232337420045288, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6751188689317459, "uncertainty": 0.04945203646289577, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.15439798996450463, "uncertainty": 0.029436562610027455, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.20185133416387044, "uncertainty": 0.036324099978122644, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6138989413395907, "uncertainty": 0.053441337996506105, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.04858245872648112, "uncertainty": 0.010421496587834459, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.06309541081458524, "uncertainty": 0.013328233255970674, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.003902455178411821, "uncertainty": 0.0008764340450620058, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 1.2272583341273742, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Haiku", "scenario": "HyggeSwag", "executed": "2024-04-02-22-37", "scoring_id": "db5ad1ec-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6451612903225806, "uncertainty": 0.04069401156737279, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8666666666666667, "uncertainty": 0.020541021677219724, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 1.3213793574306634, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Haiku", "scenario": "Angry Tweets", "executed": "2024-04-02-22-32", "scoring_id": "db5df304-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 1.070625418498821, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Haiku", "scenario": "Nordjylland News", "executed": "2024-04-02-22-25", "scoring_id": "db604aa0-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7302642923593521, "uncertainty": 0.02238037987000363, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.24178189731552996, "uncertainty": 0.020828925966975567, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.32310696269766603, "uncertainty": 0.024849365822393634, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.01616319949583461, "uncertainty": 0.0018067553217666359, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.3876348469685764, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Haiku", "scenario": "Citizenship Test", "executed": "2024-04-02-22-19", "scoring_id": "df6b54dc-f264-11ee-82c5-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.8925619834710744, "uncertainty": 0.007656634267520519, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9049999999999999, "uncertainty": 0.006864576039293647, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.5690587842929339, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B", "scenario": "Da. Cloze Self Test", "executed": "2024-03-06-17-08", "scoring_id": "4e298e3a-dc70-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.46, "uncertainty": 0.07059449881239752, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5714285714285715, "uncertainty": 0.0695992298258873, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.16, "uncertainty": 0.038196057328446956, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.26666666666666666, "uncertainty": 0.055576273890597425, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.25, "uncertainty": 0.05328691033544497, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.025, "uncertainty": 0.006927298343607846, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 4.607447621499887, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Qwen1.5 7B chat", "scenario": "Da. Cloze Self Test", "executed": "2024-03-06-17-08", "scoring_id": "4e39ff90-dc70-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4, "uncertainty": 0.06820724522936956, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5714285714285714, "uncertainty": 0.0695992298258873, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.18, "uncertainty": 0.04194745581606228, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4444444444444444, "uncertainty": 0.07017206299317855, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.3862274293115594, "uncertainty": 0.0673705134620833, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03895197870861962, "uncertainty": 0.01063883028277079, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.261060108219972, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Qwen1.5 7B chat", "scenario": "Da. Gym 2000", "executed": "2024-03-06-17-03", "scoring_id": "4e47a370-dc70-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.42424242424242425, "uncertainty": 0.08661110996342036, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6666666666666666, "uncertainty": 0.07879657372611928, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.36363636363636365, "uncertainty": 0.08205263049166141, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.28571428571428575, "uncertainty": 0.0723642003607218, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.2115086494637985, "uncertainty": 0.059135042499208035, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.02181573548180248, "uncertainty": 0.007566767308547291, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 5.402201928332391, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B", "scenario": "Da. Gym 2000", "executed": "2024-03-06-16-57", "scoring_id": "4e4acc76-dc70-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36363636363636365, "uncertainty": 0.08205263049166141, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7692307692307692, "uncertainty": 0.0629440085977876, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.12121212121212122, "uncertainty": 0.03777025848028858, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.25, "uncertainty": 0.06648460908141314, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.024999999999999998, "uncertainty": 0.008642999180583708, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 11.671382573334444, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Qwen1.5 7B chat", "scenario": "DaNE", "executed": "2024-03-06-16-41", "scoring_id": "4e503daa-dc70-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.09567198177676536, "uncertainty": 0.010648905815163317, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 4.5866476022811185, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B", "scenario": "DaNE", "executed": "2024-03-06-16-16", "scoring_id": "50947fc2-dc70-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.12105263157894738, "uncertainty": 0.013095778910648807, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 8.221095915523392, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Qwen1.5 7B chat", "scenario": "#twitterhjerne", "executed": "2024-03-06-16-16", "scoring_id": "54c1d57c-dc70-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.5128205128205128, "uncertainty": 0.056329231813053694, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.2564102564102564, "uncertainty": 0.042988097962593605, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.2692307692307692, "uncertainty": 0.04435927005277979, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6241966227945099, "uncertainty": 0.052888535235184324, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.0874468603298005, "uncertainty": 0.01799209895348203, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.12212061720597801, "uncertainty": 0.02417148242369348, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6479850663588598, "uncertainty": 0.0514286981945527, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.14265327520243867, "uncertainty": 0.027575137477239383, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.19250630393693371, "uncertainty": 0.03504802438866, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5981783171494802, "uncertainty": 0.054193035888748305, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.03630624621930579, "uncertainty": 0.00788859824694964, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.05430115702356816, "uncertainty": 0.011578209062716447, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.003091476362150831, "uncertainty": 0.000694865397505399, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.3416815917432989, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Qwen1.5 7B chat", "scenario": "HyggeSwag", "executed": "2024-03-06-16-10", "scoring_id": "a8a005d8-dc70-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4032258064516129, "uncertainty": 0.04277495534070436, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4444444444444444, "uncertainty": 0.04389107195987121, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.3387096774193548, "uncertainty": 0.03981539086307725, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.6250000000000001, "uncertainty": 0.04166222846190899, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.21736239967235266, "uncertainty": 0.030239620737965007, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.015305450834808236, "uncertainty": 0.00267903798621734, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 2.6325344367745154, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Qwen1.5 7B chat", "scenario": "Angry Tweets", "executed": "2024-03-06-16-00", "scoring_id": "a8a7e3b6-dc70-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6640625, "uncertainty": 0.027457542926020814, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7007299270072994, "uncertainty": 0.025811199327769263, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.46484375, "uncertainty": 0.030618353100062744, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.6147186147186147, "uncertainty": 0.029150675331414917, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.30443123466318434, "uncertainty": 0.026062946343980393, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.028727646919493945, "uncertainty": 0.0034342769145403883, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.7297808128475936, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Qwen1.5 7B chat", "scenario": "Nordjylland News", "executed": "2024-03-06-15-53", "scoring_id": "a8b0974a-dc70-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7038616601626079, "uncertainty": 0.023682682510043667, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.18423687560432755, "uncertainty": 0.017076134844415114, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.2571810738788693, "uncertainty": 0.021705555843448025, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.009724231538518022, "uncertainty": 0.0010941084929459912, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.7385628691699822, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Qwen1.5 7B chat", "scenario": "Citizenship Test", "executed": "2024-03-06-15-40", "scoring_id": "b227f75a-dc70-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5487603305785124, "uncertainty": 0.019771131153019653, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6180555555555555, "uncertainty": 0.01884817248788765, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.5140495867768595, "uncertainty": 0.019945205060298322, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.5732899022801303, "uncertainty": 0.019532091410017646, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.2200586320467417, "uncertainty": 0.01370382804145985, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.015690714966393408, "uncertainty": 0.0012331498392030306, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.7768002968264189, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B", "scenario": "#twitterhjerne", "executed": "2024-03-06-15-38", "scoring_id": "b22f1ecc-dc70-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9871794871794872, "uncertainty": 0.002853520295792841, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.4358974358974359, "uncertainty": 0.05543982288968968, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5256410256410257, "uncertainty": 0.05621805569763319, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5040703434528958, "uncertainty": 0.05636255507996961, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.0591488902911329, "uncertainty": 0.012547203698868853, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.06575721818403232, "uncertainty": 0.013851047846809437, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5264058086352471, "uncertainty": 0.056209081161978314, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.0915944317974531, "uncertainty": 0.018759804428723024, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.1055573985745847, "uncertainty": 0.02128730098366965, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.4783361378388527, "uncertainty": 0.05626047454912899, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.027386705839181014, "uncertainty": 0.006005642061627873, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.028948993432818905, "uncertainty": 0.0063380397201134005, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0048937962915843874, "uncertainty": 0.0010979808542718112, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 1.927991421961894, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B", "scenario": "HyggeSwag", "executed": "2024-03-06-15-25", "scoring_id": "1ecd1638-dc71-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.33064516129032256, "uncertainty": 0.03934139811470728, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.19999999999999998, "uncertainty": 0.028441414629996546, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.25806451612903225, "uncertainty": 0.03403499149271179, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.25, "uncertainty": 0.0333297827695272, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.025, "uncertainty": 0.004332871760038536, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 4.80143754376613, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B instruct", "scenario": "Da. Cloze Self Test", "executed": "2024-03-06-15-22", "scoring_id": "1ed49dc2-dc71-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36, "uncertainty": 0.06547895542019477, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4, "uncertainty": 0.06820724522936956, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.14, "uncertainty": 0.03421730135673373, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4444444444444445, "uncertainty": 0.07017206299317856, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.25, "uncertainty": 0.05328691033544497, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.025, "uncertainty": 0.006927298343607846, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 3.2145461150200574, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B instruct", "scenario": "Da. Gym 2000", "executed": "2024-03-06-15-14", "scoring_id": "1edf1dce-dc71-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.30303030303030304, "uncertainty": 0.07488930560746875, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8571428571428571, "uncertainty": 0.04341852021643309, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.24242424242424243, "uncertainty": 0.06512113531084239, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.6956521739130436, "uncertainty": 0.07507272808688868, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.25, "uncertainty": 0.06648460908141314, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.024999999999999998, "uncertainty": 0.008642999180583708, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 9.595401177939493, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B", "scenario": "Angry Tweets", "executed": "2024-03-06-15-01", "scoring_id": "1ee1cd26-dc71-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.08571428571428573, "uncertainty": 0.009645602791098088, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.34375, "uncertainty": 0.02776554819550559, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.6787878787878787, "uncertainty": 0.026836151383436205, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.3333333333333333, "uncertainty": 0.027351535692349903, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.03333333333333334, "uncertainty": 0.003965972675390736, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 3.2243851612304297, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B instruct", "scenario": "DaNE", "executed": "2024-03-06-14-33", "scoring_id": "1ee970e4-dc71-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 8.307186481136569, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B", "scenario": "Nordjylland News", "executed": "2024-03-06-14-37", "scoring_id": "20497600-dc71-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.6092342488964398, "uncertainty": 0.027048908728806186, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.14578053319598305, "uncertainty": 0.014148745820491958, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.17576922434633604, "uncertainty": 0.016460408488487933, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.011296451178010708, "uncertainty": 0.0012689866950025554, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.9715538881532848, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B", "scenario": "Citizenship Test", "executed": "2024-03-06-13-59", "scoring_id": "2f747daa-dc71-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5371900826446281, "uncertainty": 0.01985053328616431, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5914634146341463, "uncertainty": 0.01929302719469615, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.3669421487603306, "uncertainty": 0.018547378496586886, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.3333333333333333, "uncertainty": 0.017743080454379227, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.03333333333333333, "uncertainty": 0.0025727466658849877, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 2.79245991069912, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B instruct", "scenario": "#twitterhjerne", "executed": "2024-03-06-13-57", "scoring_id": "2f832030-dc71-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.3974358974358974, "uncertainty": 0.05399453338922318, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.1794871794871795, "uncertainty": 0.03320459980558954, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.15384615384615385, "uncertainty": 0.029350494471012185, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6278241350355311, "uncertainty": 0.052682413093712986, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.10397437042358562, "uncertainty": 0.021005168881819736, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.1494702313449325, "uncertainty": 0.028663133823419503, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6542547024213351, "uncertainty": 0.051001456738807883, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.15383789514882049, "uncertainty": 0.029349205345111398, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.22478623065787418, "uncertainty": 0.039288968686631204, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5979697398650341, "uncertainty": 0.05420226012601589, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.052289976229981154, "uncertainty": 0.01117309173679788, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.07350275708180806, "uncertainty": 0.015354200485717359, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0026324929121750384, "uncertainty": 0.0005919729632571599, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.5548697807564914, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B instruct", "scenario": "HyggeSwag", "executed": "2024-03-06-13-46", "scoring_id": "7aaaa1a0-dc71-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3064516129032258, "uncertainty": 0.0377806902847086, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.47058823529411764, "uncertainty": 0.044285939735288736, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.20967741935483872, "uncertainty": 0.029456915191382348, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.6341463414634146, "uncertainty": 0.04124089718061664, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.25, "uncertainty": 0.0333297827695272, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.025, "uncertainty": 0.004332871760038536, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 4.527965445782625, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B instruct", "scenario": "Angry Tweets", "executed": "2024-03-06-13-29", "scoring_id": "7ab25ada-dc71-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.515625, "uncertainty": 0.03074042835930976, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.3835616438356165, "uncertainty": 0.029101746552002993, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.31640625, "uncertainty": 0.026621796920406636, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.6136363636363636, "uncertainty": 0.029181093477556156, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.3333333333333333, "uncertainty": 0.027351535692349903, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.03333333333333334, "uncertainty": 0.003965972675390736, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 1.7121781707617174, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B instruct", "scenario": "Nordjylland News", "executed": "2024-03-06-13-18", "scoring_id": "7abaf1e0-dc71-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.722453462878863, "uncertainty": 0.02278214628540863, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.2231711470645674, "uncertainty": 0.019697555795615603, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.30086280817666244, "uncertainty": 0.02389900700471013, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.01273055349670661, "uncertainty": 0.001428012237234664, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.5859440607100259, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Gemma 7B instruct", "scenario": "Citizenship Test", "executed": "2024-03-06-12-59", "scoring_id": "82cf697e-dc71-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.45289256198347105, "uncertainty": 0.01978378314126798, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5101449275362318, "uncertainty": 0.019952748016448228, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.32892561983471075, "uncertainty": 0.017624219629916036, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.6403940886699507, "uncertainty": 0.018387203057688, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.3333333333333333, "uncertainty": 0.017743080454379227, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.03333333333333333, "uncertainty": 0.0025727466658849877, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 1.465927925624804, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Phi-2", "scenario": "DaNE", "executed": "2024-03-05-21-33", "scoring_id": "0028beac-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 2.8254792384609573, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Phi-2", "scenario": "Da. Cloze Self Test", "executed": "2024-03-05-21-50", "scoring_id": "00178128-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.32, "uncertainty": 0.061841235674628396, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.3, "uncertainty": 0.059681339575698364, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.35294117647058826, "uncertainty": 0.06490308802102639, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.29130679251847913, "uncertainty": 0.05867162940092757, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03169804285582426, "uncertainty": 0.008722932778308485, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.2988382608199027, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Phi-2", "scenario": "Da. Gym 2000", "executed": "2024-03-05-21-47", "scoring_id": "00231808-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.2727272727272727, "uncertainty": 0.07033082613570978, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.2236389790992916, "uncertainty": 0.06156460125630404, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.021679641734424656, "uncertainty": 0.007520609509357195, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 3.234881520666408, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Phi-2", "scenario": "#twitterhjerne", "executed": "2024-03-05-21-20", "scoring_id": "01fd5f9e-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 1.0, "uncertainty": 0.0, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.9871794871794872, "uncertainty": 0.002853520295792841, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.9871794871794872, "uncertainty": 0.002853520295792841, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.45713511920000754, "uncertainty": 0.055952021278979434, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.00033226682510345833, "uncertainty": 7.488970193919723e-05, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.00033226682510345833, "uncertainty": 7.488970193919723e-05, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.47455540452248013, "uncertainty": 0.05622031818572606, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.0012508009909891042, "uncertainty": 0.0002816593072048444, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.0012508009909891042, "uncertainty": 0.0002816593072048444, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.4417450393621738, "uncertainty": 0.05560114282661723, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0261934658464713, "uncertainty": 0.005751022903779632, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.43813023887177666, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Phi-2", "scenario": "HyggeSwag", "executed": "2024-03-05-21-16", "scoring_id": "73f6278e-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.24193548387096775, "uncertainty": 0.03260145244886115, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.25, "uncertainty": 0.0333297827695272, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.2240538258312395, "uncertainty": 0.03090403388462686, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.0175758957943077, "uncertainty": 0.0030693590143140155, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.2996373913709014, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Phi-2", "scenario": "Angry Tweets", "executed": "2024-03-05-21-10", "scoring_id": "73fe0328-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.31640625, "uncertainty": 0.026621796920406636, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.6136363636363636, "uncertainty": 0.029181093477556156, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.3240252349066228, "uncertainty": 0.02695898561039049, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.024416998351626484, "uncertainty": 0.0029319106278953987, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.7235387145976802, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Phi-2", "scenario": "Nordjylland News", "executed": "2024-03-05-21-04", "scoring_id": "7406af28-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.4453159459431966, "uncertainty": 0.028064859586356385, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.03717506592317174, "uncertainty": 0.004066755117820828, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.6407927043200471, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Phi-2", "scenario": "Citizenship Test", "executed": "2024-03-05-20-55", "scoring_id": "86c37a60-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36363636363636365, "uncertainty": 0.018476265597122166, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.3768595041322314, "uncertainty": 0.01875024658401692, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.04, "uncertainty": 0.0030660043025167293, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.24379877582449214, "uncertainty": 0.014720088879405078, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.01690851498527972, "uncertainty": 0.001327213947055183, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.5516997418148936, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 7B Nordic pre.", "scenario": "Da. Cloze Self Test", "executed": "2024-03-05-20-44", "scoring_id": "86d15612-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4, "uncertainty": 0.06820724522936956, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5, "uncertainty": 0.0710492137805933, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.34, "uncertainty": 0.06377377428946053, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.7142857142857143, "uncertainty": 0.057999358188239425, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.28344314456808534, "uncertainty": 0.05772127034697395, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.030876879180051497, "uncertainty": 0.008504163887215754, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 2.7011485077196267, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 7B Nordic pre.", "scenario": "Da. Gym 2000", "executed": "2024-03-05-20-39", "scoring_id": "86dcbae8-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.2727272727272727, "uncertainty": 0.07033082613570978, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4, "uncertainty": 0.08510029962420883, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.30303030303030304, "uncertainty": 0.07488930560746875, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.25, "uncertainty": 0.06648460908141314, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.1919661359756125, "uncertainty": 0.05500143655133143, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.012934781123198071, "uncertainty": 0.004527148918090923, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 5.216109173090169, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 7B Nordic pre.", "scenario": "DaNE", "executed": "2024-03-05-20-07", "scoring_id": "86e209b2-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.04428044280442804, "uncertainty": 0.005208787709769825, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 6.87124578448811, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 7B Nordic pre.", "scenario": "#twitterhjerne", "executed": "2024-03-05-19-35", "scoring_id": "8995092a-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9871794871794872, "uncertainty": 0.002853520295792841, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.5384615384615384, "uncertainty": 0.05603276217193235, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5512820512820513, "uncertainty": 0.05577335123595119, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.4954162359810793, "uncertainty": 0.05636155329389275, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.04365935849352981, "uncertainty": 0.009413896268482207, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.05089833605273767, "uncertainty": 0.010891702381696839, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5191606187667602, "uncertainty": 0.05628351564846918, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.06942670285880718, "uncertainty": 0.01456654560913511, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.08242215166900992, "uncertainty": 0.01705164625296475, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.46894180851104933, "uncertainty": 0.05614880428444443, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.019167662282988537, "uncertainty": 0.004238804345567018, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.020817325758738695, "uncertainty": 0.0045958739063479675, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0137347987448522, "uncertainty": 0.003054185817960625, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.9299598841410047, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 7B Nordic pre.", "scenario": "HyggeSwag", "executed": "2024-03-05-19-27", "scoring_id": "f1e33100-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.21774193548387097, "uncertainty": 0.03027773190197424, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.3333333333333333, "uncertainty": 0.039501964763884095, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.23387096774193547, "uncertainty": 0.03185000053071364, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.24242424242424246, "uncertainty": 0.03264625187097859, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.2015708720031557, "uncertainty": 0.02860851781776995, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.011747312203288248, "uncertainty": 0.0020636580037520277, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 2.8826161318950567, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 7B Nordic pre.", "scenario": "Angry Tweets", "executed": "2024-03-05-19-14", "scoring_id": "f1eb3d32-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.359375, "uncertainty": 0.028336484792599318, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.07792207792207792, "uncertainty": 0.008843463302788793, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.5309734513274337, "uncertainty": 0.030652398446043314, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.27283088959083085, "uncertainty": 0.024418736609597994, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.021878860260602817, "uncertainty": 0.0026339745168866796, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 1.653426170964849, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 7B Nordic pre.", "scenario": "Nordjylland News", "executed": "2024-03-05-19-02", "scoring_id": "f1f420be-dc72-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.48357770254214605, "uncertainty": 0.028373976128076732, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.0123737439686731, "uncertainty": 0.0013884898157885115, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.012752039552393185, "uncertainty": 0.0014303912416270873, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.008080182173289359, "uncertainty": 0.0009106398798640293, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.0756490106599328, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 7B Nordic pre.", "scenario": "Citizenship Test", "executed": "2024-03-05-18-40", "scoring_id": "0107b70a-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.35537190082644626, "uncertainty": 0.01829084852796569, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.22131147540983606, "uncertainty": 0.013759708824554701, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.32066115702479336, "uncertainty": 0.017392993637791485, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.3591331269349845, "uncertainty": 0.01837658575676459, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.23265220755036395, "uncertainty": 0.014254138076665875, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.011282355229916809, "uncertainty": 0.0008906633663948371, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 1.31507144681484, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Base", "scenario": "Da. Cloze Self Test", "executed": "2024-03-05-17-41", "scoring_id": "0116380c-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.34, "uncertainty": 0.06377377428946053, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.14285714285714288, "uncertainty": 0.03479961491294366, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.24, "uncertainty": 0.05183750637432087, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4444444444444445, "uncertainty": 0.07017206299317856, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.32577329079935863, "uncertainty": 0.06242243353346137, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03475711352738758, "uncertainty": 0.009534536374243317, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.1381363187206444, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny Chat", "scenario": "Da. Cloze Self Test", "executed": "2024-03-05-17-41", "scoring_id": "011be7de-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3, "uncertainty": 0.059681339575698364, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.375, "uncertainty": 0.06660863791930621, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.24, "uncertainty": 0.05183750637432087, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.30769230769230765, "uncertainty": 0.06053897505565345, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.31335794890214597, "uncertainty": 0.06114914379456455, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03302146635879978, "uncertainty": 0.00907470374018299, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 0.4213983654405456, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny Chat", "scenario": "Da. Gym 2000", "executed": "2024-03-05-17-40", "scoring_id": "01244b04-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.24242424242424243, "uncertainty": 0.06512113531084239, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.36363636363636365, "uncertainty": 0.08205263049166141, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.15151515151515152, "uncertainty": 0.04558479471758968, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.22833228637361982, "uncertainty": 0.06247661664511021, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.019487517784081754, "uncertainty": 0.006775315114743779, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 1.3007348385166773, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Base", "scenario": "Da. Gym 2000", "executed": "2024-03-05-17-38", "scoring_id": "012ead6a-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.45454545454545453, "uncertainty": 0.08791353266963721, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5, "uncertainty": 0.0886461454418842, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.36363636363636365, "uncertainty": 0.08205263049166141, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.5454545454545454, "uncertainty": 0.08791353266963722, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.21459367616835345, "uncertainty": 0.05976283083166949, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.01939398801783856, "uncertainty": 0.006743440376239591, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 3.406965996424498, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny Chat", "scenario": "DaNE", "executed": "2024-03-05-17-34", "scoring_id": "01314494-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 1.1753791572891714, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Base", "scenario": "DaNE", "executed": "2024-03-05-17-20", "scoring_id": "0222816a-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.06666666666666668, "uncertainty": 0.007658429993857974, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 3.6596498129217707, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny Chat", "scenario": "#twitterhjerne", "executed": "2024-03-05-17-29", "scoring_id": "0410aa74-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.2948717948717949, "uncertainty": 0.046879262002311135, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.16666666666666666, "uncertainty": 0.031314605843441035, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.16666666666666666, "uncertainty": 0.031314605843441035, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6318056935810633, "uncertainty": 0.05244934268445879, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.09480015735046304, "uncertainty": 0.01934786168493843, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.13240815279842913, "uncertainty": 0.02590058868802086, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6608942326826927, "uncertainty": 0.050529684214087656, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.14610788282636836, "uncertainty": 0.028129116907563465, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.20724362469250648, "uncertainty": 0.037042506761514084, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5991732462858542, "uncertainty": 0.0541487656191652, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.04555757059973855, "uncertainty": 0.009803693844876275, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.05944262625425371, "uncertainty": 0.012605576938169508, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0029697264678991185, "uncertainty": 0.0006675814200631279, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.19016514410255836, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny Chat", "scenario": "HyggeSwag", "executed": "2024-03-05-17-27", "scoring_id": "4328c304-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.20967741935483872, "uncertainty": 0.029456915191382348, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.625, "uncertainty": 0.041662228461909, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.2661290322580645, "uncertainty": 0.03471707861841491, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.2962962962962963, "uncertainty": 0.03706357187722458, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.19706355547729892, "uncertainty": 0.02812669448191016, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.009700535719581266, "uncertainty": 0.0017076288139532664, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 0.4817059088705836, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny Chat", "scenario": "Angry Tweets", "executed": "2024-03-05-17-25", "scoring_id": "432ff5e8-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.55078125, "uncertainty": 0.0304530819798514, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6243386243386244, "uncertainty": 0.028867619807320163, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.359375, "uncertainty": 0.028336484792599318, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.6161137440758293, "uncertainty": 0.02911103790979538, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2684201444690706, "uncertainty": 0.024169689623703194, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.02143579920317347, "uncertainty": 0.0025818037851441, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.30413416008605054, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny Chat", "scenario": "Nordjylland News", "executed": "2024-03-05-17-22", "scoring_id": "4338817c-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.725936070283254, "uncertainty": 0.022604723688676158, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.23646505306127827, "uncertainty": 0.020513739268637882, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.3106634230103275, "uncertainty": 0.02433158454474614, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.015222126639370497, "uncertainty": 0.001703187882779674, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.23633158376343394, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny Chat", "scenario": "Citizenship Test", "executed": "2024-03-05-17-18", "scoring_id": "4b98aa7c-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.35702479338842974, "uncertainty": 0.01832880449271066, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5510688836104513, "uncertainty": 0.019752730253927087, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.3421487603305785, "uncertainty": 0.017971494893559703, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.12322274881516587, "uncertainty": 0.008626243265763086, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.2852349938655632, "uncertainty": 0.016278246590659844, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.022442242120380772, "uncertainty": 0.0017516615848642645, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.2534334786330573, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin 7B Alpha", "scenario": "Da. Cloze Self Test", "executed": "2024-03-05-17-14", "scoring_id": "4d338afa-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.32, "uncertainty": 0.061841235674628396, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.25, "uncertainty": 0.05328691033544497, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.32, "uncertainty": 0.061841235674628396, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4615384615384615, "uncertainty": 0.0706288042315957, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.31398527838416807, "uncertainty": 0.06121558293185193, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.033244660875738435, "uncertainty": 0.009133931581346613, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.136780679159565, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin 7B Alpha", "scenario": "Da. Gym 2000", "executed": "2024-03-05-17-11", "scoring_id": "4d3f2b3a-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.24242424242424243, "uncertainty": 0.06512113531084239, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.2727272727272727, "uncertainty": 0.07033082613570978, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.19231492197526134, "uncertainty": 0.05507758506062379, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.016643737194339175, "uncertainty": 0.005803387703097777, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 3.399262558120289, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin 7B Alpha", "scenario": "DaNE", "executed": "2024-03-05-16-53", "scoring_id": "4d44b00a-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.06593406593406592, "uncertainty": 0.007580216690489435, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 3.6420899635506885, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Base", "scenario": "#twitterhjerne", "executed": "2024-03-05-17-03", "scoring_id": "4e59064e-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.7948717948717948, "uncertainty": 0.036762235499045566, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.46153846153846156, "uncertainty": 0.05603276217193235, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5128205128205128, "uncertainty": 0.056329231813053694, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.4851118423681483, "uncertainty": 0.05631631453317779, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.06395656621844079, "uncertainty": 0.013497725317858953, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.07767957810415209, "uncertainty": 0.0161535555324453, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.508726953695982, "uncertainty": 0.0563491191543976, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.09975073098282802, "uncertainty": 0.020246889393777143, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.12102563773362582, "uncertainty": 0.02398463057985304, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.46105830982709545, "uncertainty": 0.0560243826931916, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.02780845530551515, "uncertainty": 0.006095483375924527, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.03392936498509969, "uncertainty": 0.007390333873106801, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.015504651612643965, "uncertainty": 0.003441558266585645, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.5785411862568416, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Base", "scenario": "HyggeSwag", "executed": "2024-03-05-17-00", "scoring_id": "9e39e890-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.33064516129032256, "uncertainty": 0.03934139811470728, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.43478260869565216, "uncertainty": 0.04368364723416294, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.27419354838709675, "uncertainty": 0.035376044146636566, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.25481176390929433, "uncertainty": 0.033753333895180614, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.019687564978575465, "uncertainty": 0.003430739376195437, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.3175036915725344, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Base", "scenario": "Angry Tweets", "executed": "2024-03-05-16-53", "scoring_id": "9e41dc08-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3984375, "uncertainty": 0.029500894957724687, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.28515625, "uncertainty": 0.02508928289662873, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2639483618246498, "uncertainty": 0.023912307329717056, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.020813081080075787, "uncertainty": 0.0025083966284186812, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.830344636722657, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Base", "scenario": "Nordjylland News", "executed": "2024-03-05-16-46", "scoring_id": "9f599d38-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7003886500994364, "uncertainty": 0.023842198913617392, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.22021351389072805, "uncertainty": 0.019510509795667333, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.2781701494333747, "uncertainty": 0.022813625481229144, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.015180853332858533, "uncertainty": 0.0016986410447815928, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.7544874323999586, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Base", "scenario": "Citizenship Test", "executed": "2024-03-05-16-34", "scoring_id": "a9d48cd2-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.512396694214876, "uncertainty": 0.019948695263953035, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5051194539249146, "uncertainty": 0.01995887289868725, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.5239669421487604, "uncertainty": 0.01991510205377645, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.5783132530120482, "uncertainty": 0.019471285852098553, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.18701204858710277, "uncertainty": 0.012139344394512737, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.009092162302155244, "uncertainty": 0.0007193528668362647, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.6885083934760745, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin 7B Alpha", "scenario": "#twitterhjerne", "executed": "2024-03-05-16-36", "scoring_id": "a9dbc24a-dc73-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9871794871794872, "uncertainty": 0.002853520295792841, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.5512820512820513, "uncertainty": 0.05577335123595119, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5897435897435898, "uncertainty": 0.054550413966325685, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.497993807004303, "uncertainty": 0.056365383063679136, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.05716029373461778, "uncertainty": 0.01215099275188293, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.06598697168066023, "uncertainty": 0.013896024721454242, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.517751429707576, "uncertainty": 0.05629524345670906, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.09259269282176365, "uncertainty": 0.018943421948255837, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.10917548727310031, "uncertainty": 0.0219278849523502, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.4762583206861447, "uncertainty": 0.05623920317078275, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.024337689591291334, "uncertainty": 0.005353752896625877, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.02637692171886484, "uncertainty": 0.005790211347677528, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.009217799293438498, "uncertainty": 0.0020591353274822055, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.5746659348205401, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin 7B Alpha", "scenario": "HyggeSwag", "executed": "2024-03-05-16-33", "scoring_id": "07d89b98-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.29838709677419356, "uncertainty": 0.03721421114641279, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.39999999999999997, "uncertainty": 0.04266212194499482, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.18548387096774194, "uncertainty": 0.026855735474717892, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.24390243902439024, "uncertainty": 0.032781225964079896, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.19914857516606652, "uncertainty": 0.028350476793071448, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.009033158083374406, "uncertainty": 0.0015912189592625949, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.315516022129281, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin 7B Alpha", "scenario": "Angry Tweets", "executed": "2024-03-05-16-26", "scoring_id": "07e7ac28-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3984375, "uncertainty": 0.029500894957724687, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.024096385542168676, "uncertainty": 0.0028943634082919264, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.28515625, "uncertainty": 0.02508928289662873, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.3650834321177239, "uncertainty": 0.028530081601964838, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.03663774589284081, "uncertainty": 0.004344227910353556, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.8313234514844225, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Chat", "scenario": "Da. Cloze Self Test", "executed": "2024-03-05-16-23", "scoring_id": "07f01cdc-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36, "uncertainty": 0.06547895542019477, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.24, "uncertainty": 0.05183750637432087, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4000000000000001, "uncertainty": 0.06820724522936956, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.33197424982483015, "uncertainty": 0.06302558266525908, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.033731893291873136, "uncertainty": 0.009263127263602908, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.1432749324198812, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin 7B Alpha", "scenario": "Nordjylland News", "executed": "2024-03-05-16-19", "scoring_id": "07f8ba9a-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.6044364869594574, "uncertainty": 0.027165383719999082, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.11243099465213452, "uncertainty": 0.011338017595759451, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.14782797155899888, "uncertainty": 0.014313071427123856, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.007403601433810157, "uncertainty": 0.0008349580802755436, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.7563148307967155, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Chat", "scenario": "Da. Gym 2000", "executed": "2024-03-05-16-20", "scoring_id": "23f418e8-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36363636363636365, "uncertainty": 0.08205263049166141, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5, "uncertainty": 0.0886461454418842, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.30303030303030304, "uncertainty": 0.07488930560746875, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.4000000000000001, "uncertainty": 0.08510029962420883, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.19838155605374586, "uncertainty": 0.05638827913597154, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.01715793552546604, "uncertainty": 0.005979551552457953, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 3.429721403090904, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Chat", "scenario": "DaNE", "executed": "2024-03-05-16-02", "scoring_id": "336f83d4-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.0851063829787234, "uncertainty": 0.009583562075997655, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 3.669335506585867, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin 7B Alpha", "scenario": "Citizenship Test", "executed": "2024-03-05-16-08", "scoring_id": "3c8c026c-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.49586776859504134, "uncertainty": 0.019959602150374005, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5414012738853503, "uncertainty": 0.019824107903509424, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.5900826446280992, "uncertainty": 0.01931304192333894, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.6092307692307692, "uncertainty": 0.019008319573739073, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.16161105783235954, "uncertainty": 0.01081827831741144, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.006946622044547011, "uncertainty": 0.0005507922220992768, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.6859905938281147, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin NeuralBeagle 7B", "scenario": "Da. Cloze Self Test", "executed": "2024-03-05-15-59", "scoring_id": "4025897a-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5, "uncertainty": 0.0710492137805933, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7, "uncertainty": 0.05968133957569837, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.38, "uncertainty": 0.06695677906683112, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.6, "uncertainty": 0.06820724522936956, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.2895863556066871, "uncertainty": 0.058466710140134326, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.029166222626333595, "uncertainty": 0.008047191421732984, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.1391276186006143, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin NeuralBeagle 7B", "scenario": "Da. Gym 2000", "executed": "2024-03-05-15-56", "scoring_id": "4031d2c0-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.48484848484848486, "uncertainty": 0.08856474402274564, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5714285714285715, "uncertainty": 0.08683704043286615, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.24242424242424243, "uncertainty": 0.06512113531084239, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.18181818181818182, "uncertainty": 0.052748119601782335, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.26399728429870184, "uncertainty": 0.06889674806272254, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.026372181071891508, "uncertainty": 0.009104558078961053, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 3.408715513667134, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin NeuralBeagle 7B", "scenario": "DaNE", "executed": "2024-03-05-15-38", "scoring_id": "40375a6a-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.105, "uncertainty": 0.011566622550098618, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 3.6472073955742417, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Chat", "scenario": "#twitterhjerne", "executed": "2024-03-05-15-46", "scoring_id": "41483bcc-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.8589743589743589, "uncertainty": 0.027312265688303018, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.32051282051282054, "uncertainty": 0.04910278431072115, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.3717948717948718, "uncertainty": 0.052660420004177165, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5438441188034848, "uncertainty": 0.05593287731442765, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.0748410379292691, "uncertainty": 0.015611175573848507, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.09279005181829379, "uncertainty": 0.018979670443229745, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5659881719411948, "uncertainty": 0.055384516260267413, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.12170309927056319, "uncertainty": 0.024100299202885662, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.1515167136734272, "uncertainty": 0.02898566576556603, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5184972060796542, "uncertainty": 0.05628914837218751, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.032032925231205774, "uncertainty": 0.006990957005010409, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.03823683447407875, "uncertainty": 0.008291431499191659, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.004398168563896503, "uncertainty": 0.0009872724155286698, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.5813366219995376, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Chat", "scenario": "HyggeSwag", "executed": "2024-03-05-15-42", "scoring_id": "abd05a88-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.47580645161290325, "uncertainty": 0.044335663170703025, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6666666666666667, "uncertainty": 0.03950196476388409, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.3064516129032258, "uncertainty": 0.0377806902847086, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.37837837837837834, "uncertainty": 0.04181033377857418, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.1873072361918669, "uncertainty": 0.027059025975595126, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.009504395806473429, "uncertainty": 0.0016734328017715056, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.3314786443708375, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Chat", "scenario": "Angry Tweets", "executed": "2024-03-05-15-36", "scoring_id": "abd81192-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.48046875, "uncertainty": 0.030723525631106325, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.456140350877193, "uncertainty": 0.030533708819991717, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.45703125, "uncertainty": 0.03054322986360304, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2512706907207796, "uncertainty": 0.0231558590264667, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.019726768427174447, "uncertainty": 0.0023801115898617075, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.8291602052031521, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Chat", "scenario": "Nordjylland News", "executed": "2024-03-05-15-29", "scoring_id": "ad2e62c6-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.717373391588529, "uncertainty": 0.023036009921053553, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.2193705201818939, "uncertainty": 0.019456833346418043, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.2836888000361958, "uncertainty": 0.0230883489680948, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.014528294827129381, "uncertainty": 0.0016267010606738428, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.6195555097667966, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Heidrun Mistral 7B Chat", "scenario": "Citizenship Test", "executed": "2024-03-05-15-17", "scoring_id": "b823e61a-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.540495867768595, "uncertainty": 0.019830028339692888, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5483870967741935, "uncertainty": 0.01977402618797102, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.6578512396694215, "uncertainty": 0.017971494893559703, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.7259615384615384, "uncertainty": 0.015884248350101444, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.1469453088154701, "uncertainty": 0.010008618537517546, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.005314452289296435, "uncertainty": 0.0004220713330461586, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.6989513228660881, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin NeuralBeagle 7B", "scenario": "#twitterhjerne", "executed": "2024-03-05-15-21", "scoring_id": "b82b5daa-dc74-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9230769230769231, "uncertainty": 0.016009360620552093, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.32051282051282054, "uncertainty": 0.04910278431072115, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.32051282051282054, "uncertainty": 0.04910278431072115, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5563444214053134, "uncertainty": 0.055650507660747105, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.07438362100246015, "uncertainty": 0.015523433767390765, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.10146577600206386, "uncertainty": 0.020555765313903726, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5809616794188818, "uncertainty": 0.05488841293162352, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.11352278062893364, "uncertainty": 0.022689767506265723, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.1588674168789728, "uncertainty": 0.030128585103257124, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5281467751050607, "uncertainty": 0.056187667784268626, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.03512117356451513, "uncertainty": 0.00764049052664261, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.04642146271156484, "uncertainty": 0.00998055596682278, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.002812524737330536, "uncertainty": 0.0006323428497019442, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.5754189523972738, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin NeuralBeagle 7B", "scenario": "HyggeSwag", "executed": "2024-03-05-15-18", "scoring_id": "223cee98-dc75-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.41935483870967744, "uncertainty": 0.04328363048529651, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5454545454545455, "uncertainty": 0.04407244002582109, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.3548387096774194, "uncertainty": 0.04069401156737279, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.48484848484848486, "uncertainty": 0.044398902544530876, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.1814391411088841, "uncertainty": 0.02640056167096787, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.009294360976928654, "uncertainty": 0.0016367991156956098, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.3140638597176275, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin NeuralBeagle 7B", "scenario": "Angry Tweets", "executed": "2024-03-05-15-11", "scoring_id": "224ca3c4-dc75-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.41796875, "uncertainty": 0.029942243971925433, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.3, "uncertainty": 0.025847201229270655, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.28515625, "uncertainty": 0.02508928289662873, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.36308204083584933, "uncertainty": 0.028463119226656664, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.03758115521189102, "uncertainty": 0.004451726483788463, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.8276725310468009, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin NeuralBeagle 7B", "scenario": "Nordjylland News", "executed": "2024-03-05-15-02", "scoring_id": "22557fee-dc75-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.6986685295899709, "uncertainty": 0.02392018963707047, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.2049583813545503, "uncertainty": 0.01851418044385935, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.26644198630770416, "uncertainty": 0.022206804767882157, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.01434731214006509, "uncertainty": 0.001606731852661183, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.7587719926333133, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Munin NeuralBeagle 7B", "scenario": "Citizenship Test", "executed": "2024-03-05-14-51", "scoring_id": "309253c0-dc75-11ee-a77c-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4677685950413223, "uncertainty": 0.019878018639945153, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4820846905537459, "uncertainty": 0.01993533895994688, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.6380165289256199, "uncertainty": 0.018440054734204545, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.6560509554140128, "uncertainty": 0.01801661571230709, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.17573177839723617, "uncertainty": 0.011565393035054048, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.013257506273138119, "uncertainty": 0.0010444970271596358, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.6915493077520581, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neox Da.", "scenario": "#twitterhjerne", "executed": "2024-01-09-20-33", "scoring_id": "dd218c6a-af2e-11ee-ba77-b83fd2ad0420", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 1.0, "uncertainty": 0.0, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.5769230769230769, "uncertainty": 0.055032177133147855, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.6025641025641025, "uncertainty": 0.05399453338922318, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5022153066264257, "uncertainty": 0.05636518402909613, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.03693361832180852, "uncertainty": 0.008019688980396164, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.04203851012627521, "uncertainty": 0.0090797692725343, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.526331691787793, "uncertainty": 0.05620996244606129, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.06361913573117534, "uncertainty": 0.013431352307160515, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.07367631231727827, "uncertainty": 0.015387571930991382, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.4775005678335826, "uncertainty": 0.0562521545410229, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.01447933329155529, "uncertainty": 0.0032173162097216814, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.016247369628525007, "uncertainty": 0.0036036982049886313, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.037729922214893095, "uncertainty": 0.00818582276525983, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.49494073152518236, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate Mistral 7B", "scenario": "Da. Cloze Self Test", "executed": "2024-01-09-03-33", "scoring_id": "7f9c2462-aecd-11ee-bace-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.26, "uncertainty": 0.054679474925544605, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.3157894736842105, "uncertainty": 0.061405414680180355, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.22, "uncertainty": 0.04876818033899923, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4, "uncertainty": 0.06820724522936956, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.33188866930308203, "uncertainty": 0.06301740723492993, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03238715081488186, "uncertainty": 0.00890622450043932, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.1354805321991444, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate Mistral 7B", "scenario": "Da. Gym 2000", "executed": "2024-01-09-03-26", "scoring_id": "7fcbb0f6-aecd-11ee-bace-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.48484848484848486, "uncertainty": 0.08856474402274564, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9090909090909091, "uncertainty": 0.029304510889879086, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.42424242424242425, "uncertainty": 0.08661110996342036, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.5, "uncertainty": 0.0886461454418842, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.18367188781826196, "uncertainty": 0.05316518016607447, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.013678008713470979, "uncertainty": 0.004783672506373, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 3.38579808073965, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate Mistral 7B", "scenario": "DaNE", "executed": "2024-01-09-03-00", "scoring_id": "86cfd09e-aecd-11ee-bace-b83fd2ad0ed0", "metrics": [{"name": "NER F1", "value": 0.0660377358490566, "uncertainty": 0.007591292635866248, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 3.670518841670855, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate Mistral 7B", "scenario": "#twitterhjerne", "executed": "2024-01-09-01-41", "scoring_id": "1a603bc6-aed0-11ee-bace-b83fd2ad0ed0", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9615384615384616, "uncertainty": 0.008338208656537548, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.3333333333333333, "uncertainty": 0.050103369349505655, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.32051282051282054, "uncertainty": 0.04910278431072115, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5435552594753411, "uncertainty": 0.05593856943624801, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.06686559307785722, "uncertainty": 0.014067805341285662, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.08726139767285576, "uncertainty": 0.017957589075577696, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5680325917708569, "uncertainty": 0.05532273999926476, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.10418579843259912, "uncertainty": 0.02104291560967898, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.13916117158198765, "uncertainty": 0.02700967572745063, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5160958705804287, "uncertainty": 0.05630787766918447, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.03195096929877137, "uncertainty": 0.006973661105106749, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.04115067574067717, "uncertainty": 0.008896246004371815, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.007526544269729549, "uncertainty": 0.0016842011772723886, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.573482433322053, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate Mistral 7B", "scenario": "HyggeSwag", "executed": "2024-01-09-01-34", "scoring_id": "255d620a-aed1-11ee-bace-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.2903225806451613, "uncertainty": 0.036624610410635514, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5833333333333334, "uncertainty": 0.04320527396049822, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.23387096774193547, "uncertainty": 0.03185000053071364, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.4545454545454545, "uncertainty": 0.04407244002582109, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.19930158288767957, "uncertainty": 0.028366838031604336, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.011735579679359662, "uncertainty": 0.002061621418868068, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.3088113791534617, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate Mistral 7B", "scenario": "Angry Tweets", "executed": "2024-01-09-01-17", "scoring_id": "08a4ad5c-aed2-11ee-bace-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.375, "uncertainty": 0.028847322800525287, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.047058823529411764, "uncertainty": 0.005519520974317807, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.28515625, "uncertainty": 0.02508928289662873, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2612766809818015, "uncertainty": 0.023756184430020373, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.020679894588223485, "uncertainty": 0.002492683968571756, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.825288124011422, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate Mistral 7B", "scenario": "Nordjylland News", "executed": "2024-01-09-00-55", "scoring_id": "1d2efe80-aed2-11ee-bace-b83fd2ad0ed0", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.5737822096546491, "uncertainty": 0.027786100221282608, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.08128770971324954, "uncertainty": 0.00848502956109336, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.10618896172110474, "uncertainty": 0.010783854862481275, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.008200587088164563, "uncertainty": 0.0009240973778178193, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.7511084150600558, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate Mistral 7B", "scenario": "Citizenship Test", "executed": "2024-01-09-00-28", "scoring_id": "89d893d6-ae85-11ee-8d44-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.43305785123966944, "uncertainty": 0.019603165102136725, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.459214501510574, "uncertainty": 0.01982814868897121, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.6479338842975206, "uncertainty": 0.018213627772105223, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.7193460490463216, "uncertainty": 0.01611946258951851, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.14994078982895906, "uncertainty": 0.01017678283267016, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.006934291246872521, "uncertainty": 0.0005498213498845211, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.6877670353786511, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate LlaMa 2 7B", "scenario": "Da. Cloze Self Test", "executed": "2024-01-08-17-30", "scoring_id": "25b86fa8-ae75-11ee-98bf-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.34, "uncertainty": 0.06377377428946053, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4, "uncertainty": 0.06820724522936956, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.24, "uncertainty": 0.05183750637432087, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.28571428571428575, "uncertainty": 0.057999358188239425, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.34674731464453495, "uncertainty": 0.06437445686378829, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.036299647815900275, "uncertainty": 0.009941769663773078, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.6223600634653121, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate LlaMa 2 7B", "scenario": "Da. Gym 2000", "executed": "2024-01-08-17-20", "scoring_id": "25e477ce-ae75-11ee-98bf-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.2727272727272727, "uncertainty": 0.07033082613570978, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.2, "uncertainty": 0.0567335330828059, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.30303030303030304, "uncertainty": 0.07488930560746875, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.4, "uncertainty": 0.08510029962420883, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.1901713614060788, "uncertainty": 0.05460822923149631, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.00959883284982948, "uncertainty": 0.0033709275619608916, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 5.134484190888928, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate LlaMa 2 7B", "scenario": "DaNE", "executed": "2024-01-08-16-32", "scoring_id": "25ff76fa-ae75-11ee-98bf-b83fd2ad0ed0", "metrics": [{"name": "NER F1", "value": 0.08480565371024736, "uncertainty": 0.009552836923752469, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 7.3123299428443715, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate LlaMa 2 7B", "scenario": "#twitterhjerne", "executed": "2024-01-08-13-53", "scoring_id": "3a46bb32-ae75-11ee-98bf-b83fd2ad0ed0", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9743589743589743, "uncertainty": 0.005632923181305373, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.34615384615384615, "uncertainty": 0.05102983697800982, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.44871794871794873, "uncertainty": 0.055773351235951195, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5301410114026479, "uncertainty": 0.05616145979960532, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.06781750502697051, "uncertainty": 0.014253522235046624, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.0845206046992643, "uncertainty": 0.017445789004322237, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5548707178005805, "uncertainty": 0.055687460984049426, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.10408273834856181, "uncertainty": 0.021024518574350608, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.13393972288094277, "uncertainty": 0.026153930282597944, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5041899050657566, "uncertainty": 0.056362332408628535, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.0306369177985275, "uncertainty": 0.006695931361346375, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.03643028255443824, "uncertainty": 0.00791452997887043, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.010720615103566207, "uncertainty": 0.0023912121526848723, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 1.164225103154492, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate LlaMa 2 7B", "scenario": "HyggeSwag", "executed": "2024-01-08-13-41", "scoring_id": "4d4c9aca-ae76-11ee-98bf-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.20967741935483872, "uncertainty": 0.029456915191382348, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.2352941176470588, "uncertainty": 0.03198428980881964, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.2903225806451613, "uncertainty": 0.036624610410635514, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.24, "uncertainty": 0.03242321267819606, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.20146938424011276, "uncertainty": 0.02859774845674093, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.011790538351532006, "uncertainty": 0.0020711609729406697, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.822000830370422, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate LlaMa 2 7B", "scenario": "Angry Tweets", "executed": "2024-01-08-13-16", "scoring_id": "4fe8482e-ae76-11ee-98bf-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3828125, "uncertainty": 0.02908020483355036, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.10256410256410255, "uncertainty": 0.01132903845245262, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.2890625, "uncertainty": 0.025293993715981417, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.25, "uncertainty": 0.02307785824042023, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.23042491702785592, "uncertainty": 0.02182602593083428, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.009410916465476352, "uncertainty": 0.0011474127868795856, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 1.2485732840777928, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate LlaMa 2 7B", "scenario": "Nordjylland News", "executed": "2024-01-08-12-41", "scoring_id": "53b1479e-ae76-11ee-98bf-b83fd2ad0ed0", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.5227656143903733, "uncertainty": 0.028345732695411536, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.04197228718761191, "uncertainty": 0.004568668571288732, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.04923080941141753, "uncertainty": 0.005318155383312551, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.00942042752634734, "uncertainty": 0.0010602515756815481, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.4690522755604858, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate LlaMa 2 7B", "scenario": "Citizenship Test", "executed": "2024-01-08-11-52", "scoring_id": "8274cd30-ae76-11ee-98bf-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3685950413223141, "uncertainty": 0.01858228053313399, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.3049645390070922, "uncertainty": 0.01692379833290042, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.39669421487603307, "uncertainty": 0.01910886500953839, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.373015873015873, "uncertainty": 0.018673485750314644, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.22748325586107873, "uncertainty": 0.014031331088222512, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.010178740247738868, "uncertainty": 0.0008044375688334616, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 1.0098038779410017, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B Chat", "scenario": "HyggeSwag", "executed": "2024-01-07-14-46", "scoring_id": "6b3a9d86-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3467741935483871, "uncertainty": 0.04026626201396575, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.3333333333333333, "uncertainty": 0.039501964763884095, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.27419354838709675, "uncertainty": 0.035376044146636566, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.2962962962962963, "uncertainty": 0.03706357187722458, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.19700270648793006, "uncertainty": 0.028120140432442292, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.012178742079924471, "uncertainty": 0.002138513578315767, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 3.4328467887751155, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate 7B Baseline", "scenario": "Da. Cloze Self Test", "executed": "2024-01-08-05-29", "scoring_id": "cb791718-af9b-11ee-822b-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.32, "uncertainty": 0.061841235674628396, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.2, "uncertainty": 0.04547149681957972, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4444444444444445, "uncertainty": 0.07017206299317856, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.3642421749691995, "uncertainty": 0.06581141257965026, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03671352279498981, "uncertainty": 0.010050803678465605, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.6586999740358441, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate 7B Baseline", "scenario": "Da. Gym 2000", "executed": "2024-01-08-05-19", "scoring_id": "cb96a81e-af9b-11ee-822b-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.18181818181818182, "uncertainty": 0.052748119601782335, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.39999999999999997, "uncertainty": 0.08510029962420884, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.20831722048044704, "uncertainty": 0.05847849917159444, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.014653749147053339, "uncertainty": 0.005119852727130447, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 5.142786638966451, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate 7B Baseline", "scenario": "DaNE", "executed": "2024-01-08-04-33", "scoring_id": "cbaabd5e-af9b-11ee-822b-b83fd2ad0420", "metrics": [{"name": "NER F1", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 7.275510988180031, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate 7B Baseline", "scenario": "#twitterhjerne", "executed": "2024-01-08-01-55", "scoring_id": "d114f174-af9b-11ee-822b-b83fd2ad0420", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 1.0, "uncertainty": 0.0, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 1.0, "uncertainty": 0.0, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 1.0, "uncertainty": 0.0, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.4030611566498748, "uncertainty": 0.05424756297161211, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.4298423433151001, "uncertainty": 0.05525652916735675, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.37888149993541914, "uncertainty": 0.05305878624626828, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.016985263890371874, "uncertainty": 0.0037645387593898544, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 1.1787720772151191, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate 7B Baseline", "scenario": "HyggeSwag", "executed": "2024-01-08-01-43", "scoring_id": "10034894-af9d-11ee-822b-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.24193548387096775, "uncertainty": 0.03260145244886115, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.20161290322580644, "uncertainty": 0.028612976883308983, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.45614035087719296, "uncertainty": 0.044097761218408, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.20967259174891123, "uncertainty": 0.02945641690680539, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.01473564230460221, "uncertainty": 0.0025807922994344657, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.8270838551313406, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate 7B Baseline", "scenario": "Angry Tweets", "executed": "2024-01-08-01-19", "scoring_id": "1023ff62-af9d-11ee-822b-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.28515625, "uncertainty": 0.02508928289662873, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.24351515235957064, "uncertainty": 0.02267359852737814, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.013109557073161854, "uncertainty": 0.0015923964148319236, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 1.241847463641534, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate 7B Baseline", "scenario": "Nordjylland News", "executed": "2024-01-08-00-43", "scoring_id": "10707e6e-af9d-11ee-822b-b83fd2ad0420", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.4354377268751462, "uncertainty": 0.027931023690371034, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.01834705979252855, "uncertainty": 0.0020463192700009205, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.4961406651170304, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Danoliterate 7B Baseline", "scenario": "Citizenship Test", "executed": "2024-01-07-23-55", "scoring_id": "2553f75c-af9d-11ee-822b-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36363636363636365, "uncertainty": 0.018476265597122166, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.32066115702479336, "uncertainty": 0.017392993637791485, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.36260623229461764, "uncertainty": 0.018453749142417864, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.23140337770889227, "uncertainty": 0.014200698310047, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.012530798703794916, "uncertainty": 0.0009879702066481729, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 1.0050624376555428, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 1106", "scenario": "HyggeSwag", "executed": "2024-01-07-21-57", "scoring_id": "6a060360-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.7983870967741935, "uncertainty": 0.028612976883308994, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9230769230769231, "uncertainty": 0.012621929569525087, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 0.612768997691737, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 1106", "scenario": "Da. Gym 2000", "executed": "2024-01-07-21-57", "scoring_id": "6a085278-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.7878787878787878, "uncertainty": 0.059260233132866574, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9090909090909091, "uncertainty": 0.029304510889879086, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 0.7233103357580011, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 1106", "scenario": "Citizenship Test", "executed": "2024-01-07-21-51", "scoring_id": "6a0a5942-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.9768595041322314, "uncertainty": 0.0018048715649420142, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9824561403508772, "uncertainty": 0.0013761946058798247, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.5710527403984403, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4", "scenario": "HyggeSwag", "executed": "2024-01-07-21-49", "scoring_id": "6a27fa06-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.7983870967741935, "uncertainty": 0.028612976883308994, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9333333333333333, "uncertainty": 0.011060550133887542, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 0.7774393582254678, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4", "scenario": "Da. Gym 2000", "executed": "2024-01-07-21-48", "scoring_id": "6a339a1e-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.7575757575757576, "uncertainty": 0.06512113531084239, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.923076923076923, "uncertainty": 0.02517760343911506, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 1.226061771574402, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4", "scenario": "Citizenship Test", "executed": "2024-01-07-21-41", "scoring_id": "6a3581f8-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.9652892561983472, "uncertainty": 0.002675241101335371, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9702970297029703, "uncertainty": 0.0023011563024354213, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.678844494003156, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo Instruct", "scenario": "HyggeSwag", "executed": "2024-01-07-21-40", "scoring_id": "6a3e9f72-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6532258064516129, "uncertainty": 0.04026626201396575, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7619047619047619, "uncertainty": 0.03224650184806865, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 0.43039307275771976, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo Instruct", "scenario": "Da. Gym 2000", "executed": "2024-01-07-21-39", "scoring_id": "6a444580-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5757575757575758, "uncertainty": 0.08661110996342036, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9090909090909091, "uncertainty": 0.029304510889879086, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 0.3955072505456029, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo Instruct", "scenario": "Citizenship Test", "executed": "2024-01-07-21-36", "scoring_id": "6a46320a-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.7735537190082644, "uncertainty": 0.013986118595337486, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8, "uncertainty": 0.01277501792715304, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.32467054362785963, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 002", "scenario": "HyggeSwag", "executed": "2024-01-07-21-32", "scoring_id": "6a4c3600-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.33064516129032256, "uncertainty": 0.03934139811470728, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4666666666666667, "uncertainty": 0.044242200535550176, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 1.6553197875806702, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 002", "scenario": "Da. Gym 2000", "executed": "2024-01-07-21-31", "scoring_id": "6a5175b6-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3939393939393939, "uncertainty": 0.0846574759040951, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5714285714285714, "uncertainty": 0.08683704043286615, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 1.6866399414244702, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 002", "scenario": "Citizenship Test", "executed": "2024-01-07-21-16", "scoring_id": "6a53945e-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.48760330578512395, "uncertainty": 0.019948695263953035, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.546583850931677, "uncertainty": 0.019787699925743397, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 1.5534615483504435, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Babbage 002", "scenario": "HyggeSwag", "executed": "2024-01-07-21-13", "scoring_id": "6a6ef820-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.2661290322580645, "uncertainty": 0.03471707861841491, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.35294117647058826, "uncertainty": 0.040595444757348005, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 0.9306485024825369, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Babbage 002", "scenario": "Da. Gym 2000", "executed": "2024-01-07-21-13", "scoring_id": "6a71b100-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.24242424242424243, "uncertainty": 0.06512113531084239, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.25, "uncertainty": 0.06648460908141314, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 0.935084120539779, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Babbage 002", "scenario": "Citizenship Test", "executed": "2024-01-07-21-04", "scoring_id": "6a73c526-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4033057851239669, "uncertainty": 0.019214443670093374, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.29292929292929293, "uncertainty": 0.016537398219646383, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.8591080542511407, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Google Gemini Pro", "scenario": "HyggeSwag", "executed": "2024-01-07-21-01", "scoring_id": "6a7daf3c-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6451612903225806, "uncertainty": 0.04069401156737279, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7586206896551724, "uncertainty": 0.03255037048914587, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 1.1080724214421465, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Google Gemini Pro", "scenario": "Da. Gym 2000", "executed": "2024-01-07-21-01", "scoring_id": "6a869426-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6060606060606061, "uncertainty": 0.0846574759040951, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7692307692307692, "uncertainty": 0.0629440085977876, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 0.5110746756351242, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Google Gemini Pro", "scenario": "Citizenship Test", "executed": "2024-01-07-20-53", "scoring_id": "6a88a9c8-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.8462809917355372, "uncertainty": 0.01038684607641758, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.855036855036855, "uncertainty": 0.009896553408121475, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.8081370703502719, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo", "scenario": "HyggeSwag", "executed": "2024-01-07-20-51", "scoring_id": "6a91d62e-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5967741935483871, "uncertainty": 0.04277495534070436, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7368421052631577, "uncertainty": 0.03446847340892934, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 0.5157071095403104, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo", "scenario": "Da. Gym 2000", "executed": "2024-01-07-20-51", "scoring_id": "6a9464ac-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.45454545454545453, "uncertainty": 0.08791353266963721, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7272727272727273, "uncertainty": 0.07033082613570978, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 0.5079484991517595, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo", "scenario": "Citizenship Test", "executed": "2024-01-07-20-45", "scoring_id": "6a965140-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.8214876033057851, "uncertainty": 0.011708760710639074, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8585607940446649, "uncertainty": 0.009695772076952033, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.5709357662445842, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "SOLAR 10.7B Instruct", "scenario": "HyggeSwag", "executed": "2024-01-07-17-23", "scoring_id": "6a99449a-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5725806451612904, "uncertainty": 0.04350328566137039, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7692307692307693, "uncertainty": 0.03155482392381273, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.5483870967741935, "uncertainty": 0.04402352160470329, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.7142857142857143, "uncertainty": 0.03627731457907723, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.20451077851715527, "uncertainty": 0.028918896206929903, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.020901662584662722, "uncertainty": 0.0036377961316117124, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.3772739364743052, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "SOLAR 10.7B Instruct", "scenario": "Da. Gym 2000", "executed": "2024-01-07-17-21", "scoring_id": "6a9c5f0e-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5151515151515151, "uncertainty": 0.08856474402274564, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7692307692307692, "uncertainty": 0.0629440085977876, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.42424242424242425, "uncertainty": 0.08661110996342036, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.6153846153846153, "uncertainty": 0.08392534479705013, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.2568308967405227, "uncertainty": 0.06767912908887416, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.024719040951433128, "uncertainty": 0.008548328630997217, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 4.082921876176966, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "SOLAR 10.7B Instruct", "scenario": "Citizenship Test", "executed": "2024-01-07-17-14", "scoring_id": "6a9ead68-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6595041322314049, "uncertainty": 0.017929612449703182, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7083333333333334, "uncertainty": 0.016495520109930682, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.7520661157024794, "uncertainty": 0.01488789996462323, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.8057553956834532, "uncertainty": 0.012496653321421898, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.14827847395836805, "uncertainty": 0.010083638479843565, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.014678283867917455, "uncertainty": 0.0011547683510559153, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.6213795700264433, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neox Da.", "scenario": "HyggeSwag", "executed": "2024-01-07-17-11", "scoring_id": "6aa4d3f0-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.23387096774193547, "uncertainty": 0.03185000053071364, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.06896551724137931, "uncertainty": 0.011413766275414784, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.3387096774193548, "uncertainty": 0.03981539086307725, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.7, "uncertainty": 0.037329356701870466, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.1915627772639365, "uncertainty": 0.02752888599668322, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.008723885265623633, "uncertainty": 0.001537219192311555, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 0.5718450172834338, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neox Da.", "scenario": "Da. Gym 2000", "executed": "2024-01-07-17-10", "scoring_id": "6aa83450-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.30303030303030304, "uncertainty": 0.07488930560746875, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.6666666666666666, "uncertainty": 0.07879657372611928, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.23120084859749235, "uncertainty": 0.06302635140158097, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.019104823231668545, "uncertainty": 0.006644854414515488, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 1.3254646999394577, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neox Da.", "scenario": "Citizenship Test", "executed": "2024-01-07-17-07", "scoring_id": "6aaabc52-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3504132231404959, "uncertainty": 0.018174362980989733, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.019138755980861243, "uncertainty": 0.0014988660258844655, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.34049586776859503, "uncertainty": 0.017929612449703182, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.6275229357798164, "uncertainty": 0.018662536710094418, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.3016754926956442, "uncertainty": 0.016820498008707985, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.026686899858567995, "uncertainty": 0.002073921100771322, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.27251064509753725, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny", "scenario": "HyggeSwag", "executed": "2024-01-07-17-06", "scoring_id": "6ab13780-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.28225806451612906, "uncertainty": 0.03601188807737678, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.2661290322580645, "uncertainty": 0.03471707861841491, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.07142857142857144, "uncertainty": 0.011790127238200101, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.20367949597151253, "uncertainty": 0.028831445772622092, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.01033207446604426, "uncertainty": 0.0018176415170580423, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 0.4736778108711024, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny", "scenario": "Da. Gym 2000", "executed": "2024-01-07-17-05", "scoring_id": "6ab49538-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.2222222222222222, "uncertainty": 0.06128622400920389, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.23598278024060926, "uncertainty": 0.06392979443116856, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.017141688883491997, "uncertainty": 0.005973988337284858, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 1.2489171725218042, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny", "scenario": "Citizenship Test", "executed": "2024-01-07-17-03", "scoring_id": "6ab70714-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3537190082644628, "uncertainty": 0.018252456287763875, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.461111111111111, "uncertainty": 0.01984021399141766, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.36198347107438017, "uncertainty": 0.01844005473420455, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.0857142857142857, "uncertainty": 0.006257151637789243, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.26249736536111173, "uncertainty": 0.015457172746284808, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.019133310672815613, "uncertainty": 0.0014984478911758286, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.23459111592570736, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B Instruct (v. 2)", "scenario": "HyggeSwag", "executed": "2024-01-07-16-59", "scoring_id": "6abd953e-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.20967741935483872, "uncertainty": 0.029456915191382348, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6027397260273973, "uncertainty": 0.042563385564688014, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.23387096774193547, "uncertainty": 0.03185000053071364, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.6419753086419753, "uncertainty": 0.04085662747869494, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.2609897462274313, "uncertainty": 0.034285076308935875, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.0233495620250788, "uncertainty": 0.004053676609468616, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.8061530197399758, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B Instruct (v. 2)", "scenario": "Da. Gym 2000", "executed": "2024-01-07-16-57", "scoring_id": "6ac10624-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36363636363636365, "uncertainty": 0.08205263049166141, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7777777777777778, "uncertainty": 0.06128622400920389, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.3939393939393939, "uncertainty": 0.0846574759040951, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.7777777777777778, "uncertainty": 0.06128622400920389, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.1932263709981573, "uncertainty": 0.05527616937134744, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.018385463818939546, "uncertainty": 0.006399343446362811, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 3.820581339779451, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B Instruct (v. 2)", "scenario": "Citizenship Test", "executed": "2024-01-07-16-47", "scoring_id": "6ac365fe-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4115702479338843, "uncertainty": 0.019336600798008235, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5986696230598669, "uncertainty": 0.019183630061429428, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.49586776859504134, "uncertainty": 0.019959602150374005, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.6914153132250581, "uncertainty": 0.017035500607123652, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.20483023049109772, "uncertainty": 0.013004553634084877, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.010578751964488826, "uncertainty": 0.0008357130864052232, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.9746594549787869, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B (v. 2)", "scenario": "HyggeSwag", "executed": "2024-01-07-16-41", "scoring_id": "6aca6016-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.27419354838709675, "uncertainty": 0.035376044146636566, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5490196078431372, "uncertainty": 0.04401256973692276, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.2903225806451613, "uncertainty": 0.036624610410635514, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.6976744186046512, "uncertainty": 0.03749375238540648, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.19447605653303077, "uncertainty": 0.027846832630830584, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.009947533466372753, "uncertainty": 0.0017506721784804858, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.8198341785652203, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B (v. 2)", "scenario": "Da. Gym 2000", "executed": "2024-01-07-16-39", "scoring_id": "6acdc472-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.18181818181818182, "uncertainty": 0.052748119601782335, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.36363636363636365, "uncertainty": 0.08205263049166141, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.22222222222222224, "uncertainty": 0.061286224009203895, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.1859990879054306, "uncertainty": 0.053685320913223505, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.007272691678089852, "uncertainty": 0.0025600296336124487, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 3.770497488549374, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B (v. 2)", "scenario": "Citizenship Test", "executed": "2024-01-07-16-29", "scoring_id": "6ad030ea-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3933884297520661, "uncertainty": 0.01905345802651987, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4817927170868347, "uncertainty": 0.019934496859626682, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.5074380165289256, "uncertainty": 0.019956548222176133, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.6513994910941475, "uncertainty": 0.018130800002796696, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.20058804428684227, "uncertainty": 0.01280316135360716, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.005449291223441868, "uncertainty": 0.000432721511180318, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.9791964765538054, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Kanelsnegl (v. 0.2)", "scenario": "HyggeSwag", "executed": "2024-01-07-16-25", "scoring_id": "6ad6f024-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.28225806451612906, "uncertainty": 0.03601188807737678, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.1818181818181818, "uncertainty": 0.026443464015492656, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.21774193548387097, "uncertainty": 0.03027773190197424, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.553846153846154, "uncertainty": 0.04392431490194732, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.21708904991320802, "uncertainty": 0.03021214054359737, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.015164885391800966, "uncertainty": 0.0026548125906049247, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.2789266773784953, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Kanelsnegl (v. 0.2)", "scenario": "Da. Gym 2000", "executed": "2024-01-07-16-24", "scoring_id": "6ada41a2-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.30303030303030304, "uncertainty": 0.07488930560746875, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5, "uncertainty": 0.0886461454418842, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.42857142857142855, "uncertainty": 0.08683704043286614, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.2085697932967787, "uncertainty": 0.058530721853080094, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.014973797942529905, "uncertainty": 0.005229974831954288, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 1.7295661220383463, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Kanelsnegl (v. 0.2)", "scenario": "Citizenship Test", "executed": "2024-01-07-16-17", "scoring_id": "6adc99ac-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5256198347107438, "uncertainty": 0.01990855792192387, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5263157894736842, "uncertainty": 0.01990567197790467, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.3487603305785124, "uncertainty": 0.018134661914417406, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.2867383512544803, "uncertainty": 0.01632962428221281, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.23889386977400587, "uncertainty": 0.014517497537299633, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.013997064176726026, "uncertainty": 0.0011019368269175923, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.7060556162795252, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J NorPaca", "scenario": "HyggeSwag", "executed": "2024-01-07-16-13", "scoring_id": "6ae35c9c-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.24193548387096775, "uncertainty": 0.03260145244886115, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.2661290322580645, "uncertainty": 0.03471707861841491, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.2627935324966748, "uncertainty": 0.034437769941952495, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.023349205482192638, "uncertainty": 0.004053616190523108, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 0.9371482447848746, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J NorPaca", "scenario": "Da. Gym 2000", "executed": "2024-01-07-16-12", "scoring_id": "6ae68840-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.15151515151515152, "uncertainty": 0.04558479471758968, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.3013746720165368, "uncertainty": 0.07465706710530934, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.02725610944463897, "uncertainty": 0.00940117687714325, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 2.9855683896351946, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J NorPaca", "scenario": "Citizenship Test", "executed": "2024-01-07-16-08", "scoring_id": "6ae8e806-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.35537190082644626, "uncertainty": 0.01829084852796569, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.029268292682926828, "uncertainty": 0.0022684966396521013, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.371900826446281, "uncertainty": 0.018650775779857676, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.043478260869565216, "uncertainty": 0.003320538686169269, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.3596863005815938, "uncertainty": 0.018389004805415207, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.03495800932415075, "uncertainty": 0.0026936082908893245, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.39234602815386926, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct (v0.2)", "scenario": "HyggeSwag", "executed": "2024-01-07-16-04", "scoring_id": "6aeef462-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4274193548387097, "uncertainty": 0.04350328566137039, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.3333333333333333, "uncertainty": 0.039501964763884095, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.25, "uncertainty": 0.0333297827695272, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.21426244158889868, "uncertainty": 0.029926420472819494, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.01329511010032192, "uncertainty": 0.002331902723833834, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.220745136893745, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct (v0.2)", "scenario": "Da. Gym 2000", "executed": "2024-01-07-16-02", "scoring_id": "6af22f74-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36363636363636365, "uncertainty": 0.08205263049166141, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4444444444444445, "uncertainty": 0.087551748584577, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.36363636363636365, "uncertainty": 0.08205263049166141, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.2222222222222222, "uncertainty": 0.06128622400920389, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.20424889285950604, "uncertainty": 0.05763108687378795, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.018232887488720963, "uncertainty": 0.006347223329393775, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 3.2922815905432357, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct (v0.2)", "scenario": "Citizenship Test", "executed": "2024-01-07-15-56", "scoring_id": "6af49ae8-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.47107438016528924, "uncertainty": 0.019894160831848192, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.43298969072164945, "uncertainty": 0.019602436106203845, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.48760330578512395, "uncertainty": 0.019948695263953035, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.4467353951890034, "uncertainty": 0.019734439042945966, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.25288539331504456, "uncertainty": 0.015085249866637137, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.02275412916061093, "uncertainty": 0.0017754383586264808, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.6677189870491193, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "mGPT", "scenario": "HyggeSwag", "executed": "2024-01-07-15-53", "scoring_id": "6afb0c70-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.25, "uncertainty": 0.0333297827695272, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.2903225806451613, "uncertainty": 0.036624610410635514, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.47368421052631576, "uncertainty": 0.04431660866862343, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.20285914224758225, "uncertainty": 0.028744904193853435, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.011076584956528484, "uncertainty": 0.001947151546172167, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 0.9929617169433304, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "mGPT", "scenario": "Da. Gym 2000", "executed": "2024-01-07-15-51", "scoring_id": "6afe699c-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.24242424242424243, "uncertainty": 0.06512113531084239, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.42857142857142855, "uncertainty": 0.08683704043286614, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.20960027150235208, "uncertainty": 0.05874331767263933, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.01586778412255188, "uncertainty": 0.005537191960004948, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 2.587745055612741, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "mGPT", "scenario": "Citizenship Test", "executed": "2024-01-07-15-47", "scoring_id": "6b00c14c-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.35537190082644626, "uncertainty": 0.01829084852796569, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.05825242718446602, "uncertainty": 0.004380160968047807, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.36198347107438017, "uncertainty": 0.01844005473420455, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.23053737016480924, "uncertainty": 0.014163493994894666, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.01115735113155481, "uncertainty": 0.0008809065228555038, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.41762603890258543, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J", "scenario": "HyggeSwag", "executed": "2024-01-07-15-42", "scoring_id": "6b087c5c-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.25806451612903225, "uncertainty": 0.03403499149271179, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.07407407407407407, "uncertainty": 0.012191964433297559, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.1774193548387097, "uncertainty": 0.025942432374200148, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.4406779661016949, "uncertainty": 0.04381415856172263, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.2082860392787358, "uncertainty": 0.0293129600293917, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.01327022120972727, "uncertainty": 0.0023275960343566307, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.92057795519565, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J", "scenario": "Da. Gym 2000", "executed": "2024-01-07-15-40", "scoring_id": "6b0be072-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.18181818181818182, "uncertainty": 0.052748119601782335, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.18181818181818182, "uncertainty": 0.052748119601782335, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.16666666666666666, "uncertainty": 0.04924785857882455, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.23450161407933967, "uncertainty": 0.06365169353200219, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.01928342654864138, "uncertainty": 0.0067057532697816806, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 4.915701328494558, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J", "scenario": "Citizenship Test", "executed": "2024-01-07-15-30", "scoring_id": "6b0e4682-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3504132231404959, "uncertainty": 0.018174362980989733, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.12017167381974249, "uncertainty": 0.008441926875363616, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.35537190082644626, "uncertainty": 0.01829084852796569, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.09009009009009009, "uncertainty": 0.006545110028825061, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.27133956826115313, "uncertainty": 0.015786281833326, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.020754672212877988, "uncertainty": 0.0016227399288814524, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.9335499388612191, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neo Danish", "scenario": "HyggeSwag", "executed": "2024-01-07-15-27", "scoring_id": "6b14c4a8-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.23387096774193547, "uncertainty": 0.03185000053071364, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.20967741935483872, "uncertainty": 0.029456915191382348, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.6341463414634146, "uncertainty": 0.04124089718061664, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.1974541235952887, "uncertainty": 0.028168731264348938, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.00984872294525096, "uncertainty": 0.0017334554449563724, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 0.604075841827228, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neo Danish", "scenario": "Da. Gym 2000", "executed": "2024-01-07-15-27", "scoring_id": "6b184074-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.24242424242424243, "uncertainty": 0.06512113531084239, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.7272727272727273, "uncertainty": 0.07033082613570978, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.20252625020233125, "uncertainty": 0.05726873176811033, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.011586536715248941, "uncertainty": 0.004060805063574173, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 1.4479882314547219, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neo Danish", "scenario": "Citizenship Test", "executed": "2024-01-07-15-24", "scoring_id": "6b1aab2a-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.35702479338842974, "uncertainty": 0.01832880449271066, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.12500000000000003, "uncertainty": 0.008732922411139776, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.3305785123966942, "uncertainty": 0.017669156001970433, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.6450567260940032, "uncertainty": 0.018280934577938182, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.24487490247856622, "uncertainty": 0.014764023114897678, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.015972751324432006, "uncertainty": 0.0012549556857193874, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.2673092005620441, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B Chat", "scenario": "Da. Gym 2000", "executed": "2024-01-07-14-42", "scoring_id": "6b3ddbfe-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3939393939393939, "uncertainty": 0.0846574759040951, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6666666666666666, "uncertainty": 0.07879657372611928, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.42424242424242425, "uncertainty": 0.08661110996342036, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.5454545454545454, "uncertainty": 0.08791353266963722, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.20996672343700387, "uncertainty": 0.0588187380960122, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.019945990336318754, "uncertainty": 0.006931471814057469, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 6.939234665905436, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B Chat", "scenario": "Citizenship Test", "executed": "2024-01-07-14-21", "scoring_id": "6b403c3c-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.46611570247933887, "uncertainty": 0.019869293130808378, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5, "uncertainty": 0.019960965511176626, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.3867768595041322, "uncertainty": 0.018937408755000752, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.3054545454545455, "uncertainty": 0.016939040299441606, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.231977468507919, "uncertainty": 0.01422529565842232, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.013433608414402576, "uncertainty": 0.0010581824071415774, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 2.0410441384827793, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B", "scenario": "HyggeSwag", "executed": "2024-01-07-14-11", "scoring_id": "6c56c99c-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.2661290322580645, "uncertainty": 0.03471707861841491, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.2857142857142857, "uncertainty": 0.03627731457907723, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.24193548387096775, "uncertainty": 0.03260145244886115, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.21695064136962514, "uncertainty": 0.030198216028364165, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.013641365291597887, "uncertainty": 0.002391794707527053, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 4.087041776202949, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B", "scenario": "Da. Gym 2000", "executed": "2024-01-07-14-06", "scoring_id": "6c5addf2-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3939393939393939, "uncertainty": 0.0846574759040951, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5454545454545454, "uncertainty": 0.08791353266963722, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.2449548169888317, "uncertainty": 0.06558111147701386, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.020760301501985053, "uncertainty": 0.007208460374551623, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 8.434154357154373, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B", "scenario": "Citizenship Test", "executed": "2024-01-07-13-39", "scoring_id": "6c5d6f0e-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.428099173553719, "uncertainty": 0.01954819439457504, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.37984496124031003, "uncertainty": 0.018808241044122917, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.3685950413223141, "uncertainty": 0.01858228053313399, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.03902439024390244, "uncertainty": 0.0029942635712660905, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.23884028570044283, "uncertainty": 0.01451526309632623, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.01408611009430845, "uncertainty": 0.0011088469319678993, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 2.737671564882698, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B Chat", "scenario": "HyggeSwag", "executed": "2024-01-07-13-33", "scoring_id": "90bb6d38-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.23387096774193547, "uncertainty": 0.03185000053071364, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.1739130434782609, "uncertainty": 0.02553813222920295, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.2903225806451613, "uncertainty": 0.036624610410635514, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.32, "uncertainty": 0.0386803238967953, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.2027562563011046, "uncertainty": 0.028734033561253324, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.014662065733016025, "uncertainty": 0.0025680979025880387, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.8555170783863193, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B Chat", "scenario": "Da. Gym 2000", "executed": "2024-01-07-13-31", "scoring_id": "90be98e6-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.3636363636363636, "uncertainty": 0.08205263049166141, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.36363636363636365, "uncertainty": 0.08205263049166141, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.6153846153846153, "uncertainty": 0.08392534479705013, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.1948506399843544, "uncertainty": 0.05562860074994424, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.012459189723363273, "uncertainty": 0.004362793913138746, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 4.4728928124249885, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B Chat", "scenario": "Citizenship Test", "executed": "2024-01-07-13-21", "scoring_id": "91d4732c-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4066115702479339, "uncertainty": 0.019264615347629837, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.37037037037037035, "uncertainty": 0.018619281958299184, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.3950413223140496, "uncertainty": 0.019081379655757548, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.37499999999999994, "uncertainty": 0.018713405166728085, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.2323057720490659, "uncertainty": 0.014239338413970579, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.012537920501871568, "uncertainty": 0.000988524583638807, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.9368205881077212, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct", "scenario": "HyggeSwag", "executed": "2024-01-07-13-18", "scoring_id": "cb4f1bca-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.27419354838709675, "uncertainty": 0.035376044146636566, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.25, "uncertainty": 0.0333297827695272, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.1926490054810598, "uncertainty": 0.027647786492616476, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.0069127760080216335, "uncertainty": 0.0012203125863792508, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 0.9254756047795978, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct", "scenario": "Da. Gym 2000", "executed": "2024-01-07-13-17", "scoring_id": "cb522d56-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3333333333333333, "uncertainty": 0.07879657372611928, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.25, "uncertainty": 0.06648460908141314, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.2727272727272727, "uncertainty": 0.07033082613570978, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.19134774206119914, "uncertainty": 0.05486621396768015, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.01070847508389849, "uncertainty": 0.0037563994348876017, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 2.5631417831631773, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct", "scenario": "Citizenship Test", "executed": "2024-01-07-13-13", "scoring_id": "cb5c0d94-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.456198347107438, "uncertainty": 0.019807778291394112, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.24669603524229075, "uncertainty": 0.01483795189000581, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.4033057851239669, "uncertainty": 0.019214443670093374, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.253968253968254, "uncertainty": 0.015127887190128319, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.2153032776072946, "uncertainty": 0.013489442940371627, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.009536898574579634, "uncertainty": 0.0007542008204964885, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.34082215536878374, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B", "scenario": "HyggeSwag", "executed": "2024-01-07-13-09", "scoring_id": "cc829daa-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3064516129032258, "uncertainty": 0.0377806902847086, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.28571428571428575, "uncertainty": 0.03627731457907723, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.25, "uncertainty": 0.0333297827695272, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.20318491398370628, "uncertainty": 0.028779299473603234, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.011934407007592743, "uncertainty": 0.002096128158573229, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.8646595000792596, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B", "scenario": "Da. Gym 2000", "executed": "2024-01-07-13-06", "scoring_id": "feb9ed14-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3333333333333333, "uncertainty": 0.07879657372611928, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.33333333333333337, "uncertainty": 0.07879657372611928, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.5, "uncertainty": 0.0886461454418842, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.19899100357568794, "uncertainty": 0.05651850734446711, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.012977088573115475, "uncertainty": 0.004541761768813106, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 5.186868809544566, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B", "scenario": "Citizenship Test", "executed": "2024-01-07-12-55", "scoring_id": "fec35110-ae15-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3933884297520661, "uncertainty": 0.01905345802651987, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4852459016393442, "uncertainty": 0.01994358482634561, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.38016528925619836, "uncertainty": 0.018814379076172217, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.23318385650224216, "uncertainty": 0.014276812751141793, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.23213849864359415, "uncertainty": 0.014232185663016287, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.01149801623066877, "uncertainty": 0.0009074903136511989, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 1.0176557925868441, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B", "scenario": "HyggeSwag", "executed": "2024-01-07-12-51", "scoring_id": "0018169a-ae16-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.25, "uncertainty": 0.0333297827695272, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.35714285714285715, "uncertainty": 0.04081197890146187, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.2661290322580645, "uncertainty": 0.03471707861841491, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.2857142857142857, "uncertainty": 0.03627731457907723, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.20283138148478988, "uncertainty": 0.02874197144238174, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.009134777414711397, "uncertainty": 0.0016089545131035313, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.303079834395659, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B", "scenario": "Da. Gym 2000", "executed": "2024-01-07-12-50", "scoring_id": "001bc588-ae16-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3939393939393939, "uncertainty": 0.0846574759040951, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5714285714285715, "uncertainty": 0.08683704043286615, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.22031031855673058, "uncertainty": 0.06090829922402843, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.014896862813481803, "uncertainty": 0.005203509693338297, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 3.3657555970024657, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B", "scenario": "Citizenship Test", "executed": "2024-01-07-12-43", "scoring_id": "001e091a-ae16-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4479338842975207, "uncertainty": 0.01974451835015249, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.3555555555555555, "uncertainty": 0.0182950874018488, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.47603305785123967, "uncertainty": 0.01991510205377645, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.46822742474916385, "uncertainty": 0.019880363408856357, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.20004089722063426, "uncertainty": 0.012776977028832983, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.008719642908780764, "uncertainty": 0.0006901392631992064, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.6781959827319711, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "SOLAR 10.7B", "scenario": "Citizenship Test", "executed": "2024-01-06-06-20", "scoring_id": "dd80f3ca-db99-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.47603305785123967, "uncertainty": 0.01991510205377645, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.49333333333333335, "uncertainty": 0.01995741689508575, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.4380165289256198, "uncertainty": 0.019654209330586862, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.2786885245901639, "uncertainty": 0.016050311424197924, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.21385237320766473, "uncertainty": 0.013423313013943013, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.013086583165934607, "uncertainty": 0.0010312093881975836, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 49.418034908898974, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "SOLAR 10.7B Instruct", "scenario": "Da. Cloze Self Test", "executed": "2024-01-06-06-18", "scoring_id": "14345488-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.46, "uncertainty": 0.07059449881239752, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8421052631578948, "uncertainty": 0.03778794749549559, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.28, "uncertainty": 0.057294085992670434, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4444444444444445, "uncertainty": 0.07017206299317856, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.33791645151481353, "uncertainty": 0.06358305640474456, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.034801195904055685, "uncertainty": 0.009546193015493238, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.1379291147179902, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "SOLAR 10.7B Instruct", "scenario": "DaNE", "executed": "2024-01-06-05-48", "scoring_id": "14383986-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.06746987951807229, "uncertainty": 0.007744030096852176, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 6.456206154121901, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "SOLAR 10.7B Instruct", "scenario": "#twitterhjerne", "executed": "2024-01-06-05-48", "scoring_id": "1518b8f8-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.5, "uncertainty": 0.056366290518193855, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.20512820512820512, "uncertainty": 0.036762235499045566, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.20512820512820512, "uncertainty": 0.036762235499045566, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6232874264574457, "uncertainty": 0.0529392675100313, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.09164566839277312, "uncertainty": 0.01876923969402734, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.12766662285413619, "uncertainty": 0.025109571762070012, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6451467329110855, "uncertainty": 0.05161628651494745, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.13722691605298032, "uncertainty": 0.026694103336168003, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.18991152744011144, "uncertainty": 0.03468671924056187, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5977900219269288, "uncertainty": 0.05421019233780379, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.04564217771677057, "uncertainty": 0.009821030079720816, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.06501574341887958, "uncertainty": 0.013705733314555867, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.002815861076576253, "uncertainty": 0.0006330908441397928, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.5450009149320137, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neo Danish", "scenario": "DaNE", "executed": "2024-01-06-00-18", "scoring_id": "2aded6fc-ae2a-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 1.0068721039642696, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "SOLAR 10.7B Instruct", "scenario": "Angry Tweets", "executed": "2024-01-06-05-42", "scoring_id": "34eded10-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.45703125, "uncertainty": 0.03054322986360304, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.0963855421686747, "uncertainty": 0.010719864475155282, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.31640625, "uncertainty": 0.026621796920406636, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.25027698303030804, "uncertainty": 0.023094894597914598, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.019797559625122495, "uncertainty": 0.0023884803257087995, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.6961243658970488, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "SOLAR 10.7B Instruct", "scenario": "Nordjylland News", "executed": "2024-01-06-05-38", "scoring_id": "34f28686-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7111176713307699, "uncertainty": 0.02334056653402816, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.1989358040777104, "uncertainty": 0.0181062795234791, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.2750301822212789, "uncertainty": 0.022654226000902968, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.012904059352197995, "uncertainty": 0.0014472203603132588, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.7747677709969382, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neox Da.", "scenario": "Da. Cloze Self Test", "executed": "2024-01-06-05-30", "scoring_id": "3939551c-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36, "uncertainty": 0.06547895542019477, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.15384615384615385, "uncertainty": 0.03699604031178822, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.36, "uncertainty": 0.06547895542019477, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.8, "uncertainty": 0.0454714968195797, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.2681617267624229, "uncertainty": 0.05577392129525599, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.027807119884991904, "uncertainty": 0.00768294480564586, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 0.6244390220940113, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neox Da.", "scenario": "DaNE", "executed": "2024-01-06-05-24", "scoring_id": "3940c978-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 1.1370455038540968, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neox Da.", "scenario": "Angry Tweets", "executed": "2024-01-06-05-21", "scoring_id": "78326ee8-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.40625, "uncertainty": 0.02968870304887394, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.2890625, "uncertainty": 0.025293993715981417, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.2857142857142857, "uncertainty": 0.025118757268484605, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.3157052283558859, "uncertainty": 0.026590054364433624, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.02896935162793388, "uncertainty": 0.0034623099363102617, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.3225507512433978, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neox Da.", "scenario": "Nordjylland News", "executed": "2024-01-06-05-20", "scoring_id": "78374dd2-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.2661857663591703, "uncertainty": 0.022193198945225635, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.019948212773398203, "uncertainty": 0.0022212731285255597, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.024227602430087723, "uncertainty": 0.002686011780244182, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.04185010688243589, "uncertainty": 0.004555950249069486, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.2505800933235635, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny", "scenario": "Da. Cloze Self Test", "executed": "2024-01-06-05-16", "scoring_id": "81117c48-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.38, "uncertainty": 0.06695677906683112, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.2857142857142857, "uncertainty": 0.057999358188239425, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.28, "uncertainty": 0.057294085992670434, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.5454545454545454, "uncertainty": 0.07046203019562972, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.3321656811170163, "uncertainty": 0.06304385485395915, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03458753635097669, "uncertainty": 0.009489685021538194, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 0.3992782833613455, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny", "scenario": "DaNE", "executed": "2024-01-06-05-11", "scoring_id": "8116d454-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 1.130813752684844, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny", "scenario": "#twitterhjerne", "executed": "2024-01-06-05-10", "scoring_id": "8240c394-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9102564102564102, "uncertainty": 0.01841817645466295, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.47435897435897434, "uncertainty": 0.05621805569763319, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5128205128205128, "uncertainty": 0.056329231813053694, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5277534817592201, "uncertainty": 0.05619262468073688, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.06041045740276143, "uncertainty": 0.012797635739055409, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.06936301548452792, "uncertainty": 0.014554179245975959, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5530732701986264, "uncertainty": 0.05573120656053265, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.09854667770434387, "uncertainty": 0.020029249533731062, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.11306782362995153, "uncertainty": 0.02261043352663332, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5042460484382434, "uncertainty": 0.05636222562316917, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.02361037884246801, "uncertainty": 0.005197632340180194, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.025773172188424887, "uncertainty": 0.005661185766659528, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.00964823379390276, "uncertainty": 0.002154352401406176, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.18362835930803648, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny", "scenario": "Angry Tweets", "executed": "2024-01-06-05-08", "scoring_id": "ad95742c-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.33984375, "uncertainty": 0.027613423641674694, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.15094339622641512, "uncertainty": 0.015774114568033765, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.4296875, "uncertainty": 0.030161979438570057, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.7536231884057971, "uncertainty": 0.0228532680075967, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.26890188301577855, "uncertainty": 0.024197123327876078, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.023300035830641025, "uncertainty": 0.0028009927834815604, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.28342892682849197, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "DanskGPT-tiny", "scenario": "Nordjylland News", "executed": "2024-01-06-05-07", "scoring_id": "ad9dac8c-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.5612878188490867, "uncertainty": 0.027977844768909722, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.08014849414555676, "uncertainty": 0.008376489274131968, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.10209696089412837, "uncertainty": 0.010415765704180567, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.009670823950824949, "uncertainty": 0.0010881580953305062, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.22772863042696068, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B Instruct (v. 2)", "scenario": "Da. Cloze Self Test", "executed": "2024-01-06-05-03", "scoring_id": "b4482a9e-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.2, "uncertainty": 0.04547149681957972, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.14285714285714285, "uncertainty": 0.03479961491294365, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.14, "uncertainty": 0.03421730135673373, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.1818181818181818, "uncertainty": 0.04227721811737783, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.32930655774507045, "uncertainty": 0.06276878281130244, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03353694253842561, "uncertainty": 0.009211449861454097, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.5013375239633024, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B Instruct (v. 2)", "scenario": "DaNE", "executed": "2024-01-06-04-42", "scoring_id": "b45087de-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.031545741324921134, "uncertainty": 0.0037602271451583143, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 4.334347317831998, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B Instruct (v. 2)", "scenario": "#twitterhjerne", "executed": "2024-01-06-04-41", "scoring_id": "b5ab6310-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9615384615384616, "uncertainty": 0.008338208656537548, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.5384615384615384, "uncertainty": 0.05603276217193235, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5128205128205128, "uncertainty": 0.056329231813053694, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5546461051919012, "uncertainty": 0.055693007169849804, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.04142564059864047, "uncertainty": 0.008953121682213792, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.06208537239362224, "uncertainty": 0.013129012008708333, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5803967332228636, "uncertainty": 0.054908966070068774, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.06259653292082132, "uncertainty": 0.01322989144848949, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.09721830321245852, "uncertainty": 0.019788379400240187, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5256892580252427, "uncertainty": 0.05621749749505148, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.019908748031086585, "uncertainty": 0.004399364124833517, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.02888613763901269, "uncertainty": 0.006324687555808344, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.026390225457129046, "uncertainty": 0.005793052600566649, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.9522064315895431, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B Instruct (v. 2)", "scenario": "Angry Tweets", "executed": "2024-01-06-04-32", "scoring_id": "ee1d39da-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.40625, "uncertainty": 0.02968870304887394, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.3671875, "uncertainty": 0.028599416120208273, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.611764705882353, "uncertainty": 0.029233018493609125, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2571859825200072, "uncertainty": 0.02351373472339025, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.021472382041215748, "uncertainty": 0.002586113268696188, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 1.1149854612813215, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B Instruct (v. 2)", "scenario": "Nordjylland News", "executed": "2024-01-06-04-28", "scoring_id": "ee21f358-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.5736068310340245, "uncertainty": 0.027789037132297623, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.06868733572765552, "uncertainty": 0.007268103877747946, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.09432797733469425, "uncertainty": 0.009706449961585423, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.055740090889545776, "uncertainty": 0.0059800961878969374, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.9541847574462493, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B (v. 2)", "scenario": "Da. Cloze Self Test", "executed": "2024-01-06-04-15", "scoring_id": "f7a8f75a-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.34, "uncertainty": 0.06377377428946053, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.30769230769230765, "uncertainty": 0.06053897505565345, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.24, "uncertainty": 0.05183750637432087, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4615384615384615, "uncertainty": 0.0706288042315957, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.32580247368732895, "uncertainty": 0.06242532325431172, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03226391448004999, "uncertainty": 0.008873465420392685, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.5041309183184057, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B (v. 2)", "scenario": "DaNE", "executed": "2024-01-06-03-54", "scoring_id": "f7b21394-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.014760147601476014, "uncertainty": 0.0017898923018127967, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 4.337333014605974, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B (v. 2)", "scenario": "#twitterhjerne", "executed": "2024-01-06-03-53", "scoring_id": "f92fbfdc-ae28-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9743589743589743, "uncertainty": 0.005632923181305373, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.5128205128205128, "uncertainty": 0.056329231813053694, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5769230769230769, "uncertainty": 0.055032177133147855, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.4972952086446631, "uncertainty": 0.0563646410384543, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.049503843095288755, "uncertainty": 0.010608860208079614, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.055443392395272253, "uncertainty": 0.011807480362052564, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.519780600300202, "uncertainty": 0.05627807227987718, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.07814736503400375, "uncertainty": 0.016242590174318602, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.08787305108398252, "uncertainty": 0.01807134342597989, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.4738701005012561, "uncertainty": 0.05621234929796067, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.02077100872374342, "uncertainty": 0.0045858653304410146, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.022883668400564734, "uncertainty": 0.00504140240404155, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0061921080475888, "uncertainty": 0.0013874598137171266, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.9350227347563188, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B (v. 2)", "scenario": "Angry Tweets", "executed": "2024-01-06-03-45", "scoring_id": "2db6faea-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.421875, "uncertainty": 0.030019245289296625, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.17777777777777776, "uncertainty": 0.017991232366523488, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.328125, "uncertainty": 0.027134513009244098, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.6212121212121212, "uncertainty": 0.028962111657705215, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.28228405575420457, "uncertainty": 0.024936366489083997, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.02423298225358664, "uncertainty": 0.00291036345095044, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 1.1197061044967995, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT-Sw3 6.7B (v. 2)", "scenario": "Nordjylland News", "executed": "2024-01-06-03-40", "scoring_id": "2dbc13c2-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.5439657228191693, "uncertainty": 0.028184995326275157, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.05761659357833012, "uncertainty": 0.00616913330314585, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.07213577100963267, "uncertainty": 0.007604734495746674, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.008427383009887612, "uncertainty": 0.0009494371110328611, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.953250799376207, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Kanelsnegl (v. 0.2)", "scenario": "Da. Cloze Self Test", "executed": "2024-01-06-03-28", "scoring_id": "36844812-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36, "uncertainty": 0.06547895542019477, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5454545454545454, "uncertainty": 0.07046203019562972, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.28, "uncertainty": 0.057294085992670434, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.5, "uncertainty": 0.0710492137805933, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.33193196723280816, "uncertainty": 0.0630215439675367, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.034205488781062075, "uncertainty": 0.009388577624542975, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.1455711758602412, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Kanelsnegl (v. 0.2)", "scenario": "DaNE", "executed": "2024-01-06-03-17", "scoring_id": "368ae0c8-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 2.3598164778686623, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Kanelsnegl (v. 0.2)", "scenario": "#twitterhjerne", "executed": "2024-01-06-03-16", "scoring_id": "37db5a48-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9615384615384616, "uncertainty": 0.008338208656537548, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.3974358974358974, "uncertainty": 0.05399453338922318, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.3974358974358974, "uncertainty": 0.05399453338922318, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5291322822117397, "uncertainty": 0.05617494051981174, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.0648664087679086, "uncertainty": 0.013676436654330826, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.08591345661291795, "uncertainty": 0.017706305545326893, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5482583523560793, "uncertainty": 0.05584121178813384, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.09880149230537047, "uncertainty": 0.0200753633384331, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.1362819105380403, "uncertainty": 0.026539312897430924, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5076752457863245, "uncertainty": 0.056353008501253125, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.03081652699348673, "uncertainty": 0.0067339383824800035, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.03807242575252969, "uncertainty": 0.0082571917253031, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.004862617299062176, "uncertainty": 0.001091019663077507, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.5827253802189938, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Kanelsnegl (v. 0.2)", "scenario": "Angry Tweets", "executed": "2024-01-06-03-10", "scoring_id": "649b8332-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.46875, "uncertainty": 0.030650280475558116, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5954198473282444, "uncertainty": 0.029649823348568565, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.28515625, "uncertainty": 0.02508928289662873, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.3020377346736847, "uncertainty": 0.025947013459334128, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.028515511064371505, "uncertainty": 0.0034096614519802436, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.8327398592191457, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Kanelsnegl (v. 0.2)", "scenario": "Nordjylland News", "executed": "2024-01-06-03-07", "scoring_id": "64a0b6c2-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.6196952487031618, "uncertainty": 0.02677681164001452, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.09091903651095727, "uncertainty": 0.009390880935754652, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.11654724472409071, "uncertainty": 0.011698610629713042, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.0038474956824211403, "uncertainty": 0.00043546466248487104, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.5915614904168373, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J NorPaca", "scenario": "Da. Cloze Self Test", "executed": "2024-01-06-02-58", "scoring_id": "6b0d25c2-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.38, "uncertainty": 0.06695677906683112, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.28571428571428575, "uncertainty": 0.057999358188239425, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.36, "uncertainty": 0.06547895542019477, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.8000000000000002, "uncertainty": 0.04547149681957969, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.31369122553018003, "uncertainty": 0.06118446826820143, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.030407645428427735, "uncertainty": 0.008378981713545152, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.5260124979354441, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J NorPaca", "scenario": "DaNE", "executed": "2024-01-06-02-29", "scoring_id": "6b11cac8-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 6.301203531909778, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J NorPaca", "scenario": "#twitterhjerne", "executed": "2024-01-06-02-28", "scoring_id": "6c201b04-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.41025641025641024, "uncertainty": 0.054550413966325685, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.23076923076923078, "uncertainty": 0.040023401551380254, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.16666666666666666, "uncertainty": 0.031314605843441035, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6209035817883972, "uncertainty": 0.05307051380960069, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.09720289812883741, "uncertainty": 0.019785581375604527, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.14166156424247303, "uncertainty": 0.02741511294318596, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6512952095422989, "uncertainty": 0.051205338749658075, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.14932277885232428, "uncertainty": 0.028639821916459775, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.21783188060485748, "uncertainty": 0.038415014139337796, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5863147954910229, "uncertainty": 0.05468652006514119, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.043229428321165164, "uncertainty": 0.009325384494131754, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.0617073643707902, "uncertainty": 0.013054334931395689, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0030208138505725237, "uncertainty": 0.0006790308434880074, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.9378954714749199, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J NorPaca", "scenario": "Angry Tweets", "executed": "2024-01-06-02-24", "scoring_id": "8fcb328c-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.24609375, "uncertainty": 0.02283558580283769, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.2890625, "uncertainty": 0.025293993715981417, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.45454545454545453, "uncertainty": 0.030516176185679637, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.3594585829285429, "uncertainty": 0.0283393773052004, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.036467889961808615, "uncertainty": 0.004324850078330262, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.513880264468753, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J NorPaca", "scenario": "Nordjylland News", "executed": "2024-01-06-02-19", "scoring_id": "8fd01bd0-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7082038034995397, "uncertainty": 0.023479390964196347, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.1951544732142207, "uncertainty": 0.017845963113156237, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.2693246650036869, "uncertainty": 0.02235885305069786, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.012126309506129473, "uncertainty": 0.0013610654632126675, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.8855800222605467, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct (v0.2)", "scenario": "Da. Cloze Self Test", "executed": "2024-01-06-02-13", "scoring_id": "94b3fe3c-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.38, "uncertainty": 0.06695677906683112, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.608695652173913, "uncertainty": 0.0676915004639301, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.26, "uncertainty": 0.054679474925544605, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4, "uncertainty": 0.06820724522936956, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.34938218183222797, "uncertainty": 0.06460200146850703, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03569692586434429, "uncertainty": 0.009782810394914037, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.0514284780994059, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct (v0.2)", "scenario": "DaNE", "executed": "2024-01-06-01-56", "scoring_id": "94b994d2-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.05829596412556053, "uncertainty": 0.006756894688823795, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 3.627848023097613, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct (v0.2)", "scenario": "#twitterhjerne", "executed": "2024-01-06-01-55", "scoring_id": "95c733ca-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.6410256410256411, "uncertainty": 0.05188218719623366, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.3076923076923077, "uncertainty": 0.04802808186165631, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.2948717948717949, "uncertainty": 0.046879262002311135, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6152062909343302, "uncertainty": 0.053373806528540464, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.07569253108717479, "uncertainty": 0.015774257874602134, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.10223329928920154, "uncertainty": 0.020693564999667034, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6368855184469467, "uncertainty": 0.05214160431522196, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.11745539272008636, "uncertainty": 0.023371633799540707, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.1605934513141676, "uncertainty": 0.030393424143031297, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5913789982979114, "uncertainty": 0.054483629059213924, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.035995498353899334, "uncertainty": 0.00782360109307138, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.046751228595508655, "uncertainty": 0.010047979228751834, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0036137250075952555, "uncertainty": 0.0008118247430716091, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.43321838586901623, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct (v0.2)", "scenario": "Angry Tweets", "executed": "2024-01-06-01-50", "scoring_id": "b571a17e-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.51171875, "uncertainty": 0.030753574925690204, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5299145299145299, "uncertainty": 0.030660334224494795, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.32421875, "uncertainty": 0.026967363808121262, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2788993742977919, "uncertainty": 0.024753558551219856, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.0274225947184083, "uncertainty": 0.0032826679150676605, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.5096606212191546, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct (v0.2)", "scenario": "Nordjylland News", "executed": "2024-01-06-01-48", "scoring_id": "b57671ea-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.697248907883962, "uncertainty": 0.02398404923898796, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.1786138870514948, "uncertainty": 0.01666907588979072, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.2477421153757047, "uncertainty": 0.021174615645586616, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.012653670835425146, "uncertainty": 0.0014194986852788507, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.5741938101360574, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "mGPT", "scenario": "Da. Cloze Self Test", "executed": "2024-01-06-01-39", "scoring_id": "ba377ca6-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.42, "uncertainty": 0.0692303539078101, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.15384615384615385, "uncertainty": 0.03699604031178822, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.18, "uncertainty": 0.04194745581606228, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4, "uncertainty": 0.06820724522936956, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.3722811773647129, "uncertainty": 0.06641336692649552, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03842707558350563, "uncertainty": 0.010501197549043257, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 0.96286948624067, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "mGPT", "scenario": "DaNE", "executed": "2024-01-06-01-31", "scoring_id": "ba3e1750-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 1.634296112732045, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "mGPT", "scenario": "#twitterhjerne", "executed": "2024-01-06-01-30", "scoring_id": "bb63d566-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9871794871794872, "uncertainty": 0.002853520295792841, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.6153846153846154, "uncertainty": 0.05336453540184034, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.6666666666666666, "uncertainty": 0.050103369349505655, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.47974717941167, "uncertainty": 0.05627380995262925, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.0358091673655057, "uncertainty": 0.0077846065429047605, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.03845309436576684, "uncertainty": 0.008336451240995076, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.4978773804047169, "uncertainty": 0.05636527468176173, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.060054079360465855, "uncertainty": 0.012726964331873815, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.0651875408756919, "uncertainty": 0.013739424317528764, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.46127755099382156, "uncertainty": 0.05602822172829774, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.015256535447313598, "uncertainty": 0.003387337543684492, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.016013094779454326, "uncertainty": 0.0035525814122542064, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.011354918216313355, "uncertainty": 0.00253106831294719, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.39185356337409943, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "mGPT", "scenario": "Angry Tweets", "executed": "2024-01-06-01-26", "scoring_id": "ea09284e-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.38671875, "uncertainty": 0.02919101160732842, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.3203125, "uncertainty": 0.02679645844517544, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.6188679245283019, "uncertainty": 0.029031381522767918, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.45312499999032857, "uncertainty": 0.030500034002527113, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.04531249999907317, "uncertainty": 0.00532443450721405, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.5279575067179394, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "mGPT", "scenario": "Nordjylland News", "executed": "2024-01-06-01-24", "scoring_id": "ea0e29f2-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.4808886108795802, "uncertainty": 0.028363119503515367, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.04318412701987031, "uncertainty": 0.004694630997383968, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.05212683954795967, "uncertainty": 0.005613846927249088, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.020606754603407655, "uncertainty": 0.002293061220548852, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.266758039893272, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J", "scenario": "Da. Cloze Self Test", "executed": "2024-01-06-01-18", "scoring_id": "f51de530-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.32, "uncertainty": 0.061841235674628396, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4285714285714285, "uncertainty": 0.0695992298258873, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.34, "uncertainty": 0.06377377428946053, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.7272727272727272, "uncertainty": 0.05636962415650378, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.31015916966829693, "uncertainty": 0.06080688960783416, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.031129292163046933, "uncertainty": 0.008571450851964486, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.7662621699366718, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J", "scenario": "DaNE", "executed": "2024-01-06-00-48", "scoring_id": "f5243fb6-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 6.302254380540035, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J", "scenario": "#twitterhjerne", "executed": "2024-01-06-00-47", "scoring_id": "f63aedc8-ae29-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9743589743589743, "uncertainty": 0.005632923181305373, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.46153846153846156, "uncertainty": 0.05603276217193235, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5, "uncertainty": 0.056366290518193855, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5215822418849183, "uncertainty": 0.05626127038680454, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.050013375116377386, "uncertainty": 0.01071230921862612, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.05969820054510176, "uncertainty": 0.012656334773430594, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5448451137695557, "uncertainty": 0.05591286108655938, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.08405814804871613, "uncertainty": 0.017359098487063518, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.09971902600319682, "uncertainty": 0.020241166908707905, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.4961393081989044, "uncertainty": 0.056362929973214335, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.018314945138536032, "uncertainty": 0.004053752667872396, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.022581171594055684, "uncertainty": 0.004976300727899047, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.006144234150176486, "uncertainty": 0.0013767990748731896, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 1.006033529730466, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J", "scenario": "Angry Tweets", "executed": "2024-01-06-00-39", "scoring_id": "2435824c-ae2a-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.34375, "uncertainty": 0.02776554819550559, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.1818181818181818, "uncertainty": 0.018309705711407786, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.29296875, "uncertainty": 0.025494948373511118, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.6391752577319588, "uncertainty": 0.028386411524688782, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2638419739600344, "uncertainty": 0.02390612401726984, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.018632670336351683, "uncertainty": 0.0022506135297601835, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.981961911842518, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NB GPT-J", "scenario": "Nordjylland News", "executed": "2024-01-06-00-34", "scoring_id": "243b245e-ae2a-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.5081794945398966, "uncertainty": 0.02839701655937392, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.03355427105846527, "uncertainty": 0.0036844632204001294, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.0376417878812811, "uncertainty": 0.004115815947970543, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.025123984365491195, "uncertainty": 0.0027828310871346996, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.9572955326456577, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neo Danish", "scenario": "Da. Cloze Self Test", "executed": "2024-01-06-00-23", "scoring_id": "2ad79a22-ae2a-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36, "uncertainty": 0.06547895542019477, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.2857142857142857, "uncertainty": 0.057999358188239425, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.22, "uncertainty": 0.04876818033899923, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.5333333333333333, "uncertainty": 0.07073343949712399, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.2964247103813537, "uncertainty": 0.059271272347427385, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.029934840813716248, "uncertainty": 0.008252720323766189, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 0.6577322459965944, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neo Danish", "scenario": "#twitterhjerne", "executed": "2024-01-06-00-17", "scoring_id": "2c1a9290-ae2a-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9871794871794872, "uncertainty": 0.002853520295792841, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.5384615384615384, "uncertainty": 0.05603276217193235, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5256410256410257, "uncertainty": 0.05621805569763319, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.4904750408652501, "uncertainty": 0.05634583522596951, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.04369943129585163, "uncertainty": 0.009422142000863462, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.04916102204336249, "uncertainty": 0.010539192226262163, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.514336048410489, "uncertainty": 0.05631995240311595, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.07342936993960802, "uncertainty": 0.015340085416619107, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.08317063044159823, "uncertainty": 0.017192457383781085, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.466257251225985, "uncertainty": 0.056109581950837144, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.016748478997384998, "uncertainty": 0.0037129529498211257, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.01895353824758746, "uncertainty": 0.004192367231874631, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.008477378082133304, "uncertainty": 0.0018951501576229912, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.345089104384757, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neo Danish", "scenario": "Angry Tweets", "executed": "2024-01-06-00-15", "scoring_id": "63473106-ae2a-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.1411764705882353, "uncertainty": 0.01492314930093333, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.387002763159843, "uncertainty": 0.029198921597772008, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.03881620193725573, "uncertainty": 0.004592125086216443, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.3362743946872797, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT Neo Danish", "scenario": "Nordjylland News", "executed": "2024-01-06-00-13", "scoring_id": "634c5d34-ae2a-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.5060641391078631, "uncertainty": 0.02840043992346537, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.05033065992550075, "uncertainty": 0.005430677185335411, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.05816517469940329, "uncertainty": 0.006224245696192526, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.010899335844248223, "uncertainty": 0.0012248685232732527, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.23774381061395009, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B Chat", "scenario": "Da. Cloze Self Test", "executed": "2024-01-05-22-26", "scoring_id": "d64e9932-ae2a-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36, "uncertainty": 0.06547895542019477, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6666666666666665, "uncertainty": 0.06315485669386071, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.22, "uncertainty": 0.04876818033899923, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.28571428571428575, "uncertainty": 0.057999358188239425, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.3608051651603245, "uncertainty": 0.06554284229174685, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03711153897431362, "uncertainty": 0.01015556790700843, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 2.7757513320446012, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B Chat", "scenario": "DaNE", "executed": "2024-01-05-21-05", "scoring_id": "d65449fe-ae2a-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.007220216606498194, "uncertainty": 0.0008822616069356568, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 18.201242118253504, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B Chat", "scenario": "#twitterhjerne", "executed": "2024-01-05-21-02", "scoring_id": "d770a972-ae2a-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.6025641025641025, "uncertainty": 0.05399453338922318, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.44871794871794873, "uncertainty": 0.055773351235951195, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.3974358974358974, "uncertainty": 0.05399453338922318, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6107080444184123, "uncertainty": 0.053602928368461415, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.06791251550290162, "uncertainty": 0.014272036239660191, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.09770150619391806, "uncertainty": 0.01987608921465528, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6347301311981983, "uncertainty": 0.05227359994252375, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.10429145838925964, "uncertainty": 0.021061771770450308, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.15597738935689975, "uncertainty": 0.029682137620212747, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5836201569972894, "uncertainty": 0.05478976355351572, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.03040100773896528, "uncertainty": 0.006645988438261591, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.04263823166747985, "uncertainty": 0.009203535910072483, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.005853652651869477, "uncertainty": 0.0013120691238690965, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 2.0136339435150896, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B Chat", "scenario": "Angry Tweets", "executed": "2024-01-05-20-51", "scoring_id": "fa184c6e-ae2a-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.38671875, "uncertainty": 0.02919101160732842, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.529032258064516, "uncertainty": 0.030666735356704652, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2242663672563561, "uncertainty": 0.021412678612936005, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.006508549388481232, "uncertainty": 0.0007958707947743879, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.6373365148192534, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B Chat", "scenario": "Nordjylland News", "executed": "2024-01-05-20-43", "scoring_id": "fa1cf0fc-ae2a-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.6871218512455622, "uncertainty": 0.02442631419297222, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.12325291080566964, "uncertainty": 0.012277797416642767, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.16524090104487835, "uncertainty": 0.01567211688559362, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.011362457443804791, "uncertainty": 0.0012763162949024386, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.539047646825202, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B", "scenario": "Da. Cloze Self Test", "executed": "2024-01-05-20-19", "scoring_id": "ff8530d6-ae2a-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3, "uncertainty": 0.059681339575698364, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.26, "uncertainty": 0.054679474925544605, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.5, "uncertainty": 0.0710492137805933, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.35264471697163663, "uncertainty": 0.06487828279132736, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03623745306116441, "uncertainty": 0.009925376243493905, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 4.5396957537997515, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B", "scenario": "DaNE", "executed": "2024-01-05-18-57", "scoring_id": "ff8b57b8-ae2a-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.02247191011235955, "uncertainty": 0.002703730898511548, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 18.163202061423362, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B", "scenario": "#twitterhjerne", "executed": "2024-01-05-18-53", "scoring_id": "00af1fee-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9743589743589743, "uncertainty": 0.005632923181305373, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.5384615384615384, "uncertainty": 0.05603276217193235, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5641025641025641, "uncertainty": 0.05543982288968968, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5074505323337184, "uncertainty": 0.05635377484963367, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.055213596396678784, "uncertainty": 0.011761402618354422, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.06463270789766168, "uncertainty": 0.01363056874009391, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5273122523839657, "uncertainty": 0.05619810272198438, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.08666359952995038, "uncertainty": 0.017846248493325372, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.10271166143814457, "uncertainty": 0.020779314865428253, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.4854777986422563, "uncertainty": 0.056318741193387284, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.02358057281183915, "uncertainty": 0.0051912292523028725, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.028344034359439087, "uncertainty": 0.006209457132900537, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.00998443137937918, "uncertainty": 0.0022286650719316988, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 2.8294277253966684, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B", "scenario": "Angry Tweets", "executed": "2024-01-05-18-32", "scoring_id": "2d503be6-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.40625, "uncertainty": 0.02968870304887394, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.13114754098360656, "uncertainty": 0.014024920747380707, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.34375, "uncertainty": 0.02776554819550559, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.02777777777777778, "uncertainty": 0.0033239713515008564, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.22801485515490508, "uncertainty": 0.02166538020181122, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.008144010624638185, "uncertainty": 0.000994216991226209, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 2.985585258835272, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 13B", "scenario": "Nordjylland News", "executed": "2024-01-05-18-18", "scoring_id": "2d551760-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.5312598648667336, "uncertainty": 0.02829359250205772, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.045067320147885316, "uncertainty": 0.0048897137565020385, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.051257849167188944, "uncertainty": 0.005525321085288882, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.010833259562108045, "uncertainty": 0.0012175241941943865, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 2.9173257661859195, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B Chat", "scenario": "Da. Cloze Self Test", "executed": "2024-01-05-17-47", "scoring_id": "3475b7ca-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.26, "uncertainty": 0.054679474925544605, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.13333333333333333, "uncertainty": 0.03284052548080757, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.28, "uncertainty": 0.057294085992670434, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4, "uncertainty": 0.06820724522936956, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.28319396021334264, "uncertainty": 0.05769058070916025, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.029147881414693277, "uncertainty": 0.0080422828701883, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.3868643043003976, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B Chat", "scenario": "DaNE", "executed": "2024-01-05-17-13", "scoring_id": "347b69fe-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 7.3765813877271285, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B Chat", "scenario": "#twitterhjerne", "executed": "2024-01-05-17-12", "scoring_id": "359ac2d0-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.6923076923076923, "uncertainty": 0.04802808186165631, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.46153846153846156, "uncertainty": 0.05603276217193235, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.4358974358974359, "uncertainty": 0.05543982288968968, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6082900836554348, "uncertainty": 0.05372231868340405, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.06283546259886871, "uncertainty": 0.01327700470551505, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.08393729500182588, "uncertainty": 0.017336427900594056, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6322379647157131, "uncertainty": 0.05242360843993194, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.09919746527743346, "uncertainty": 0.020146964475976883, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.12991775787283352, "uncertainty": 0.025486386681884177, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5818325349917779, "uncertainty": 0.05485644867948837, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.028864430796536878, "uncertainty": 0.006320076058231159, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.03917950573987839, "uncertainty": 0.008487516996374428, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.004353086170083724, "uncertainty": 0.0009771968585105398, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.8927731012555364, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B Chat", "scenario": "Angry Tweets", "executed": "2024-01-05-17-05", "scoring_id": "580138a4-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.28125, "uncertainty": 0.024880815915453058, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.23099233889506346, "uncertainty": 0.021863640209049098, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.009025917654560367, "uncertainty": 0.0011009000526451445, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.36810683831208735, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B Chat", "scenario": "Nordjylland News", "executed": "2024-01-05-17-02", "scoring_id": "5805f678-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.6934622544050216, "uncertainty": 0.02415214638073352, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.1329040502053852, "uncertainty": 0.013093456801877972, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.17483606913775632, "uncertainty": 0.016391557278861043, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.009638657942414284, "uncertainty": 0.001084574012041996, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.7215755885808418, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct", "scenario": "Da. Cloze Self Test", "executed": "2024-01-05-16-50", "scoring_id": "5cd490c4-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.32, "uncertainty": 0.061841235674628396, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.39999999999999997, "uncertainty": 0.06820724522936958, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.38, "uncertainty": 0.06695677906683112, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.5714285714285714, "uncertainty": 0.0695992298258873, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.2511583653576342, "uncertainty": 0.05345113089303821, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.02540315464427962, "uncertainty": 0.00703609866998141, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 0.6217037582956254, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct", "scenario": "DaNE", "executed": "2024-01-05-16-34", "scoring_id": "5cd8ed90-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.015444015444015444, "uncertainty": 0.0018715217248980493, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 3.465410070191865, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct", "scenario": "#twitterhjerne", "executed": "2024-01-05-16-33", "scoring_id": "5db10b58-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.3717948717948718, "uncertainty": 0.052660420004177165, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.21794871794871795, "uncertainty": 0.038429877230353085, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.23076923076923078, "uncertainty": 0.040023401551380254, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6258659796200247, "uncertainty": 0.05279441622096892, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.09940626763163576, "uncertainty": 0.020184692334264676, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.1360471978725201, "uncertainty": 0.026500804896455805, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6542680034270654, "uncertainty": 0.0510005315059272, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.15158267606199913, "uncertainty": 0.02899603022519912, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.21526559880791124, "uncertainty": 0.03808700029252041, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5947773433648623, "uncertainty": 0.054340994502553634, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.05013069089309465, "uncertainty": 0.010736110966540887, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.0621407280802595, "uncertainty": 0.013139942349079083, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.00402777662085823, "uncertainty": 0.0009044655907834417, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.4525159021290258, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct", "scenario": "Angry Tweets", "executed": "2024-01-05-16-29", "scoring_id": "7ea34c2c-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4765625, "uncertainty": 0.030702866741079908, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6114649681528662, "uncertainty": 0.02924125394802242, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.28515625, "uncertainty": 0.02508928289662873, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.3762311406678518, "uncertainty": 0.028885019030778378, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.038766214661742536, "uncertainty": 0.0045864498849370475, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.38834209359265515, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B Instruct", "scenario": "Nordjylland News", "executed": "2024-01-05-16-25", "scoring_id": "7ea82d50-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7117045096556346, "uncertainty": 0.0233123745801171, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.1989880488624334, "uncertainty": 0.01810985343101045, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.27215805184933517, "uncertainty": 0.022506461266127847, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.015221611742551128, "uncertainty": 0.001703131162002796, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.6662785590393469, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B", "scenario": "Da. Cloze Self Test", "executed": "2024-01-05-16-19", "scoring_id": "83740e76-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.42, "uncertainty": 0.0692303539078101, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.42857142857142855, "uncertainty": 0.0695992298258873, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.2, "uncertainty": 0.04547149681957972, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.28571428571428575, "uncertainty": 0.057999358188239425, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.3597522008700319, "uncertainty": 0.06545921932389198, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03746224300217442, "uncertainty": 0.010247804195886886, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.6903216705191881, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B", "scenario": "DaNE", "executed": "2024-01-05-15-45", "scoring_id": "837a1f5a-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.04332129963898917, "uncertainty": 0.0051010762001007055, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 7.331830649769472, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B", "scenario": "#twitterhjerne", "executed": "2024-01-05-15-43", "scoring_id": "84a188dc-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 1.0, "uncertainty": 0.0, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.44871794871794873, "uncertainty": 0.055773351235951195, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5384615384615384, "uncertainty": 0.05603276217193235, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5095691766812761, "uncertainty": 0.05634564486667137, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.049438986473734466, "uncertainty": 0.010595684131351722, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.05536522169628174, "uncertainty": 0.011791808568997053, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5316315770913393, "uncertainty": 0.05614069984659044, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.08360016400390322, "uncertainty": 0.017273151344742176, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.09471651770126527, "uncertainty": 0.019332577730559852, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.48690979526593137, "uncertainty": 0.05632765628256777, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.019429270218490675, "uncertainty": 0.004295511239918964, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.02060468541097146, "uncertainty": 0.004549916810962279, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.013117989460275007, "uncertainty": 0.0029188512031910617, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 1.1797126152027302, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B", "scenario": "Angry Tweets", "executed": "2024-01-05-15-33", "scoring_id": "b212f56c-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.34375, "uncertainty": 0.02776554819550559, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.02985074626865672, "uncertainty": 0.0035644126487023153, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.28125, "uncertainty": 0.024880815915453058, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2297741475475044, "uncertainty": 0.02178278898195242, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.008869875964499981, "uncertainty": 0.001082037848286793, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 1.294308058641036, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 7B", "scenario": "Nordjylland News", "executed": "2024-01-05-15-26", "scoring_id": "b217e464-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.5367392089962959, "uncertainty": 0.028251259358358583, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.05069597466397126, "uncertainty": 0.005467990425607376, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.06329627157141011, "uncertainty": 0.006736422593263343, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.008612269227936243, "uncertainty": 0.0009700856574200655, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.5090639061573894, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B", "scenario": "Da. Cloze Self Test", "executed": "2024-01-05-15-13", "scoring_id": "b8f3d630-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.44, "uncertainty": 0.07002610510215276, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5714285714285715, "uncertainty": 0.0695992298258873, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.36, "uncertainty": 0.06547895542019477, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.5454545454545454, "uncertainty": 0.07046203019562972, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.27911850214600153, "uncertainty": 0.05718363683690438, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.029425442990768727, "uncertainty": 0.008116544608795812, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.119703773278743, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B", "scenario": "DaNE", "executed": "2024-01-05-14-56", "scoring_id": "b8faa7ee-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.04810996563573883, "uncertainty": 0.005636584940744654, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 3.5648044765548548, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B", "scenario": "#twitterhjerne", "executed": "2024-01-05-14-55", "scoring_id": "ba1b4e12-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9871794871794872, "uncertainty": 0.002853520295792841, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.47435897435897434, "uncertainty": 0.05621805569763319, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5, "uncertainty": 0.056366290518193855, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5040644449683336, "uncertainty": 0.05636256589844733, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.05458851201103428, "uncertainty": 0.011635942798988413, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.06325708118997603, "uncertainty": 0.013360078613950166, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5239643530967908, "uncertainty": 0.05623680808081183, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.08670919054717456, "uncertainty": 0.017854745548241173, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.10283953958179953, "uncertainty": 0.020802220465939714, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.483214292770777, "uncertainty": 0.05630276346152683, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.024094823280062964, "uncertainty": 0.005301647066722659, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.026658776112946765, "uncertainty": 0.005850389363409885, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.00875673341887215, "uncertainty": 0.0019570495651714493, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.5680747278428708, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B", "scenario": "Angry Tweets", "executed": "2024-01-05-14-49", "scoring_id": "e6b333cc-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4140625, "uncertainty": 0.02986148649273125, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.15217391304347827, "uncertainty": 0.01587966049057271, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.28515625, "uncertainty": 0.02508928289662873, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.374462610764668, "uncertainty": 0.028830751532588923, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.03850023238151372, "uncertainty": 0.004556241796292765, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.802469062327873, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Mistral 7B", "scenario": "Nordjylland News", "executed": "2024-01-05-14-46", "scoring_id": "e6b826b6-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.6163453696171443, "uncertainty": 0.02686665062178918, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.12077482697359125, "uncertainty": 0.01206494881514298, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.15642561613887582, "uncertainty": 0.014992712175183241, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.010880766822762476, "uncertainty": 0.0012228046907267213, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.7387422141556939, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 1106", "scenario": "Da. Cloze Self Test", "executed": "2024-01-04-13-53", "scoring_id": "eddacd36-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.92, "uncertainty": 0.020916888537006656, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9600000000000001, "uncertainty": 0.010913159236699109, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 0.00030880297999829053, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 1106", "scenario": "DaNE", "executed": "2024-01-04-13-52", "scoring_id": "edde891c-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.5107913669064749, "uncertainty": 0.030756144322343252, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.0943424258948653, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 1106", "scenario": "#twitterhjerne", "executed": "2024-01-04-13-52", "scoring_id": "eecc07b4-ae2b-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.4358974358974359, "uncertainty": 0.05543982288968968, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.3076923076923077, "uncertainty": 0.04802808186165631, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.34615384615384615, "uncertainty": 0.05102983697800982, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6301285661183871, "uncertainty": 0.05254838888540765, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.08721402156411097, "uncertainty": 0.017948771101003142, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.1164425657937111, "uncertainty": 0.02319668889231009, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6541981895764669, "uncertainty": 0.05100538694615181, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.13421790251803886, "uncertainty": 0.02619983130237885, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.1802492038732125, "uncertainty": 0.03331460346663988, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6052224888251378, "uncertainty": 0.05386999161493399, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.039247640082233366, "uncertainty": 0.008501674125333777, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.05181612082565065, "uncertainty": 0.011077376326542316, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.003245813431045136, "uncertainty": 0.0007294425070777918, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.00021317262703982682, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 1106", "scenario": "Angry Tweets", "executed": "2024-01-04-13-52", "scoring_id": "0e1c29be-ae2c-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.69921875, "uncertainty": 0.025885589203101564, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7105263157894737, "uncertainty": 0.02531532372079338, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.00011692824227793608, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 1106", "scenario": "Nordjylland News", "executed": "2024-01-04-13-52", "scoring_id": "0e1f47b6-ae2c-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7220087387164433, "uncertainty": 0.022804604462649373, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.2195023816011322, "uncertainty": 0.01946524009257681, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.30001350486272305, "uncertainty": 0.023860492947831127, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.014172522141598165, "uncertainty": 0.0015874388660574602, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.00015610460657626392, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4", "scenario": "Da. Cloze Self Test", "executed": "2024-01-04-13-51", "scoring_id": "123fc474-ae2c-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.9, "uncertainty": 0.025577716961013578, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9565217391304348, "uncertainty": 0.011819150874654454, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 0.00021978256292641164, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4", "scenario": "DaNE", "executed": "2024-01-04-12-41", "scoring_id": "12436566-ae2c-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.608, "uncertainty": 0.029334850248473574, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 16.337515170223014, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4", "scenario": "#twitterhjerne", "executed": "2024-01-04-12-41", "scoring_id": "130cd626-ae2c-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.34615384615384615, "uncertainty": 0.05102983697800982, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.14102564102564102, "uncertainty": 0.02731226568830301, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.20512820512820512, "uncertainty": 0.036762235499045566, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6339507712767675, "uncertainty": 0.05232081215064037, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.10280160823163442, "uncertainty": 0.02079542695174274, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.1389122684698227, "uncertainty": 0.026969161944892635, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6601360593086634, "uncertainty": 0.050584561672383815, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.15409638932285047, "uncertainty": 0.029389539925249463, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.20530389847782574, "uncertainty": 0.036785589892675205, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6071827190044599, "uncertainty": 0.05377611624141963, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.049234389557299106, "uncertainty": 0.010554106405650644, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.06632182038464582, "uncertainty": 0.013961532559295506, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.003608359994056324, "uncertainty": 0.0008106238554293306, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.00022118166686059572, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4", "scenario": "Angry Tweets", "executed": "2024-01-04-12-41", "scoring_id": "32318e16-ae2c-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.69921875, "uncertainty": 0.025885589203101564, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7362637362637362, "uncertainty": 0.023899977330013755, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.00015813589834579034, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4", "scenario": "Nordjylland News", "executed": "2024-01-04-12-41", "scoring_id": "3234c7fc-ae2c-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7269613492488861, "uncertainty": 0.022551965383004947, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.23324691477113652, "uncertainty": 0.02031984477559388, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.31564429612442385, "uncertainty": 0.024543064179336254, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.016240555067003393, "uncertainty": 0.0018152595462896618, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.0001713235133017103, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo Instruct", "scenario": "Da. Cloze Self Test", "executed": "2024-01-03-16-02", "scoring_id": "36623846-ae2c-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.62, "uncertainty": 0.06695677906683112, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8333333333333333, "uncertainty": 0.03947178543366296, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 0.3306750841997564, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo Instruct", "scenario": "DaNE", "executed": "2024-01-03-15-50", "scoring_id": "36662096-ae2c-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.31311154598825836, "uncertainty": 0.026471559545845288, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 2.6968115434456195, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo Instruct", "scenario": "#twitterhjerne", "executed": "2024-01-03-15-49", "scoring_id": "8ca6788e-ae2c-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.34615384615384615, "uncertainty": 0.05102983697800982, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.24358974358974358, "uncertainty": 0.041542808462127094, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.24358974358974358, "uncertainty": 0.041542808462127094, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6340242295311048, "uncertainty": 0.052316373874389026, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.09959400064037267, "uncertainty": 0.020218596452755717, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.13242833171242524, "uncertainty": 0.025903933418912034, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.659106833812518, "uncertainty": 0.05065864342018598, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.15305754195747698, "uncertainty": 0.029227258824137917, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.20506339561028525, "uncertainty": 0.03675361704857845, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6068583780374283, "uncertainty": 0.053791768550728716, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.04698383699039088, "uncertainty": 0.010095508374304037, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.060930330923513625, "uncertainty": 0.012900626344240518, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.003596891232658751, "uncertainty": 0.0008080566806649675, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.7850504054759557, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo Instruct", "scenario": "Angry Tweets", "executed": "2024-01-03-15-47", "scoring_id": "d12e828a-ae2c-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6640625, "uncertainty": 0.027457542926020814, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.55, "uncertainty": 0.030462772877354702, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.3154313512686713, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo Instruct", "scenario": "Nordjylland News", "executed": "2024-01-03-15-42", "scoring_id": "d1318890-ae2c-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.725343137383461, "uncertainty": 0.022635125525149374, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.2299710644118691, "uncertainty": 0.020120056056764955, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.3100713758740808, "uncertainty": 0.024306072326160093, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.015445752203231678, "uncertainty": 0.001727816668428168, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.9806408804701641, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "mGPT 13B", "scenario": "Da. Gym 2000", "executed": "2024-01-03-11-17", "scoring_id": "f26cbfee-db99-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.18181818181818182, "uncertainty": 0.052748119601782335, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.18181818181818182, "uncertainty": 0.052748119601782335, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.2213894474636776, "uncertainty": 0.06112192860575643, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.017491781561890813, "uncertainty": 0.006093826491976638, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 7.135719217726904, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "mGPT 13B", "scenario": "DaNE", "executed": "2024-01-03-10-19", "scoring_id": "f26f27d4-db99-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "NER F1", "value": 0.023255813953488372, "uncertainty": 0.002795803269796718, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 13.555485398534074, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "mGPT 13B", "scenario": "#twitterhjerne", "executed": "2024-01-03-10-16", "scoring_id": "f3cc3e64-db99-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 1.0, "uncertainty": 0.0, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.7051282051282052, "uncertainty": 0.04687926200231113, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.7051282051282052, "uncertainty": 0.04687926200231113, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.4722074520957265, "uncertainty": 0.05619213542826779, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.023174933622268835, "uncertainty": 0.005104047888675775, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.02794653116266054, "uncertainty": 0.006124878946474273, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.4862031015830162, "uncertainty": 0.056323372231209916, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.042156181291678925, "uncertainty": 0.00910406627274048, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.05128024325336298, "uncertainty": 0.0109690108832692, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.45742911979174, "uncertainty": 0.05595768454996239, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.007932362358678379, "uncertainty": 0.0017742845618855362, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.008940678779586627, "uncertainty": 0.001997788866173049, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.012992018077803107, "uncertainty": 0.002891190625589304, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 2.2187503757707487, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "mGPT 13B", "scenario": "HyggeSwag", "executed": "2024-01-03-10-09", "scoring_id": "1e1e76dc-db9a-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.24193548387096775, "uncertainty": 0.03260145244886115, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.24193548387096775, "uncertainty": 0.03260145244886115, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.22304588104490614, "uncertainty": 0.030804970132326567, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.01776694458424751, "uncertainty": 0.003102119361398305, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 3.4800239865773266, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "mGPT 13B", "scenario": "Angry Tweets", "executed": "2024-01-03-09-59", "scoring_id": "1e22b1fc-db9a-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.025641025641025644, "uncertainty": 0.0030750247228085686, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.3203125, "uncertainty": 0.02679645844517544, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.6188679245283019, "uncertainty": 0.029031381522767918, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.45312499432786574, "uncertainty": 0.030500033937188357, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.04531249932325008, "uncertainty": 0.005324434431570784, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 2.47152531176107, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "mGPT 13B", "scenario": "Nordjylland News", "executed": "2024-01-03-09-42", "scoring_id": "1e26a4ce-db9a-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.3783741863568624, "uncertainty": 0.02672387838639101, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.013269742088482755, "uncertainty": 0.0014876811968817525, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.016391846576872655, "uncertainty": 0.0018318881215285859, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.058546931685026116, "uncertainty": 0.006262557995489119, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 3.318113434645347, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Hestenettet LM", "scenario": "Angry Tweets", "executed": "2024-01-03-04-44", "scoring_id": "960b9396-db9a-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4140625, "uncertainty": 0.02986148649273125, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.15217391304347827, "uncertainty": 0.01587966049057271, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.28515625, "uncertainty": 0.02508928289662873, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.37446267957198925, "uncertainty": 0.028830753658924714, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.038500252022828856, "uncertainty": 0.004556244027635412, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 38.818311703173094, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Hestenettet LM", "scenario": "Nordjylland News", "executed": "2024-01-02-23-47", "scoring_id": "961795a6-db9a-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.6163453696171443, "uncertainty": 0.02686665062178918, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.12077482697359125, "uncertainty": 0.01206494881514298, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.15642561613887582, "uncertainty": 0.014992712175183241, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.010880766822762476, "uncertainty": 0.0012228046907267213, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 59.394208959216876, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Hestenettet LM", "scenario": "Citizenship Test", "executed": "2024-01-02-18-26", "scoring_id": "9d2aa00e-db9a-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4214876033057851, "uncertainty": 0.019468792261430383, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.3137254901960784, "uncertainty": 0.017190527775869144, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.428099173553719, "uncertainty": 0.01954819439457504, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.31451612903225806, "uncertainty": 0.017213996011849773, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.22745685353550185, "uncertainty": 0.014030182067284954, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.013212767051898708, "uncertainty": 0.0010410194307963296, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 31.816915237872806, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 002", "scenario": "Da. Cloze Self Test", "executed": "2024-01-02-21-12", "scoring_id": "4b24f79a-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36, "uncertainty": 0.06547895542019477, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.42857142857142855, "uncertainty": 0.0695992298258873, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 1.5909027396980673, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 002", "scenario": "DaNE", "executed": "2024-01-02-20-42", "scoring_id": "4b2b0004-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.08125, "uncertainty": 0.009187872311967302, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 6.8728154343089045, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 002", "scenario": "#twitterhjerne", "executed": "2024-01-02-20-40", "scoring_id": "4c737112-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9871794871794872, "uncertainty": 0.002853520295792841, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.4230769230769231, "uncertainty": 0.05503217713314785, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.41025641025641024, "uncertainty": 0.054550413966325685, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5169217199405544, "uncertainty": 0.05630172978525055, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.060412989224786905, "uncertainty": 0.012798137606144776, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.070160665127684, "uncertainty": 0.014708929205526926, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.539635011400932, "uncertainty": 0.05601209960024914, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.09650161459475773, "uncertainty": 0.019658093960061927, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.1140677697224066, "uncertainty": 0.02278467813173314, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.49065833252209884, "uncertainty": 0.05634661490597573, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.026900330941110957, "uncertainty": 0.0059019346151725155, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.029086930477706625, "uncertainty": 0.006367334801166774, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.008141124647898743, "uncertainty": 0.0018205966283530738, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 1.6835558229478267, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 002", "scenario": "Angry Tweets", "executed": "2024-01-02-20-29", "scoring_id": "7dfd703e-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.44140625, "uncertainty": 0.03034790944880782, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.09523809523809525, "uncertainty": 0.010605697513360166, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 1.6607854936755757, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 002", "scenario": "Nordjylland News", "executed": "2024-01-02-20-22", "scoring_id": "7e00fb64-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.5543679994344711, "uncertainty": 0.02806877560670821, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.06976062018601677, "uncertainty": 0.00737316579061294, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.08949965228595451, "uncertainty": 0.009258708477687788, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.010464754272834397, "uncertainty": 0.001176546912861723, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.5266670223930852, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Babbage 002", "scenario": "Da. Cloze Self Test", "executed": "2024-01-02-20-05", "scoring_id": "84c07f9c-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36, "uncertainty": 0.06547895542019477, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5000000000000001, "uncertainty": 0.0710492137805933, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 0.7874375885585323, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Babbage 002", "scenario": "DaNE", "executed": "2024-01-02-19-47", "scoring_id": "84c65b24-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.11912225705329153, "uncertainty": 0.012915248882706587, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 4.064488099023947, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Babbage 002", "scenario": "#twitterhjerne", "executed": "2024-01-02-19-45", "scoring_id": "85f0afd6-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9871794871794872, "uncertainty": 0.002853520295792841, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.44871794871794873, "uncertainty": 0.055773351235951195, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5128205128205128, "uncertainty": 0.056329231813053694, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5120929805641501, "uncertainty": 0.056333318452551004, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.04865042138585862, "uncertainty": 0.01043532987980946, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.05615863151114802, "uncertainty": 0.011950744755101014, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5358660706342795, "uncertainty": 0.05607625776520471, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.08202496960562379, "uncertainty": 0.01697682189250248, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.09487514646448181, "uncertainty": 0.01936156219524155, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.4874951476470018, "uncertainty": 0.05633103423039746, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.019800618026888005, "uncertainty": 0.004375952672344408, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.022340280806564798, "uncertainty": 0.004924428042960577, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.009784550267235877, "uncertainty": 0.0021844897580082815, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.9984522193837433, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Babbage 002", "scenario": "Angry Tweets", "executed": "2024-01-02-19-39", "scoring_id": "b8841866-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.34765625, "uncertainty": 0.027913916587513497, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.030303030303030307, "uncertainty": 0.003616731992376847, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.9913096503323686, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Babbage 002", "scenario": "Nordjylland News", "executed": "2024-01-02-19-34", "scoring_id": "b8876f7a-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.4902825661500295, "uncertainty": 0.028393889280261923, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.014432331122413655, "uncertainty": 0.001616113576067946, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.014853137213412951, "uncertainty": 0.0016625247436742995, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.006067971414886415, "uncertainty": 0.0006852501791989841, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.9896903053733209, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Google Gemini Pro", "scenario": "Da. Cloze Self Test", "executed": "2023-12-27-09-18", "scoring_id": "bf22d2e8-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.8, "uncertainty": 0.0454714968195797, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8695652173913043, "uncertainty": 0.032234047839966716, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 0.7746840693592094, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Google Gemini Pro", "scenario": "DaNE", "executed": "2023-12-27-08-59", "scoring_id": "bf268b54-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.3881578947368421, "uncertainty": 0.0292308883114464, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 4.25328927452756, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Google Gemini Pro", "scenario": "#twitterhjerne", "executed": "2023-12-27-08-58", "scoring_id": "bfefa278-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.3076923076923077, "uncertainty": 0.04802808186165631, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.24358974358974358, "uncertainty": 0.041542808462127094, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.20512820512820512, "uncertainty": 0.036762235499045566, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6345504310650703, "uncertainty": 0.05228451014600119, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.10351985317917697, "uncertainty": 0.020923954630058174, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.13814144052269134, "uncertainty": 0.026843517604113, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6624938387137193, "uncertainty": 0.05041305254915886, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.15618416172032681, "uncertainty": 0.029714204624236663, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.21458626216733093, "uncertainty": 0.03799967255745894, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6056144688373957, "uncertainty": 0.05385135830065759, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.04956167585606681, "uncertainty": 0.010620607738536661, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.0627877248319795, "uncertainty": 0.013267593610078007, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.005246421683412523, "uncertainty": 0.0011766793999863205, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.9962853956027314, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Google Gemini Pro", "scenario": "Angry Tweets", "executed": "2023-12-27-08-52", "scoring_id": "ddaabffa-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.9007400582345326, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Google Gemini Pro", "scenario": "Nordjylland News", "executed": "2023-12-27-08-52", "scoring_id": "ddadb570-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.736829720934232, "uncertainty": 0.02203194923855022, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.2778885768203802, "uncertainty": 0.022799422978518183, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.34956074659658887, "uncertainty": 0.025833208362959183, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.018346145356772467, "uncertainty": 0.002046219185513557, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.00014685400994494558, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 003", "scenario": "Da. Gym 2000", "executed": "2023-12-26-16-22", "scoring_id": "a05a6dc2-db9a-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5454545454545454, "uncertainty": 0.08791353266963722, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7692307692307692, "uncertainty": 0.0629440085977876, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 0.000271157938352024, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 003", "scenario": "Da. Cloze Self Test", "executed": "2023-12-24-01-23", "scoring_id": "a05c9dfe-db9a-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6, "uncertainty": 0.06820724522936956, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7826086956521738, "uncertainty": 0.04835107175995008, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 0.0002200246002757922, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 003", "scenario": "DaNE", "executed": "2023-12-24-01-06", "scoring_id": "a05fab16-db9a-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "NER F1", "value": 0.40695652173913044, "uncertainty": 0.029704946618250756, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 3.8291618820898066, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 003", "scenario": "#twitterhjerne", "executed": "2023-12-24-01-05", "scoring_id": "a13b972a-db9a-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.32051282051282054, "uncertainty": 0.04910278431072115, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.2564102564102564, "uncertainty": 0.042988097962593605, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.2692307692307692, "uncertainty": 0.04435927005277979, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6331687009487397, "uncertainty": 0.052367913223872395, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.09888904628325303, "uncertainty": 0.020091201225510776, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.12917887236843412, "uncertainty": 0.02536295741125821, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6588708689579597, "uncertainty": 0.05067556042356015, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.1602196773858482, "uncertainty": 0.03033618702828325, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.21038032772689005, "uncertainty": 0.037454373153021414, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6064616846732604, "uncertainty": 0.053810848010974806, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.03902032313615526, "uncertainty": 0.008454433466972187, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.051837212862459445, "uncertainty": 0.011081638920590517, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0035490320035769865, "uncertainty": 0.0007973432005429051, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 1.1003405564231052, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 003", "scenario": "HyggeSwag", "executed": "2023-12-24-01-04", "scoring_id": "bebeb41c-db9a-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5564516129032258, "uncertainty": 0.04387323122107378, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7999999999999999, "uncertainty": 0.02844141462999655, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 0.5404774214999164, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 003", "scenario": "Angry Tweets", "executed": "2023-12-24-01-02", "scoring_id": "bec1c6b6-db9a-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5, "uncertainty": 0.030770477653893638, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6270270270270271, "uncertainty": 0.028784444486984914, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.3933784757422245, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 003", "scenario": "Nordjylland News", "executed": "2023-12-24-00-56", "scoring_id": "bec40bba-db9a-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7313240977128347, "uncertainty": 0.022324798412402067, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.24304361991572562, "uncertainty": 0.020902778802093475, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.31118902569249873, "uncertainty": 0.02435416682595438, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.014631454134359956, "uncertainty": 0.0016380800879068058, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.1206945577433605, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI Davinci 003", "scenario": "Citizenship Test", "executed": "2023-12-24-00-53", "scoring_id": "c28da51c-db9a-11ee-9b0f-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6859504132231405, "uncertainty": 0.017200159885868746, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7405541561712846, "uncertainty": 0.015340696473157006, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.3530606422347232, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo", "scenario": "Da. Cloze Self Test", "executed": "2023-12-24-00-52", "scoring_id": "e15d8b50-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.82, "uncertainty": 0.04194745581606229, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8799999999999999, "uncertainty": 0.030011187900922633, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 0.00021823548013344407, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo", "scenario": "DaNE", "executed": "2023-12-24-00-37", "scoring_id": "e1615a82-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.3380281690140845, "uncertainty": 0.027541439233161692, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 3.3818004145937266, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo", "scenario": "#twitterhjerne", "executed": "2023-12-24-00-36", "scoring_id": "e24bd6f2-ae32-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.2948717948717949, "uncertainty": 0.046879262002311135, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.24358974358974358, "uncertainty": 0.041542808462127094, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.21794871794871795, "uncertainty": 0.038429877230353085, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6389120967214943, "uncertainty": 0.05201558609690747, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.10007505780023987, "uncertainty": 0.020305401651629435, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.13468865858739057, "uncertainty": 0.02627742889722727, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.664695353844227, "uncertainty": 0.05025064729681559, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.15658616405440037, "uncertainty": 0.02977649341854477, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.21254500018026384, "uncertainty": 0.03773601919348389, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6113945092910376, "uncertainty": 0.053568552686966885, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.048645367258028274, "uncertainty": 0.010434301221504804, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.06588488263688635, "uncertainty": 0.013876042562067389, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.003637337221358067, "uncertainty": 0.0008171098719653954, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.9859193268971583, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo", "scenario": "Angry Tweets", "executed": "2023-12-24-00-33", "scoring_id": "0040b326-ae33-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.671875, "uncertainty": 0.027134513009244098, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6614173228346457, "uncertainty": 0.02756351051791526, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.4187816126718644, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "OpenAI GPT 3.5 Turbo", "scenario": "Nordjylland News", "executed": "2023-12-24-00-27", "scoring_id": "004387f4-ae33-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7304507311185201, "uncertainty": 0.022370620595714635, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.24557735509540668, "uncertainty": 0.021049994146114564, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.32439066843057024, "uncertainty": 0.024900779239153393, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.01688373862261263, "uncertainty": 0.0018859164376948195, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.0951127608067084, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Constant Baseline", "scenario": "Da. Cloze Self Test", "executed": "2023-12-23-20-07", "scoring_id": "0443aa78-ae33-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.34, "uncertainty": 0.06377377428946053, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.32, "uncertainty": 0.061841235674628396, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.1875, "uncertainty": 0.04329561464754904, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.004000000000000001, "uncertainty": 0.0011322402708075349, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 0.00026034344045910984, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Constant Baseline", "scenario": "Da. Gym 2000", "executed": "2023-12-23-20-07", "scoring_id": "04482044-ae33-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.1875, "uncertainty": 0.05401874487864818, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.0022727272727272717, "uncertainty": 0.0008040425175410566, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 0.0003518807881681079, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Constant Baseline", "scenario": "DaNE", "executed": "2023-12-23-20-06", "scoring_id": "044df528-ae33-11ee-8ef9-b83fd2977436", "metrics": [{"name": "NER F1", "value": 0.0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.08893299106637187, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Constant Baseline", "scenario": "#twitterhjerne", "executed": "2023-12-23-20-06", "scoring_id": "0510701c-ae33-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 1.0, "uncertainty": 0.0, "higher_is_better": false, "N": 59}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.4406779661016949, "uncertainty": 0.06423327138108706, "higher_is_better": false, "N": 59}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.4406779661016949, "uncertainty": 0.06423327138108706, "higher_is_better": false, "N": 59}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.4438345299602228, "uncertainty": 0.06432827198172882, "higher_is_better": true, "N": 59}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.05912273309027137, "uncertainty": 0.014496536523517036, "higher_is_better": true, "N": 59}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.08140074883771133, "uncertainty": 0.019486384321565093, "higher_is_better": true, "N": 59}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.45981162836996176, "uncertainty": 0.06472945609015042, "higher_is_better": true, "N": 59}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.09242107392908774, "uncertainty": 0.02185909563942202, "higher_is_better": true, "N": 59}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.1267486056805615, "uncertainty": 0.02884425024640574, "higher_is_better": true, "N": 59}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.4305738473342637, "uncertainty": 0.06389425839096641, "higher_is_better": true, "N": 59}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.029147729259892025, "uncertainty": 0.007374535220442992, "higher_is_better": true, "N": 59}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.035231507572790505, "uncertainty": 0.008857906984389916, "higher_is_better": true, "N": 59}, {"name": "Generated Text Offensive Prob", "value": 0.009489454329013824, "uncertainty": 0.002449498174673105, "higher_is_better": false, "N": 59}, {"name": "Inference seconds", "value": 0.0002633663051232885, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Constant Baseline", "scenario": "HyggeSwag", "executed": "2023-12-23-20-06", "scoring_id": "1c0f7ede-ae33-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.25, "uncertainty": 0.0372040678407878, "higher_is_better": true, "N": 100}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 100}, {"name": "Accuracy (LM)", "value": 0.25, "uncertainty": 0.0372040678407878, "higher_is_better": true, "N": 100}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 100}, {"name": "Brier Score (LM)", "value": 0.1875, "uncertainty": 0.03022830512064009, "higher_is_better": false, "N": 100}, {"name": "ECE Calibration (LM)", "value": 0.0024999999999999996, "uncertainty": 0.0004948141022824777, "higher_is_better": false, "N": 100}, {"name": "Inference seconds", "value": 0.00028643294994253667, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Constant Baseline", "scenario": "Angry Tweets", "executed": "2023-12-23-20-06", "scoring_id": "1c12e9fc-ae33-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2222222222222223, "uncertainty": 0.021273416649605484, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.004079861111111094, "uncertainty": 0.000500108369375321, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.0001316767226171578, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Constant Baseline", "scenario": "Nordjylland News", "executed": "2023-12-23-20-06", "scoring_id": "1c16a6c8-ae33-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.43089988897244136, "uncertainty": 0.02786210974287749, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.07739510173801453, "uncertainty": 0.008112938380883384, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.11267702865194659, "uncertainty": 0.01135967893167194, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.009489454515278339, "uncertainty": 0.0010679460114115995, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.00016618853667750954, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Constant Baseline", "scenario": "Citizenship Test", "executed": "2023-12-23-20-06", "scoring_id": "1fab27f0-ae33-11ee-8ef9-b83fd2977436", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.36363636363636365, "uncertainty": 0.018476265597122166, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.36363636363636365, "uncertainty": 0.018476265597122166, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.20955004591368231, "uncertainty": 0.013225243426377157, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.004113865932047754, "uncertainty": 0.00032711567497832383, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.00038487281157704425, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Starling-LM-7B-beta", "scenario": "Citizenship Test", "executed": "2024-04-17-15-28", "scoring_id": "183f96f4-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.44958677685950416, "uncertainty": 0.019758042889314494, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.45890410958904104, "uncertainty": 0.019826119431536476, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.5619834710743802, "uncertainty": 0.019654209330586862, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.5647840531561462, "uncertainty": 0.019625862934577035, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.1775136068346369, "uncertainty": 0.011657405561943413, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.009950580536784574, "uncertainty": 0.0007865871152540301, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.7713248658049534, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Starling-LM-7B-beta", "scenario": "Nordjylland News", "executed": "2024-04-17-15-37", "scoring_id": "18477676-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7065004307031632, "uncertainty": 0.02355965058853601, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.189218860305218, "uncertainty": 0.01743078740021942, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.26646348551994964, "uncertainty": 0.02220794574326104, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.013614426859421656, "uncertainty": 0.001525790901219038, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.6338279390233219, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Starling-LM-7B-beta", "scenario": "Angry Tweets", "executed": "2024-04-17-15-40", "scoring_id": "29dc69c8-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6953125, "uncertainty": 0.02607527537516231, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7019867549668874, "uncertainty": 0.025748901962031955, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.28515625, "uncertainty": 0.02508928289662873, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.3808355824591092, "uncertainty": 0.02902269502601044, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.03905752794999177, "uncertainty": 0.004619514879924719, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.6355140673593951, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Starling-LM-7B-beta", "scenario": "HyggeSwag", "executed": "2024-04-17-15-43", "scoring_id": "29e190ba-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.27419354838709675, "uncertainty": 0.035376044146636566, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.36363636363636365, "uncertainty": 0.04113427735743302, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.29838709677419356, "uncertainty": 0.03721421114641279, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.08333333333333333, "uncertainty": 0.013578800387585153, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.19713986788805266, "uncertainty": 0.028134912237098422, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.012404022903361843, "uncertainty": 0.0021775748034846246, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.402608288903256, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Starling-LM-7B-beta", "scenario": "#twitterhjerne", "executed": "2024-04-17-15-46", "scoring_id": "29e591ec-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.717948717948718, "uncertainty": 0.045656324732685626, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.2692307692307692, "uncertainty": 0.04435927005277979, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.2948717948717949, "uncertainty": 0.046879262002311135, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5958396539919907, "uncertainty": 0.054295339055859176, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.07745056033883849, "uncertainty": 0.01610993023141245, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.11166180099000723, "uncertainty": 0.022364665745316776, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6223192803370647, "uncertainty": 0.05299287933332093, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.11621701278235233, "uncertainty": 0.02315766629681816, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.1680119259337705, "uncertainty": 0.03151640387985688, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5660336873470209, "uncertainty": 0.05538316143368199, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.03622500159685227, "uncertainty": 0.007871609030190616, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.05101014649240936, "uncertainty": 0.010914342693087206, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0026493250572970375, "uncertainty": 0.0005957479807567246, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.65302073667949, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Starling-LM-7B-beta", "scenario": "DaNE", "executed": "2024-04-17-15-46", "scoring_id": "52e4f8a8-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "NER F1", "value": 0.1086261980830671, "uncertainty": 0.011917596424372408, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 4.194642334750029, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Starling-LM-7B-beta", "scenario": "Da. Gym 2000", "executed": "2024-04-17-16-04", "scoring_id": "542ed30a-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.48484848484848486, "uncertainty": 0.08856474402274564, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.888888888888889, "uncertainty": 0.03502069943383077, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.3333333333333333, "uncertainty": 0.07879657372611928, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.22222222222222224, "uncertainty": 0.061286224009203895, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.20906403887809194, "uncertainty": 0.05863278260878843, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.018871405001272715, "uncertainty": 0.006565231068620442, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 3.6425555572733916, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Starling-LM-7B-beta", "scenario": "Da. Cloze Self Test", "executed": "2024-04-17-16-06", "scoring_id": "543259b2-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3, "uncertainty": 0.059681339575698364, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5555555555555556, "uncertainty": 0.07017206299317855, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.32, "uncertainty": 0.061841235674628396, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.36363636363636365, "uncertainty": 0.06576456151592107, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.2665934032137702, "uncertainty": 0.055566555785137264, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.0268775900947792, "uncertainty": 0.007433221391907441, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.2263283034402412, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B Instruct", "scenario": "Citizenship Test", "executed": "2024-04-18-21-10", "scoring_id": "54392b66-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6, "uncertainty": 0.019162526890729562, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6629834254143646, "uncertainty": 0.01784002534010719, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.39669421487603307, "uncertainty": 0.01910886500953839, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.21951219512195122, "uncertainty": 0.01367937672152021, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.23323355305589186, "uncertainty": 0.014278929988064529, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.016335701083889053, "uncertainty": 0.001282998719567769, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 1.6145094992892628, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B Instruct", "scenario": "Nordjylland News", "executed": "2024-04-18-21-26", "scoring_id": "544110e2-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.6022124399741491, "uncertainty": 0.027217602420314305, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.0957581825992252, "uncertainty": 0.009838059128085391, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.1326097238265579, "uncertainty": 0.013068894911488244, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.02511239092020939, "uncertainty": 0.002781580030429377, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.3933271755700116, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B Instruct", "scenario": "Angry Tweets", "executed": "2024-04-18-21-33", "scoring_id": "5bf3f048-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.54296875, "uncertainty": 0.03054322986360304, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.375, "uncertainty": 0.028847322800525287, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.453125, "uncertainty": 0.030500034002638714, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.6732673267326732, "uncertainty": 0.027075365887790345, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.23249152986838642, "uncertainty": 0.02196263993038719, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.017362517647935873, "uncertainty": 0.002099907939328366, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 1.6323952851562353, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B Instruct", "scenario": "HyggeSwag", "executed": "2024-04-18-21-40", "scoring_id": "5bf8f0d4-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4274193548387097, "uncertainty": 0.04350328566137039, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5945945945945946, "uncertainty": 0.042849099835184715, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.22580645161290322, "uncertainty": 0.03107542701508467, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.27586206896551724, "uncertainty": 0.03550949507906822, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.2129319873254397, "uncertainty": 0.029790951950412935, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.014064263714415666, "uncertainty": 0.0024648859000952557, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 2.7190418577177504, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B Instruct", "scenario": "#twitterhjerne", "executed": "2024-04-18-21-46", "scoring_id": "5bfcae2c-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 1.0, "uncertainty": 0.0, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.3974358974358974, "uncertainty": 0.05399453338922318, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.48717948717948717, "uncertainty": 0.05632923181305369, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5107386849438533, "uncertainty": 0.05634029002128122, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.061995735096603576, "uncertainty": 0.013111309611072552, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.07020379087448857, "uncertainty": 0.014717287745796191, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5307078116979355, "uncertainty": 0.0561536837021169, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.09350031382105285, "uncertainty": 0.019109977365047503, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.10998561872460322, "uncertainty": 0.02207051018855501, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.4882222715860758, "uncertainty": 0.056335015143806455, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.030500931191070935, "uncertainty": 0.006667145620131786, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.032681632771737724, "uncertainty": 0.007127752742992502, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.009676650981418788, "uncertainty": 0.0021606356710005136, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.9793772624230209, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B Instruct", "scenario": "DaNE", "executed": "2024-04-18-21-47", "scoring_id": "8a0b1920-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "NER F1", "value": 0.058997050147492625, "uncertainty": 0.00683306436358338, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 7.272252524347664, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B Instruct", "scenario": "Da. Gym 2000", "executed": "2024-04-18-22-18", "scoring_id": "8b491f08-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3333333333333333, "uncertainty": 0.07879657372611928, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6666666666666666, "uncertainty": 0.07879657372611928, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.18181818181818182, "uncertainty": 0.052748119601782335, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.24418743458593317, "uncertainty": 0.06544210607810133, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.022558707023290252, "uncertainty": 0.007818523281230514, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 5.966995946576142, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B Instruct", "scenario": "Da. Cloze Self Test", "executed": "2024-04-18-22-22", "scoring_id": "8b4c8706-fe06-11ee-9824-b83fd2ad0f00", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4, "uncertainty": 0.06820724522936956, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7272727272727272, "uncertainty": 0.05636962415650378, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.24, "uncertainty": 0.05183750637432087, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.5, "uncertainty": 0.0710492137805933, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.3593532110926725, "uncertainty": 0.06542736822590094, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.036945554852049145, "uncertainty": 0.010111889174950582, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 2.033060621499899, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B", "scenario": "Citizenship Test", "executed": "2024-04-19-06-31", "scoring_id": "e6c6f754-fef8-11ee-97c7-b83fd2979c02", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4, "uncertainty": 0.019162526890729562, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.3512544802867384, "uncertainty": 0.018194401728510733, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.43471074380165287, "uncertainty": 0.019620616120410276, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.3261802575107296, "uncertainty": 0.017548618724187923, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.21240159133987113, "uncertainty": 0.013356852552511869, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.009245394856082377, "uncertainty": 0.0007313631916092032, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 1.6252218897537183, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B", "scenario": "Nordjylland News", "executed": "2024-04-19-06-48", "scoring_id": "e6cebee4-fef8-11ee-97c7-b83fd2979c02", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.6442219364643097, "uncertainty": 0.026041357632468305, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.12095876201845628, "uncertainty": 0.012080795384178668, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.17193048722411874, "uncertainty": 0.01617590677326226, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.008522465705949193, "uncertainty": 0.000960057149943095, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.4032115286165694, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B", "scenario": "Angry Tweets", "executed": "2024-04-19-06-55", "scoring_id": "f72cd186-fef8-11ee-97c7-b83fd2979c02", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.31640625, "uncertainty": 0.026621796920406636, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5070422535211268, "uncertainty": 0.030764373611510402, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.29296875, "uncertainty": 0.025494948373511118, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.5932203389830509, "uncertainty": 0.029700891961241777, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.34644227669231903, "uncertainty": 0.02786820935402142, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.03304139242390298, "uncertainty": 0.003932425049923465, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 1.6344588090039451, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B", "scenario": "HyggeSwag", "executed": "2024-04-19-07-02", "scoring_id": "f734d1f6-fef8-11ee-97c7-b83fd2979c02", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.25806451612903225, "uncertainty": 0.03403499149271179, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.28225806451612906, "uncertainty": 0.03601188807737678, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.23999999999999996, "uncertainty": 0.032423212678196055, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.20209418260047418, "uncertainty": 0.028663990734376994, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.008579936840586524, "uncertainty": 0.0015120738590716858, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 2.7415266243065894, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B", "scenario": "#twitterhjerne", "executed": "2024-04-19-07-08", "scoring_id": "f738d0ee-fef8-11ee-97c7-b83fd2979c02", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9871794871794872, "uncertainty": 0.002853520295792841, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.48717948717948717, "uncertainty": 0.05632923181305369, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5256410256410257, "uncertainty": 0.05621805569763319, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.47709443061652335, "uncertainty": 0.056247996814408556, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.057585720844638394, "uncertainty": 0.012235905422103741, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.06783439283829383, "uncertainty": 0.01425681333821802, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.4958246193635158, "uncertainty": 0.056362359802871305, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.09199300671805646, "uncertainty": 0.018833171146864166, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.10997048973065048, "uncertainty": 0.022067849411200897, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.4572043636670479, "uncertainty": 0.05595335862938853, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.02594623149557573, "uncertainty": 0.005698186580012364, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.02990817993340995, "uncertainty": 0.006541574222814435, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.019622117244393732, "uncertainty": 0.0043372935603758, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.9879095815256453, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B", "scenario": "DaNE", "executed": "2024-04-19-07-09", "scoring_id": "25208a60-fef9-11ee-97c7-b83fd2979c02", "metrics": [{"name": "NER F1", "value": 0.04810996563573883, "uncertainty": 0.005636584940744654, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 7.313394851648354, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B", "scenario": "Da. Gym 2000", "executed": "2024-04-19-07-40", "scoring_id": "266e7f80-fef9-11ee-97c7-b83fd2979c02", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.2727272727272727, "uncertainty": 0.07033082613570978, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.24242424242424243, "uncertainty": 0.06512113531084239, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.2, "uncertainty": 0.0567335330828059, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.20228923106419627, "uncertainty": 0.05721871047802109, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.015097755242874062, "uncertainty": 0.005272606434026845, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 5.8291835792726046, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 8B", "scenario": "Da. Cloze Self Test", "executed": "2024-04-19-07-43", "scoring_id": "2671defa-fef9-11ee-97c7-b83fd2979c02", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4, "uncertainty": 0.06820724522936956, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5000000000000001, "uncertainty": 0.0710492137805933, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.18, "uncertainty": 0.04194745581606228, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4444444444444445, "uncertainty": 0.07017206299317856, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.3919901056695831, "uncertainty": 0.06773373425610467, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03818702776569983, "uncertainty": 0.010438203392239411, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 2.0478029756399336, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 70B (@ Groq)", "scenario": "Angry Tweets", "executed": "2024-04-20-08-35", "scoring_id": "cb53ad32-ff52-11ee-b1f1-b83fd2ad1a28", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3984375, "uncertainty": 0.029500894957724687, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.00012362017582745466, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 70B (@ Groq)", "scenario": "Citizenship Test", "executed": "2024-04-20-08-34", "scoring_id": "cb59a5a2-ff52-11ee-b1f1-b83fd2ad1a28", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.8661157024793389, "uncertainty": 0.009258637745032503, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8837209302325582, "uncertainty": 0.00820461535343117, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.00036305129751255195, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Opus", "scenario": "DaNE", "executed": "2024-04-24-07-28", "scoring_id": "9546763e-020e-11ef-9006-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.4349157733537519, "uncertainty": 0.030249108027433174, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 27.761413026765695, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 70B (@ Groq)", "scenario": "Da. Cloze Self Test", "executed": "2024-04-20-09-09", "scoring_id": "cb5cae0a-ff52-11ee-b1f1-b83fd2ad1a28", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.62, "uncertainty": 0.06695677906683112, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9, "uncertainty": 0.025577716961013578, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 2.5248806737794074, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 70B (@ Groq)", "scenario": "Da. Gym 2000", "executed": "2024-04-20-09-07", "scoring_id": "cb6020b2-ff52-11ee-b1f1-b83fd2ad1a28", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6666666666666666, "uncertainty": 0.07879657372611928, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8333333333333333, "uncertainty": 0.04924785857882458, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 2.6918855155447754, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 70B (@ Groq)", "scenario": "DaNE", "executed": "2024-04-20-08-35", "scoring_id": "cb62468a-ff52-11ee-b1f1-b83fd2ad1a28", "metrics": [{"name": "NER F1", "value": 0.38251366120218583, "uncertainty": 0.029071573142500366, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 7.630544226398342, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 70B (@ Groq)", "scenario": "HyggeSwag", "executed": "2024-04-20-08-35", "scoring_id": "cc567a98-ff52-11ee-b1f1-b83fd2ad1a28", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6693548387096774, "uncertainty": 0.03934139811470728, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7999999999999999, "uncertainty": 0.02844141462999655, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 0.00023876480671817496, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 70B (@ Groq)", "scenario": "Nordjylland News", "executed": "2024-04-20-08-35", "scoring_id": "d7e75602-ff52-11ee-b1f1-b83fd2ad1a28", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7338526801268259, "uncertainty": 0.022191156068111156, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.25575641856054415, "uncertainty": 0.021626716418124307, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.3375786234398664, "uncertainty": 0.02540728286430704, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.016664228612789884, "uncertainty": 0.0018618127451518116, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.0001890160032780841, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3 70B (@ Groq)", "scenario": "#twitterhjerne", "executed": "2024-04-20-08-35", "scoring_id": "facc5cf8-ff52-11ee-b1f1-b83fd2ad1a28", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.32051282051282054, "uncertainty": 0.04910278431072115, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.23076923076923078, "uncertainty": 0.040023401551380254, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.19230769230769232, "uncertainty": 0.035020476357457725, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6346899915709455, "uncertainty": 0.05227603821822634, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.0994891062213779, "uncertainty": 0.020199654738455558, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.13496264630551907, "uncertainty": 0.026322545958007634, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6587542761594821, "uncertainty": 0.05068391003083688, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.14959664556715452, "uncertainty": 0.028683111821467766, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.20131833339271182, "uncertainty": 0.03625237702376303, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6045976754946586, "uncertainty": 0.053899549744979895, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.04729360145970991, "uncertainty": 0.01015876503092767, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.06592948649239772, "uncertainty": 0.013884773571150045, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.003635353017717791, "uncertainty": 0.0008166657567447263, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.00023484693613285437, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 2024-04-09", "scenario": "Citizenship Test", "executed": "2024-04-24-06-29", "scoring_id": "97b9f062-020e-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.9818181818181818, "uncertainty": 0.0014253119174922817, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9774436090225564, "uncertainty": 0.001760365549066395, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.7504444941522338, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Opus", "scenario": "Citizenship Test", "executed": "2024-04-24-06-29", "scoring_id": "97bd21b0-020e-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.9752066115702479, "uncertainty": 0.001930518896511586, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9777777777777776, "uncertainty": 0.0017348789777615352, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 1.596441911555411, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 (@ Groq)", "scenario": "Citizenship Test", "executed": "2024-04-24-08-20", "scoring_id": "27a32bf8-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5371900826446281, "uncertainty": 0.01985053328616431, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5740181268882175, "uncertainty": 0.019523526292911597, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.0003579041439547273, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 2024-04-09", "scenario": "Nordjylland News", "executed": "2024-04-24-06-36", "scoring_id": "97c45700-020e-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7242373651266099, "uncertainty": 0.022691609090697437, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.22389206481655577, "uncertainty": 0.019742846612224536, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.3063563204772042, "uncertainty": 0.024144166871377243, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.014854775128575663, "uncertainty": 0.0016627053125272343, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 3.2270918313766983, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 2024-04-09", "scenario": "Angry Tweets", "executed": "2024-04-24-06-52", "scoring_id": "a6e70390-020e-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6875, "uncertainty": 0.026443379233814845, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6956521739130435, "uncertainty": 0.026058930035811625, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.8276714318162703, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 2024-04-09", "scenario": "HyggeSwag", "executed": "2024-04-24-06-56", "scoring_id": "a6ea8916-020e-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.8467741935483871, "uncertainty": 0.023063793487758156, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9302325581395349, "uncertainty": 0.011536539195509688, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 0.8092701721855725, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 2024-04-09", "scenario": "#twitterhjerne", "executed": "2024-04-24-06-58", "scoring_id": "a6ed32ec-020e-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.4230769230769231, "uncertainty": 0.05503217713314785, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.2948717948717949, "uncertainty": 0.046879262002311135, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.28205128205128205, "uncertainty": 0.045656324732685626, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6328831473349507, "uncertainty": 0.05238504227821128, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.09108845465654361, "uncertainty": 0.018666564714168953, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.12185509728125136, "uncertainty": 0.024126222657225586, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.657833836781673, "uncertainty": 0.05074961061642387, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.14065802890318305, "uncertainty": 0.027252728953867027, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.18954340300327016, "uncertainty": 0.03463521447399968, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6062923769156138, "uncertainty": 0.05381896947198442, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.04215635089300611, "uncertainty": 0.009104101287888204, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.0550989411276403, "uncertainty": 0.011738403513443237, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0027075022673950745, "uncertainty": 0.0006087946497093977, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 3.14585919151208, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 (@ Groq)", "scenario": "Nordjylland News", "executed": "2024-04-24-08-20", "scoring_id": "27a74026-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7141054958105088, "uncertainty": 0.023196215152392907, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.195553063261051, "uncertainty": 0.017873556258083442, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.2591173205480888, "uncertainty": 0.02181196699881703, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.015486067798143873, "uncertainty": 0.0017322555785562038, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.0001744274131488055, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Opus", "scenario": "Nordjylland News", "executed": "2024-04-24-06-45", "scoring_id": "cce2ac5c-020e-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7320408469438553, "uncertainty": 0.022287063846669754, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.24537464605024453, "uncertainty": 0.021038270011172495, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.32396179486742277, "uncertainty": 0.024883644172365486, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.016607350596459583, "uncertainty": 0.0018555653658537381, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 4.831654539576654, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Opus", "scenario": "Angry Tweets", "executed": "2024-04-24-07-09", "scoring_id": "d12c0f60-020e-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.703125, "uncertainty": 0.025692146869217832, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7380952380952381, "uncertainty": 0.02379304507931458, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 1.6473593249415899, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 (@ Groq)", "scenario": "Angry Tweets", "executed": "2024-04-24-08-20", "scoring_id": "2daab99e-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3984375, "uncertainty": 0.029500894957724687, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.00012015772244922118, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Opus", "scenario": "HyggeSwag", "executed": "2024-04-24-07-16", "scoring_id": "d131ec32-020e-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.8064516129032258, "uncertainty": 0.027745916977754175, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9523809523809523, "uncertainty": 0.00806162546201717, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 1.859334268112434, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 (@ Groq)", "scenario": "HyggeSwag", "executed": "2024-04-24-08-20", "scoring_id": "2dadf406-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4032258064516129, "uncertainty": 0.04277495534070436, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.36363636363636365, "uncertainty": 0.04113427735743302, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 0.00023026727402823105, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 (@ Groq)", "scenario": "#twitterhjerne", "executed": "2024-04-24-08-20", "scoring_id": "2db0afca-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.6923076923076923, "uncertainty": 0.04802808186165631, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.5128205128205128, "uncertainty": 0.056329231813053694, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5256410256410257, "uncertainty": 0.05621805569763319, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6058362230658532, "uncertainty": 0.053840786220034485, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.0585066040037125, "uncertainty": 0.01241942858347421, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.07735479191941773, "uncertainty": 0.016091680414828134, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6310549699343168, "uncertainty": 0.05249383501362704, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.094672483688845, "uncertainty": 0.019324529874527603, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.1252876726357058, "uncertainty": 0.024708878561292356, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5794605039633237, "uncertainty": 0.05494270986776133, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.02557236290123237, "uncertainty": 0.005618234962872988, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.0319685056424156, "uncertainty": 0.006977362212639456, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.004251913828715586, "uncertainty": 0.0009545823074306118, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.00021979356339822212, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Opus", "scenario": "#twitterhjerne", "executed": "2024-04-24-07-20", "scoring_id": "fb9dfe84-020e-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.23076923076923078, "uncertainty": 0.040023401551380254, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.20512820512820512, "uncertainty": 0.036762235499045566, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.14102564102564102, "uncertainty": 0.02731226568830301, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6400566124763244, "uncertainty": 0.05194359865943587, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.10793747664357248, "uncertainty": 0.02170935905052806, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.1505754369184321, "uncertainty": 0.028837552191184116, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.666582078505785, "uncertainty": 0.0501097249640679, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.15839417428410793, "uncertainty": 0.030055737107326848, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.22376661111162824, "uncertainty": 0.039162197223891006, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6122242663151178, "uncertainty": 0.053526717795293784, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.055703676200043656, "uncertainty": 0.011859642634314738, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.08046393258579793, "uncertainty": 0.016682051934857032, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0035653207279467145, "uncertainty": 0.000800989612678758, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 5.628630899230186, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 2024-04-09", "scenario": "DaNE", "executed": "2024-04-24-07-02", "scoring_id": "2110c19c-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.551594746716698, "uncertainty": 0.030442831406052192, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 8.74844233212525, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 2024-04-09", "scenario": "Da. Gym 2000", "executed": "2024-04-24-07-39", "scoring_id": "25241fe0-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.7878787878787878, "uncertainty": 0.059260233132866574, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9090909090909091, "uncertainty": 0.029304510889879086, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 0.8816362523339745, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4 Turbo 2024-04-09", "scenario": "Da. Cloze Self Test", "executed": "2024-04-24-07-40", "scoring_id": "2526fbac-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.94, "uncertainty": 0.01602870262890186, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 1.0, "uncertainty": 0.0, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 0.8558014790993184, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 (@ Groq)", "scenario": "DaNE", "executed": "2024-04-24-08-20", "scoring_id": "559056ee-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.11602209944751382, "uncertainty": 0.012623400374479734, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.09673222381616142, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 (@ Groq)", "scenario": "Da. Gym 2000", "executed": "2024-04-24-08-21", "scoring_id": "588b228e-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.45454545454545453, "uncertainty": 0.08791353266963721, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6, "uncertainty": 0.08510029962420883, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 1.055459603547316, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 2 (@ Groq)", "scenario": "Da. Cloze Self Test", "executed": "2024-04-24-08-21", "scoring_id": "588e09ae-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.48, "uncertainty": 0.07093553503854434, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7586206896551724, "uncertainty": 0.05204080343501245, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 2.6789879679400475, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NorskGPT-Llama-3-8b-v0.1", "scenario": "Citizenship Test", "executed": "2024-04-24-08-23", "scoring_id": "5893dbcc-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.35206611570247937, "uncertainty": 0.018213627772105223, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.1889763779527559, "uncertainty": 0.012237214146848193, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.5206611570247934, "uncertainty": 0.019926881491111097, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.5381818181818181, "uncertainty": 0.01984456503791476, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.19589086178942597, "uncertainty": 0.012576816083553734, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.008319684392866672, "uncertainty": 0.0006587491684718136, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 1.3438829974958304, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NorskGPT-Llama-3-8b-v0.1", "scenario": "Nordjylland News", "executed": "2024-04-24-08-37", "scoring_id": "589bd19c-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.5790818191568057, "uncertainty": 0.027694055663079895, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.0667218998193881, "uncertainty": 0.007075032264980468, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.08963546376619393, "uncertainty": 0.00927137499164215, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.004357765277964063, "uncertainty": 0.0004929650058160246, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.4112925418501254, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NorskGPT-Llama-3-8b-v0.1", "scenario": "Angry Tweets", "executed": "2024-04-24-08-44", "scoring_id": "602a93e4-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.390625, "uncertainty": 0.029298062219283494, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.04545454545454545, "uncertainty": 0.0053403308324939365, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.359375, "uncertainty": 0.028336484792599318, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.6082949308755761, "uncertainty": 0.029326998600665687, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2731606223164153, "uncertainty": 0.02443716215085115, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.022403340937675594, "uncertainty": 0.0026956700037740777, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 1.5763641916364577, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NorskGPT-Llama-3-8b-v0.1", "scenario": "HyggeSwag", "executed": "2024-04-24-08-50", "scoring_id": "602f6112-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.24193548387096775, "uncertainty": 0.03260145244886115, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.07407407407407407, "uncertainty": 0.012191964433297559, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.29838709677419356, "uncertainty": 0.03721421114641279, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.4, "uncertainty": 0.042662121944994816, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.19654422719301826, "uncertainty": 0.02807071526664272, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.011498506140506083, "uncertainty": 0.0020204586301961537, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 2.8154344375727836, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NorskGPT-Llama-3-8b-v0.1", "scenario": "#twitterhjerne", "executed": "2024-04-24-08-56", "scoring_id": "603327ca-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.3076923076923077, "uncertainty": 0.04802808186165631, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.24358974358974358, "uncertainty": 0.041542808462127094, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.21794871794871795, "uncertainty": 0.038429877230353085, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.626270282918062, "uncertainty": 0.05277143241000707, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.09477978238368757, "uncertainty": 0.019344138740645733, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.13747308337188408, "uncertainty": 0.026734359048825162, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6530172205888308, "uncertainty": 0.05108718838365823, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.1384505025387007, "uncertainty": 0.026893926643403645, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.20544820803785166, "uncertainty": 0.03680476212077275, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5971042670500584, "uncertainty": 0.05424032569113606, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.04931996369541173, "uncertainty": 0.010571498886166994, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.07030879489537996, "uncertainty": 0.014737635894243128, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.002927112417707506, "uncertainty": 0.0006580300930621878, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 1.0017512745779151, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NorskGPT-Llama-3-8b-v0.1", "scenario": "DaNE", "executed": "2024-04-24-08-58", "scoring_id": "888bf1a2-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.06896551724137931, "uncertainty": 0.007903000205994085, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 3.8169179606093167, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NorskGPT-Llama-3-8b-v0.1", "scenario": "Da. Gym 2000", "executed": "2024-04-24-09-14", "scoring_id": "8e17b642-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.2727272727272727, "uncertainty": 0.07033082613570978, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.3333333333333333, "uncertainty": 0.07879657372611928, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.24242424242424243, "uncertainty": 0.06512113531084239, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.18181818181818182, "uncertainty": 0.052748119601782335, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.21969513998789153, "uncertainty": 0.060786146026811524, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.017061810439036137, "uncertainty": 0.0059466334409157065, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 5.629204463908646, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "NorskGPT-Llama-3-8b-v0.1", "scenario": "Da. Cloze Self Test", "executed": "2024-04-24-09-17", "scoring_id": "8e1b24ee-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.34, "uncertainty": 0.06377377428946053, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.30769230769230765, "uncertainty": 0.06053897505565345, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.2, "uncertainty": 0.04547149681957972, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4444444444444445, "uncertainty": 0.07017206299317856, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.36730533038683577, "uncertainty": 0.06604511098251367, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03635986319888703, "uncertainty": 0.009957639262402895, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 2.0860606722999364, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Opus", "scenario": "Da. Gym 2000", "executed": "2024-04-24-09-26", "scoring_id": "8e21f72e-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.7272727272727273, "uncertainty": 0.07033082613570978, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9090909090909091, "uncertainty": 0.029304510889879086, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 2.4594881460917266, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude Opus", "scenario": "Da. Cloze Self Test", "executed": "2024-04-24-09-28", "scoring_id": "8e246176-020f-11ef-9006-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.96, "uncertainty": 0.010913159236699138, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 1.0, "uncertainty": 0.0, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 1.860271888920106, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o 2024-05-13", "scenario": "Citizenship Test", "executed": "2024-05-13-23-45", "scoring_id": "737597be-1178-11ef-9803-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.9801652892561984, "uncertainty": 0.0015522680754323618, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9800995024875622, "uncertainty": 0.001557312029188109, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.4396561113486359, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o 2024-05-13", "scenario": "Nordjylland News", "executed": "2024-05-13-23-50", "scoring_id": "7379249c-1178-11ef-9803-b83fd2ad0420", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.729204365213712, "uncertainty": 0.022435712441322673, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.23589652723918977, "uncertainty": 0.020479656446220025, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.32299230688623465, "uncertainty": 0.02484475555115567, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.014397660305257886, "uncertainty": 0.001612287899192952, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 1.0020452641602606, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o 2024-05-13", "scenario": "Angry Tweets", "executed": "2024-05-13-23-55", "scoring_id": "863e8f9a-1178-11ef-9803-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.71875, "uncertainty": 0.024880815915453058, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7515151515151515, "uncertainty": 0.02298433181155486, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.40589280311723996, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o 2024-05-13", "scenario": "HyggeSwag", "executed": "2024-05-13-23-57", "scoring_id": "8641a2b6-1178-11ef-9803-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.8387096774193549, "uncertainty": 0.024046461380720276, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9565217391304348, "uncertainty": 0.007392617224242953, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 0.41448438456544895, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o 2024-05-13", "scenario": "#twitterhjerne", "executed": "2024-05-13-23-58", "scoring_id": "8643e594-1178-11ef-9803-b83fd2ad0420", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.358974358974359, "uncertainty": 0.05188218719623366, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.2564102564102564, "uncertainty": 0.042988097962593605, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.21794871794871795, "uncertainty": 0.038429877230353085, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6311755325549687, "uncertainty": 0.0524867068882028, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.10297688688223812, "uncertainty": 0.02082681397356195, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.13641956326134214, "uncertainty": 0.02656188525708298, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6567275493572919, "uncertainty": 0.050828071434419884, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.1538040032570963, "uncertainty": 0.02934391473162375, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.205757052954966, "uncertainty": 0.03684576211778944, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6060040975228335, "uncertainty": 0.05383276809744492, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.048471698934417794, "uncertainty": 0.010398947795840023, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.06272228889695906, "uncertainty": 0.01325469180134472, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0028667657983859475, "uncertainty": 0.0006445028646127216, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.9683888617049282, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o 2024-05-13", "scenario": "DaNE", "executed": "2024-05-13-23-59", "scoring_id": "a410aad0-1178-11ef-9803-b83fd2ad0420", "metrics": [{"name": "NER F1", "value": 0.48504983388704326, "uncertainty": 0.03074296792784243, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 3.2700433970430822, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o 2024-05-13", "scenario": "Da. Gym 2000", "executed": "2024-05-14-00-13", "scoring_id": "a4e3a66a-1178-11ef-9803-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.7575757575757576, "uncertainty": 0.06512113531084239, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7692307692307692, "uncertainty": 0.0629440085977876, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 0.4065632574246124, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o 2024-05-13", "scenario": "Da. Cloze Self Test", "executed": "2024-05-14-00-14", "scoring_id": "a4e6a216-1178-11ef-9803-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.84, "uncertainty": 0.03819605732844696, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8695652173913043, "uncertainty": 0.032234047839966716, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 0.4101825327426195, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o mini-2024-07-18", "scenario": "Citizenship Test", "executed": "2024-09-11-12-09", "scoring_id": "adfb04b4-7037-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.8842975206611571, "uncertainty": 0.00816925792930608, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9090909090909091, "uncertainty": 0.00659866628468649, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.46490577784956677, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o mini-2024-07-18", "scenario": "Nordjylland News", "executed": "2024-09-11-12-15", "scoring_id": "ae0089c0-7037-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7287902440627416, "uncertainty": 0.022457261917836098, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.23688437869967824, "uncertainty": 0.02053883055459146, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.3206585924609636, "uncertainty": 0.024750268493817368, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.014743295695710307, "uncertainty": 0.0016504140824607572, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.886178231779971, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o mini-2024-07-18", "scenario": "Angry Tweets", "executed": "2024-09-11-12-19", "scoring_id": "c6fc54cc-7037-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6953125, "uncertainty": 0.02607527537516231, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6666666666666666, "uncertainty": 0.027351535692349903, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.5295953585898587, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o mini-2024-07-18", "scenario": "HyggeSwag", "executed": "2024-09-11-12-21", "scoring_id": "c6ffe92a-7037-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.7741935483870968, "uncertainty": 0.031075427015084676, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8717948717948718, "uncertainty": 0.019867852100178385, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 0.4604180235161743, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o mini-2024-07-18", "scenario": "#twitterhjerne", "executed": "2024-09-11-12-22", "scoring_id": "c7028658-7037-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.23076923076923078, "uncertainty": 0.040023401551380254, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.2564102564102564, "uncertainty": 0.042988097962593605, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.23076923076923078, "uncertainty": 0.040023401551380254, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.64078680735368, "uncertainty": 0.05189736242248896, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.09902402889568908, "uncertainty": 0.020115611839995155, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.1336929230839098, "uncertainty": 0.026113177879706306, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6653513954235957, "uncertainty": 0.05020182858998381, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.1521515637496449, "uncertainty": 0.02908533630362678, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.20851567464126794, "uncertainty": 0.037210068716726205, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6127325021303617, "uncertainty": 0.05350094011832232, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.04513496328497912, "uncertainty": 0.00971705209542843, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.059995306084535543, "uncertainty": 0.012715303819255262, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0023169397974971873, "uncertainty": 0.0005211788626121885, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.8641884824233458, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o mini-2024-07-18", "scenario": "DaNE", "executed": "2024-09-11-12-23", "scoring_id": "e4bbe176-7037-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "NER F1", "value": 0.33532934131736525, "uncertainty": 0.02743293615355199, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 2.9459936437500573, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o mini-2024-07-18", "scenario": "Da. Gym 2000", "executed": "2024-09-11-12-36", "scoring_id": "e59cd758-7037-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5757575757575758, "uncertainty": 0.08661110996342036, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7692307692307692, "uncertainty": 0.0629440085977876, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 0.591255598817952, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "GPT 4o mini-2024-07-18", "scenario": "Da. Cloze Self Test", "executed": "2024-09-11-12-36", "scoring_id": "e5a02cbe-7037-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.7, "uncertainty": 0.05968133957569837, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9, "uncertainty": 0.025577716961013578, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 0.4518279932602309, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude 3.5 Sonnet", "scenario": "Citizenship Test", "executed": "2024-09-11-13-26", "scoring_id": "08e89b20-7038-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.9933884297520661, "uncertainty": 0.0005244030991202106, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9949748743718593, "uncertainty": 0.00039920922918239326, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.00019731595871723756, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude 3.5 Sonnet", "scenario": "Nordjylland News", "executed": "2024-09-11-13-26", "scoring_id": "08eca76a-7038-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7290500473976135, "uncertainty": 0.02244374717840485, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.23667851527247621, "uncertainty": 0.020526517249576385, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.3180810234293733, "uncertainty": 0.024644469974281005, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.016376243420139266, "uncertainty": 0.0018301734061894873, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.0001290164466869707, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude 3.5 Sonnet", "scenario": "Angry Tweets", "executed": "2024-09-11-13-26", "scoring_id": "0cd5f6f6-7038-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5234375, "uncertainty": 0.030702866741079908, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.20224719101123595, "uncertainty": 0.019858437289067575, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.00010366323044763703, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude 3.5 Sonnet", "scenario": "HyggeSwag", "executed": "2024-09-11-13-26", "scoring_id": "0cd90aa8-7038-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.7580645161290323, "uncertainty": 0.03260145244886115, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9302325581395349, "uncertainty": 0.011536539195509688, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 0.0001982901209679943, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude 3.5 Sonnet", "scenario": "#twitterhjerne", "executed": "2024-09-11-13-26", "scoring_id": "0cdb7144-7038-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.3076923076923077, "uncertainty": 0.04802808186165631, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.21794871794871795, "uncertainty": 0.038429877230353085, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.16666666666666666, "uncertainty": 0.031314605843441035, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6334030629095868, "uncertainty": 0.05235382744991725, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.09874024071573681, "uncertainty": 0.020064281309854142, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.14274300268753842, "uncertainty": 0.027589594212079287, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6599439359628237, "uncertainty": 0.050598426616367154, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.14704471473465153, "uncertainty": 0.028278419306786696, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.21107833879609672, "uncertainty": 0.03754542235593056, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.605231856688475, "uncertainty": 0.05386954710866527, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.05141588192326344, "uncertainty": 0.010996452046145784, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.0714254078025669, "uncertainty": 0.014953710582715394, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.002522862532761139, "uncertainty": 0.0005673825612004922, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.00025712598700267385, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude 3.5 Sonnet", "scenario": "DaNE", "executed": "2024-09-11-13-26", "scoring_id": "2c9b76f0-7038-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "NER F1", "value": 0.3, "uncertainty": 0.025847201229270655, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 8.555960742820389, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude 3.5 Sonnet", "scenario": "Da. Gym 2000", "executed": "2024-09-11-14-03", "scoring_id": "2d85b3c8-7038-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.7272727272727273, "uncertainty": 0.07033082613570978, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9090909090909091, "uncertainty": 0.029304510889879086, "higher_is_better": true, "N": 33}, {"name": "Inference seconds", "value": 1.4247908113951173, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "Claude 3.5 Sonnet", "scenario": "Da. Cloze Self Test", "executed": "2024-09-11-14-04", "scoring_id": "2d89186a-7038-11ef-858d-b83fd2ad0ed0", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.96, "uncertainty": 0.010913159236699138, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 1.0, "uncertainty": 0.0, "higher_is_better": true, "N": 50}, {"name": "Inference seconds", "value": 0.8876124241203069, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B Instruct", "scenario": "Citizenship Test", "executed": "2024-11-14-11-13", "scoring_id": "56f01448-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.6628099173553719, "uncertainty": 0.01784453873561962, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7341176470588235, "uncertainty": 0.015584637786841092, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.32727272727272727, "uncertainty": 0.017578846982404805, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.6427406199021207, "uncertainty": 0.018334156038389397, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.23345991666787905, "uncertainty": 0.01428856883430355, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.013831830742947903, "uncertainty": 0.001089111094571587, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.5763207201803611, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B Instruct", "scenario": "Nordjylland News", "executed": "2024-11-14-11-19", "scoring_id": "56fb0010-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7347163138786952, "uncertainty": 0.022145177853833627, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.2556564730633289, "uncertainty": 0.021621168191621597, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.33408525051337973, "uncertainty": 0.02527696241582582, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.016481304094195365, "uncertainty": 0.0018417180244197163, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.3676725119398907, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B Instruct", "scenario": "Angry Tweets", "executed": "2024-11-14-11-21", "scoring_id": "677c853a-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.23828125, "uncertainty": 0.022339772442203663, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.4716981132075471, "uncertainty": 0.030671889437843432, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2816390679413773, "uncertainty": 0.024901747945261773, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.02253167001669454, "uncertainty": 0.002710755244037984, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.6893156235582865, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B Instruct", "scenario": "HyggeSwag", "executed": "2024-11-14-11-24", "scoring_id": "6781374c-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.25806451612903225, "uncertainty": 0.03403499149271179, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4, "uncertainty": 0.042662121944994816, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.20967741935483872, "uncertainty": 0.029456915191382348, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.6341463414634146, "uncertainty": 0.04124089718061664, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.1951973263663498, "uncertainty": 0.02792508388195176, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.007475799077109555, "uncertainty": 0.0013189548727450993, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.5547517383951814, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B Instruct", "scenario": "#twitterhjerne", "executed": "2024-11-14-11-27", "scoring_id": "6784d078-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.34615384615384615, "uncertainty": 0.05102983697800982, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.20512820512820512, "uncertainty": 0.036762235499045566, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.21794871794871795, "uncertainty": 0.038429877230353085, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6291788503145561, "uncertainty": 0.05260391381917778, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.10466150149702583, "uncertainty": 0.02112777027204278, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.1465402575886956, "uncertainty": 0.028198073418978033, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6550796528657278, "uncertainty": 0.050943921295566824, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.15658740326800652, "uncertainty": 0.029776685317504274, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.2220047926814803, "uncertainty": 0.038942041731367526, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5994641108390613, "uncertainty": 0.0541357390163186, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.0539480227572909, "uncertainty": 0.011507208330954628, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.07152113505319849, "uncertainty": 0.014972208504676714, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.003818146497882807, "uncertainty": 0.0008575721331143236, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.407448661295721, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B Instruct", "scenario": "DaNE", "executed": "2024-11-14-11-28", "scoring_id": "86b8d278-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.020618556701030927, "uncertainty": 0.0024854461703644557, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 4.059267306793117, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B Instruct", "scenario": "Da. Gym 2000", "executed": "2024-11-14-11-45", "scoring_id": "87e5e780-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.45454545454545453, "uncertainty": 0.08791353266963721, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.75, "uncertainty": 0.06648460908141314, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.24242424242424243, "uncertainty": 0.06512113531084239, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.7272727272727273, "uncertainty": 0.07033082613570978, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.1915933663737148, "uncertainty": 0.054919956461392416, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.007111155356603292, "uncertainty": 0.002503575226765178, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 4.510986441668744, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B Instruct", "scenario": "Da. Cloze Self Test", "executed": "2024-11-14-11-48", "scoring_id": "87e94e0c-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.38, "uncertainty": 0.06695677906683112, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5714285714285715, "uncertainty": 0.0695992298258873, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.24, "uncertainty": 0.05183750637432087, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.5714285714285715, "uncertainty": 0.0695992298258873, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.3226898490573315, "uncertainty": 0.06211438021997185, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.032446228520981515, "uncertainty": 0.008921925665843074, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.143816736699082, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B Instruct", "scenario": "Citizenship Test", "executed": "2024-11-14-11-49", "scoring_id": "87ed5bd2-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.5933884297520661, "uncertainty": 0.019264615347629833, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.6666666666666667, "uncertainty": 0.017743080454379223, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.36363636363636365, "uncertainty": 0.018476265597122166, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.3227265731421954, "uncertainty": 0.017451802852336405, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.030733152188693255, "uncertainty": 0.002378438908535553, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.4239505948829811, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B Instruct", "scenario": "Nordjylland News", "executed": "2024-11-14-11-53", "scoring_id": "87f40c66-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7293587799866994, "uncertainty": 0.02242766723954803, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.2404791218334851, "uncertainty": 0.020752290574293012, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.31440695320482176, "uncertainty": 0.024491054929642295, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.015415325236972421, "uncertainty": 0.0017244662917653229, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.17944417411383862, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B Instruct", "scenario": "Angry Tweets", "executed": "2024-11-14-11-54", "scoring_id": "8ba9eae2-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4609375, "uncertainty": 0.030582669562744386, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.28125, "uncertainty": 0.024880815915453058, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.26604870805643904, "uncertainty": 0.02403380996196219, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.018916053837295825, "uncertainty": 0.002284183236171725, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.5309171653671001, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B Instruct", "scenario": "HyggeSwag", "executed": "2024-11-14-11-57", "scoring_id": "8bae6900-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.29838709677419356, "uncertainty": 0.03721421114641279, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.24193548387096775, "uncertainty": 0.03260145244886115, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.24973656608907718, "uncertainty": 0.033306356580120766, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.022012337238227205, "uncertainty": 0.0038267557641467245, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.2151544656615794, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B Instruct", "scenario": "#twitterhjerne", "executed": "2024-11-14-11-59", "scoring_id": "8bb1b290-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.3076923076923077, "uncertainty": 0.04802808186165631, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.20512820512820512, "uncertainty": 0.036762235499045566, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.24358974358974358, "uncertainty": 0.041542808462127094, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.6336212737183284, "uncertainty": 0.05234069013684022, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.09997391539562034, "uncertainty": 0.02028715949749856, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.14067435527513633, "uncertainty": 0.027255374389554353, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6592895396244831, "uncertainty": 0.05064552746508866, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.14703579612820528, "uncertainty": 0.028276999819136967, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.20976042871703002, "uncertainty": 0.037373328760113, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.60482536141689, "uncertainty": 0.05388879896241535, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.051165040552755434, "uncertainty": 0.010945697621541657, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.07188925178852251, "uncertainty": 0.015043303300573609, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0034344306220121393, "uncertainty": 0.0007716850245051831, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.16218038708962595, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B Instruct", "scenario": "DaNE", "executed": "2024-11-14-11-59", "scoring_id": "a9b1d0c2-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.0065359477124183, "uncertainty": 0.0007991990436826575, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 2.263367516375183, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B Instruct", "scenario": "Da. Gym 2000", "executed": "2024-11-14-12-09", "scoring_id": "aacf029a-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3333333333333333, "uncertainty": 0.07879657372611928, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5, "uncertainty": 0.0886461454418842, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.2532257867393677, "uncertainty": 0.06705282650152447, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.021476688855523292, "uncertainty": 0.007451751248194422, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 3.074300798241783, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B Instruct", "scenario": "Da. Cloze Self Test", "executed": "2024-11-14-12-11", "scoring_id": "aad28708-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.24, "uncertainty": 0.05183750637432087, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.3, "uncertainty": 0.059681339575698364, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.5454545454545454, "uncertainty": 0.07046203019562972, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.29860981466464576, "uncertainty": 0.059522755812379466, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.031076821149175725, "uncertainty": 0.008557466378440829, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 0.9202946676220745, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B Instruct", "scenario": "Citizenship Test", "executed": "2024-11-14-12-12", "scoring_id": "aad675de-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.38181818181818183, "uncertainty": 0.01884579090906461, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.34965034965034963, "uncertainty": 0.018156093623545665, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.34049586776859503, "uncertainty": 0.017929612449703182, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.5831702544031311, "uncertainty": 0.019408662265484967, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.21466657991405813, "uncertainty": 0.013460464658450157, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.0062819165910466615, "uncertainty": 0.0004984216451776556, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.43752267410563045, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B Instruct", "scenario": "Nordjylland News", "executed": "2024-11-14-12-16", "scoring_id": "aadd647a-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.6868963169058164, "uncertainty": 0.02443589835884643, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.18522008781284063, "uncertainty": 0.017146573481204675, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.24007603818130122, "uncertainty": 0.020728501169986643, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.014395477563375607, "uncertainty": 0.0016120470400869898, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.11567402610322461, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B Instruct", "scenario": "Angry Tweets", "executed": "2024-11-14-12-17", "scoring_id": "aed9ead0-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.32421875, "uncertainty": 0.026967363808121262, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.6212121212121212, "uncertainty": 0.028962111657705215, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2459564048507771, "uncertainty": 0.02282699906137346, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.01592886386998411, "uncertainty": 0.0019293255853635063, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.45666856603565975, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B Instruct", "scenario": "HyggeSwag", "executed": "2024-11-14-12-19", "scoring_id": "aede75b4-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.22580645161290322, "uncertainty": 0.03107542701508467, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.2857142857142857, "uncertainty": 0.03627731457907723, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.25806451612903225, "uncertainty": 0.03403499149271179, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.29411764705882354, "uncertainty": 0.036904949779407274, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.20120617944147928, "uncertainty": 0.028569801450246044, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.009835869164318143, "uncertainty": 0.0017312155485467602, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.1095350971520548, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B Instruct", "scenario": "#twitterhjerne", "executed": "2024-11-14-12-21", "scoring_id": "aee1c822-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.4358974358974359, "uncertainty": 0.05543982288968968, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.20512820512820512, "uncertainty": 0.036762235499045566, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.20512820512820512, "uncertainty": 0.036762235499045566, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.617399202624702, "uncertainty": 0.0532588005132667, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.09809392266950699, "uncertainty": 0.019947242214733152, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.1370579283315353, "uncertainty": 0.026666452976232626, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6440381828026894, "uncertainty": 0.0516885652279037, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.14611037761224677, "uncertainty": 0.028129515025804845, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.20924107115570323, "uncertainty": 0.03730529555739873, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.5861107248526353, "uncertainty": 0.05469445350464498, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.04656822876782952, "uncertainty": 0.010010569511763137, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.061875724469324676, "uncertainty": 0.013087603136193598, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.004657471957706058, "uncertainty": 0.001045206869343687, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.14752549744652918, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B Instruct", "scenario": "DaNE", "executed": "2024-11-14-12-22", "scoring_id": "d06d727a-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.014336917562724016, "uncertainty": 0.0017393160632203082, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.9684290430350302, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B Instruct", "scenario": "Da. Gym 2000", "executed": "2024-11-14-12-26", "scoring_id": "d18b3868-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4, "uncertainty": 0.08510029962420883, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.2, "uncertainty": 0.0567335330828059, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.1983799852651701, "uncertainty": 0.05638794314577711, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.010113813534646908, "uncertainty": 0.0035499321604705193, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 2.4449032446665857, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B Instruct", "scenario": "Da. Cloze Self Test", "executed": "2024-11-14-12-27", "scoring_id": "d18e9c88-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.32, "uncertainty": 0.061841235674628396, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.28571428571428575, "uncertainty": 0.057999358188239425, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.22, "uncertainty": 0.04876818033899923, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.25, "uncertainty": 0.05328691033544497, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.3429866340972798, "uncertainty": 0.06404285270398995, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.0358089016129232, "uncertainty": 0.009812358009436303, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 0.8396608720626682, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B", "scenario": "Citizenship Test", "executed": "2024-11-14-12-28", "scoring_id": "d192c380-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.46611570247933887, "uncertainty": 0.019869293130808378, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5590778097982709, "uncertainty": 0.019682295453088878, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.3652892561983471, "uncertainty": 0.018512040184582947, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0.4188790560471976, "uncertainty": 0.019435544389960233, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.2364105808781314, "uncertainty": 0.014413463329957006, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.012707191270315768, "uncertainty": 0.001001698621983132, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.9975693781240574, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B", "scenario": "Nordjylland News", "executed": "2024-11-14-12-38", "scoring_id": "d19a4e20-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.5774514250953993, "uncertainty": 0.027723052332483015, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.07981652644013869, "uncertainty": 0.00834480511738152, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.10414753956789304, "uncertainty": 0.010600697731068816, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.01878163410932757, "uncertainty": 0.0020938616858891448, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.8193169769070422, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B", "scenario": "Angry Tweets", "executed": "2024-11-14-12-43", "scoring_id": "d8c69c80-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3203125, "uncertainty": 0.02679645844517544, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5863453815261044, "uncertainty": 0.02985283740321947, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.28515625, "uncertainty": 0.02508928289662873, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0.4444444444444445, "uncertainty": 0.030390595213722116, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.32667653211190867, "uncertainty": 0.02707297095902988, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.03129708820127095, "uncertainty": 0.0037315457296604594, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 1.1698149236954123, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B", "scenario": "HyggeSwag", "executed": "2024-11-14-12-48", "scoring_id": "d8cb8b00-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3790322580645161, "uncertainty": 0.041838530642705145, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7368421052631579, "uncertainty": 0.034468473408929334, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.2661290322580645, "uncertainty": 0.03471707861841491, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0.4888888888888889, "uncertainty": 0.04441776482338966, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.21178622475961945, "uncertainty": 0.029673784638728957, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.012464504884802443, "uncertainty": 0.002188058643744588, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 2.032073739444792, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B", "scenario": "#twitterhjerne", "executed": "2024-11-14-12-52", "scoring_id": "d8cf2c92-a287-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9743589743589743, "uncertainty": 0.005632923181305373, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.5128205128205128, "uncertainty": 0.056329231813053694, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5256410256410257, "uncertainty": 0.05621805569763319, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5207559127392423, "uncertainty": 0.056269158342122996, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.054300335286150324, "uncertainty": 0.011578043910498027, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.06646307238722558, "uncertainty": 0.013989151110605327, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5429087839065454, "uncertainty": 0.055951172237977756, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.08600449973536908, "uncertainty": 0.01772330362879453, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.10683156757899351, "uncertainty": 0.021513566449409233, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.49572169589690673, "uncertainty": 0.05636216362957063, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.02448187214122548, "uncertainty": 0.005384674005370205, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.028268136799417986, "uncertainty": 0.006193313639176416, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.008340306131569192, "uncertainty": 0.001864764957755587, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.6206369813597308, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B", "scenario": "DaNE", "executed": "2024-11-14-12-53", "scoring_id": "0a14af70-a288-11ef-b105-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.10452961672473868, "uncertainty": 0.011520857735872475, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 3.910010511519431, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B", "scenario": "Da. Gym 2000", "executed": "2024-11-14-13-09", "scoring_id": "0b35510c-a288-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.30303030303030304, "uncertainty": 0.07488930560746875, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5, "uncertainty": 0.0886461454418842, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0.3333333333333333, "uncertainty": 0.07879657372611928, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.2155074690755725, "uncertainty": 0.059947487678125744, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.01754848535688244, "uncertainty": 0.006113228253589863, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 4.900199050119034, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.1 8B", "scenario": "Da. Cloze Self Test", "executed": "2024-11-14-13-12", "scoring_id": "0b38c6de-a288-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.32, "uncertainty": 0.061841235674628396, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5, "uncertainty": 0.0710492137805933, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.22, "uncertainty": 0.04876818033899923, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.3076923076923077, "uncertainty": 0.060538975055653456, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.3531480026469555, "uncertainty": 0.06492036390770682, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.036299700410413964, "uncertainty": 0.00994178352581182, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.685058217300102, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B", "scenario": "Citizenship Test", "executed": "2024-11-14-13-17", "scoring_id": "0b3e3c5e-a288-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.42644628099173554, "uncertainty": 0.019528998274474133, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4408945686900958, "uncertainty": 0.01968203481080405, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.3586776859504132, "uncertainty": 0.018366324181998794, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.2583691820579968, "uncertainty": 0.015299245521953072, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.0194433022990468, "uncertainty": 0.0015222440128208133, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.6531311460778364, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B", "scenario": "Nordjylland News", "executed": "2024-11-14-13-23", "scoring_id": "0b45a570-a288-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.6133846853176753, "uncertainty": 0.026943929153699347, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.12308035670772367, "uncertainty": 0.012263021529367701, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.15627456748957977, "uncertainty": 0.014980916792922254, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.012552384328640377, "uncertainty": 0.001408280738842408, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.4478065167367458, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B", "scenario": "Angry Tweets", "executed": "2024-11-14-13-26", "scoring_id": "12ada718-a288-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.3125, "uncertainty": 0.026443379233814845, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.4201680672268907, "uncertainty": 0.029986059714972965, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.2890625, "uncertainty": 0.025293993715981417, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.25627882018384357, "uncertainty": 0.02345941050283301, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.017378315306563905, "uncertainty": 0.0021017847950512655, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.7951463224062536, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B", "scenario": "HyggeSwag", "executed": "2024-11-14-13-29", "scoring_id": "12b258c6-a288-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.29838709677419356, "uncertainty": 0.03721421114641279, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.5882352941176471, "uncertainty": 0.04305577474264182, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.24193548387096775, "uncertainty": 0.03260145244886115, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.22571684719395202, "uncertainty": 0.031066690890418858, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.01618991898036761, "uncertainty": 0.0028313082529928457, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.4838644067020785, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B", "scenario": "#twitterhjerne", "executed": "2024-11-14-13-32", "scoring_id": "12b5d686-a288-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9743589743589743, "uncertainty": 0.005632923181305373, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.46153846153846156, "uncertainty": 0.05603276217193235, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5, "uncertainty": 0.056366290518193855, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.5122487502092989, "uncertainty": 0.056332463555672584, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.056565085877582175, "uncertainty": 0.012032055906746662, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.06425055438793321, "uncertainty": 0.013555511315783962, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5349604464494265, "uncertainty": 0.05609071959825655, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.09058771900383746, "uncertainty": 0.018574177226592645, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.10488737048285864, "uncertainty": 0.02116802446012567, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.4870666108834438, "uncertainty": 0.05632857638468684, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.025462715123827206, "uncertainty": 0.0055947748856087975, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.0270916221343956, "uncertainty": 0.005942735469134922, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.005711046483319921, "uncertainty": 0.0012802882375312623, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.346235374499184, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B", "scenario": "DaNE", "executed": "2024-11-14-13-33", "scoring_id": "4513f2ac-a288-11ef-b105-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.11009174311926606, "uncertainty": 0.012058525709664909, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 2.1788817520118755, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B", "scenario": "Da. Gym 2000", "executed": "2024-11-14-13-42", "scoring_id": "4635ce44-a288-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.2727272727272727, "uncertainty": 0.07033082613570978, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0.36363636363636365, "uncertainty": 0.08205263049166141, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.23475090491834863, "uncertainty": 0.06369860878993297, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.018046056678166247, "uncertainty": 0.006283379387570357, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 3.7279924257855974, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 11B Text Preview (@ Groq)", "scenario": "Angry Tweets", "executed": "2024-11-14-15-24", "scoring_id": "4811e3d4-a296-11ef-a2c5-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.0001168926492027822, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 11B Text Preview (@ Groq)", "scenario": "Citizenship Test", "executed": "2024-11-14-15-24", "scoring_id": "3ce7d194-a296-11ef-a2c5-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.7239669421487603, "uncertainty": 0.015955902282964556, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8027842227378191, "uncertainty": 0.012641017128109869, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.00022896342325863267, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 11B Text Preview (@ Groq)", "scenario": "HyggeSwag", "executed": "2024-11-14-15-24", "scoring_id": "481c7ec0-a296-11ef-a2c5-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.4274193548387097, "uncertainty": 0.04350328566137039, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.8235294117647058, "uncertainty": 0.025833464845585102, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 0.00020043052274793866, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 11B Text Preview (@ Groq)", "scenario": "Nordjylland News", "executed": "2024-11-14-15-24", "scoring_id": "3ceceb98-a296-11ef-a2c5-b83fd2ad0420", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7362763065099717, "uncertainty": 0.02206169724736346, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.25190657200665384, "uncertainty": 0.021411361472813993, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.33039884260335556, "uncertainty": 0.025136433579430177, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.016460527500409324, "uncertainty": 0.0018394351822190594, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.00014604673720896243, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 11B Text Preview (@ Groq)", "scenario": "#twitterhjerne", "executed": "2024-11-14-15-24", "scoring_id": "481f1d9c-a296-11ef-a2c5-b83fd2ad0420", "metrics": [{"name": "Avg. similarity to references (BERT similarity)", "value": 0.6341910923902805, "uncertainty": 0.05230628314149346, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.10346565692064373, "uncertainty": 0.0209142644940071, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.14368590118815383, "uncertainty": 0.02774129283604422, "higher_is_better": true, "N": 78}, {"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.3076923076923077, "uncertainty": 0.04802808186165631, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.1794871794871795, "uncertainty": 0.03320459980558954, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.16666666666666666, "uncertainty": 0.031314605843441035, "higher_is_better": false, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6616668747021601, "uncertainty": 0.050473492824694176, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.15500373183781926, "uncertainty": 0.029530880164940734, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.22367873468519625, "uncertainty": 0.039151249418341166, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6043484142193427, "uncertainty": 0.05391129245960822, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.05060565966589938, "uncertainty": 0.010832412131767093, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.06710274874873469, "uncertainty": 0.014114112350032586, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.003495384004707329, "uncertainty": 0.0007853326533113417, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.00019924120547679754, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 3B", "scenario": "Da. Cloze Self Test", "executed": "2024-11-14-13-44", "scoring_id": "8532b8d2-a288-11ef-b105-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.42, "uncertainty": 0.0692303539078101, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7272727272727272, "uncertainty": 0.05636962415650378, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.24, "uncertainty": 0.05183750637432087, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.4, "uncertainty": 0.06820724522936956, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.3430703199319099, "uncertainty": 0.06405031929025831, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.0363206675177212, "uncertainty": 0.009947309582540894, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 1.1739148894976825, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B", "scenario": "Citizenship Test", "executed": "2024-11-14-13-47", "scoring_id": "5b41d826-a28f-11ef-874d-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.37355371900826445, "uncertainty": 0.018684368990034263, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.20338983050847456, "uncertainty": 0.01293649474094067, "higher_is_better": true, "N": 605}, {"name": "Accuracy (LM)", "value": 0.3652892561983471, "uncertainty": 0.018512040184582947, "higher_is_better": true, "N": 605}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 605}, {"name": "Brier Score (LM)", "value": 0.27270895740731294, "uncertainty": 0.015836134344700156, "higher_is_better": false, "N": 605}, {"name": "ECE Calibration (LM)", "value": 0.02304567059984106, "uncertainty": 0.0017976500347558187, "higher_is_better": false, "N": 605}, {"name": "Inference seconds", "value": 0.4628704805785313, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B", "scenario": "Nordjylland News", "executed": "2024-11-14-13-51", "scoring_id": "5b490a10-a28f-11ef-874d-b83fd2ad0948", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.5063259716828664, "uncertainty": 0.028400071329846333, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.029092180276913276, "uncertainty": 0.003209247525461857, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.036166317887031674, "uncertainty": 0.003960548539718591, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.010390335776222248, "uncertainty": 0.0011682679333315845, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.19012103654677048, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B", "scenario": "Angry Tweets", "executed": "2024-11-14-13-52", "scoring_id": "63f0908e-a28f-11ef-874d-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.34375, "uncertainty": 0.02776554819550559, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0.2903225806451613, "uncertainty": 0.025359228201752095, "higher_is_better": true, "N": 256}, {"name": "Accuracy (LM)", "value": 0.29296875, "uncertainty": 0.025494948373511118, "higher_is_better": true, "N": 256}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Brier Score (LM)", "value": 0.2720867460083169, "uncertainty": 0.02437705533646375, "higher_is_better": false, "N": 256}, {"name": "ECE Calibration (LM)", "value": 0.01957256524920268, "uncertainty": 0.0023618778545828507, "higher_is_better": false, "N": 256}, {"name": "Inference seconds", "value": 0.5637867390742031, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B", "scenario": "HyggeSwag", "executed": "2024-11-14-13-55", "scoring_id": "63f568f2-a28f-11ef-874d-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.2903225806451613, "uncertainty": 0.036624610410635514, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Accuracy (LM)", "value": 0.24193548387096775, "uncertainty": 0.03260145244886115, "higher_is_better": true, "N": 124}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 124}, {"name": "Brier Score (LM)", "value": 0.24932178420916828, "uncertainty": 0.033269421577997796, "higher_is_better": false, "N": 124}, {"name": "ECE Calibration (LM)", "value": 0.021095275647785676, "uncertainty": 0.0036707671805556383, "higher_is_better": false, "N": 124}, {"name": "Inference seconds", "value": 1.1201762226034677, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B", "scenario": "#twitterhjerne", "executed": "2024-11-14-13-57", "scoring_id": "63f8f0c6-a28f-11ef-874d-b83fd2ad0948", "metrics": [{"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.9743589743589743, "uncertainty": 0.005632923181305373, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.46153846153846156, "uncertainty": 0.05603276217193235, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.5256410256410257, "uncertainty": 0.05621805569763319, "higher_is_better": false, "N": 78}, {"name": "Avg. similarity to references (BERT similarity)", "value": 0.504898399573106, "uncertainty": 0.056360880635311986, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.05530912760675237, "uncertainty": 0.011780561033611548, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.06171902727264836, "uncertainty": 0.013056639950122174, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.5287010841644727, "uncertainty": 0.05618056308764943, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.09155406396592633, "uncertainty": 0.018752369822346415, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.1040021307205648, "uncertainty": 0.02101012614094582, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.480182823462364, "uncertainty": 0.05627774573018575, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.023858512494317214, "uncertainty": 0.005250922163633195, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.02572087812818836, "uncertainty": 0.005650002417914663, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.016450703743313894, "uncertainty": 0.0036480439288361687, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.16168592184877548, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B", "scenario": "DaNE", "executed": "2024-11-14-13-57", "scoring_id": "94c6d308-a28f-11ef-874d-b83fd2ad0948", "metrics": [{"name": "NER F1", "value": 0.02826855123674912, "uncertainty": 0.003380991189230282, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.9350787333050903, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B", "scenario": "Da. Gym 2000", "executed": "2024-11-14-14-01", "scoring_id": "95ed933e-a28f-11ef-874d-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.2727272727272727, "uncertainty": 0.07033082613570978, "higher_is_better": true, "N": 33}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Accuracy (LM)", "value": 0.21212121212121213, "uncertainty": 0.05926023313286657, "higher_is_better": true, "N": 33}, {"name": "F1 score (LM)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 33}, {"name": "Brier Score (LM)", "value": 0.2563131418491639, "uncertainty": 0.06758974822453226, "higher_is_better": false, "N": 33}, {"name": "ECE Calibration (LM)", "value": 0.022670180541883037, "uncertainty": 0.00785626231941437, "higher_is_better": false, "N": 33}, {"name": "Inference seconds", "value": 2.7929446373318294, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 1B", "scenario": "Da. Cloze Self Test", "executed": "2024-11-14-14-03", "scoring_id": "95f116c6-a28f-11ef-874d-b83fd2ad0948", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.32, "uncertainty": 0.061841235674628396, "higher_is_better": true, "N": 50}, {"name": "F1 score (Parsing of chosen option)", "value": 0.3333333333333333, "uncertainty": 0.06315485669386071, "higher_is_better": true, "N": 50}, {"name": "Accuracy (LM)", "value": 0.28, "uncertainty": 0.057294085992670434, "higher_is_better": true, "N": 50}, {"name": "F1 score (LM)", "value": 0.3076923076923077, "uncertainty": 0.060538975055653456, "higher_is_better": true, "N": 50}, {"name": "Brier Score (LM)", "value": 0.33390601182075635, "uncertainty": 0.06320901463018266, "higher_is_better": false, "N": 50}, {"name": "ECE Calibration (LM)", "value": 0.03399847597308149, "uncertainty": 0.00933375783773047, "higher_is_better": false, "N": 50}, {"name": "Inference seconds", "value": 0.886838188841939, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 90B Text Preview (@ Groq)", "scenario": "Citizenship Test", "executed": "2024-11-14-15-25", "scoring_id": "66f49ec2-a296-11ef-a2c5-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.9223140495867769, "uncertainty": 0.00572088006552687, "higher_is_better": true, "N": 605}, {"name": "F1 score (Parsing of chosen option)", "value": 0.9313725490196079, "uncertainty": 0.005103437933461151, "higher_is_better": true, "N": 605}, {"name": "Inference seconds", "value": 0.0002336224629582206, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 90B Text Preview (@ Groq)", "scenario": "Nordjylland News", "executed": "2024-11-14-15-25", "scoring_id": "66f86d90-a296-11ef-a2c5-b83fd2ad0420", "metrics": [{"name": "Similarity (BERT similarity)", "value": 0.7411900722980499, "uncertainty": 0.021795130364221104, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-L)", "value": 0.2691066867424524, "uncertainty": 0.02234742167674666, "higher_is_better": true, "N": 300}, {"name": "Similarity (ROUGE-1)", "value": 0.3460088450055581, "uncertainty": 0.025710351930225788, "higher_is_better": true, "N": 300}, {"name": "Generated Text Offensive Prob", "value": 0.01707854993835402, "uncertainty": 0.0019072988749307526, "higher_is_better": false, "N": 300}, {"name": "Inference seconds", "value": 0.0001445305805342893, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 90B Text Preview (@ Groq)", "scenario": "Angry Tweets", "executed": "2024-11-14-15-25", "scoring_id": "6aa04a9e-a296-11ef-a2c5-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.39453125, "uncertainty": 0.029401356669415582, "higher_is_better": true, "N": 256}, {"name": "F1 score (Parsing of chosen option)", "value": 0, "uncertainty": 0.0, "higher_is_better": true, "N": 256}, {"name": "Inference seconds", "value": 0.00011326601179462159, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 90B Text Preview (@ Groq)", "scenario": "HyggeSwag", "executed": "2024-11-14-15-25", "scoring_id": "6aa3bc38-a296-11ef-a2c5-b83fd2ad0420", "metrics": [{"name": "Accuracy (NLG Parsing of chosen option)", "value": 0.7338709677419355, "uncertainty": 0.03471707861841491, "higher_is_better": true, "N": 124}, {"name": "F1 score (Parsing of chosen option)", "value": 0.7894736842105262, "uncertainty": 0.029544405779082294, "higher_is_better": true, "N": 124}, {"name": "Inference seconds", "value": 0.00020882533112120245, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}, {"model": "LlaMa 3.2 90B Text Preview (@ Groq)", "scenario": "#twitterhjerne", "executed": "2024-11-14-15-25", "scoring_id": "6aa63bd4-a296-11ef-a2c5-b83fd2ad0420", "metrics": [{"name": "Avg. similarity to references (BERT similarity)", "value": 0.6318691024668197, "uncertainty": 0.052445573059133534, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-L)", "value": 0.10124865448167175, "uncertainty": 0.02051673552331105, "higher_is_better": true, "N": 78}, {"name": "Avg. similarity to references (ROUGE-1)", "value": 0.14745362746578713, "uncertainty": 0.02834346343793145, "higher_is_better": true, "N": 78}, {"name": "Prediction odd-one-out frequency (BERT similarity)", "value": 0.3717948717948718, "uncertainty": 0.052660420004177165, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-L)", "value": 0.23076923076923078, "uncertainty": 0.040023401551380254, "higher_is_better": false, "N": 78}, {"name": "Prediction odd-one-out frequency (ROUGE-1)", "value": 0.11538461538461539, "uncertainty": 0.02301345589204365, "higher_is_better": false, "N": 78}, {"name": "Max. similarity to references (BERT similarity)", "value": 0.6610248241669092, "uncertainty": 0.05052020568405437, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-L)", "value": 0.15388037724662698, "uncertainty": 0.029355836180846515, "higher_is_better": true, "N": 78}, {"name": "Max. similarity to references (ROUGE-1)", "value": 0.22552449014999262, "uncertainty": 0.03938046545441791, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (BERT similarity)", "value": 0.6006812697801834, "uncertainty": 0.054080813732374736, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-L)", "value": 0.04667204805618798, "uncertainty": 0.01003179461028865, "higher_is_better": true, "N": 78}, {"name": "Min. similarity to references (ROUGE-1)", "value": 0.06667338324515808, "uncertainty": 0.014030255848220692, "higher_is_better": true, "N": 78}, {"name": "Generated Text Offensive Prob", "value": 0.0033442448482860643, "uncertainty": 0.0007514891103083279, "higher_is_better": false, "N": 78}, {"name": "Inference seconds", "value": 0.0001992958967979902, "uncertainty": null, "higher_is_better": false, "N": 0}], "chosen_metric": null}]}